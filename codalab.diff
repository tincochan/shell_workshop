diff --git a/codalab/__init__.py b/codalab/__init__.py
index e69de29b..d169634f 100644
--- a/codalab/__init__.py
+++ b/codalab/__init__.py
@@ -0,0 +1,21 @@
+from opentelemetry import trace
+from opentelemetry.exporter.jaeger.thrift import JaegerExporter
+from opentelemetry.sdk.trace import TracerProvider
+from opentelemetry.sdk.trace.export import (
+    BatchSpanProcessor,
+    ConsoleSpanExporter,
+)
+from opentelemetry.propagate import set_global_textmap
+from opentelemetry.propagators.jaeger import JaegerPropagator
+from opentelemetry.sdk.resources import Resource
+
+set_global_textmap(JaegerPropagator())
+provider = TracerProvider(resource=Resource.create({"service.name": "codalab"}),)
+jaeger_exporter = JaegerExporter(
+    agent_host_name="44.242.150.207",
+    agent_port=6831,
+    collector_endpoint='http://44.242.150.207:14268/api/traces?format=jaeger.thrift',
+)
+processor = BatchSpanProcessor(jaeger_exporter)
+trace.set_tracer_provider(provider)
+provider.add_span_processor(processor)
diff --git a/codalab/lib/bundle_cli.py b/codalab/lib/bundle_cli.py
index 65dd1910..bf0998ba 100644
--- a/codalab/lib/bundle_cli.py
+++ b/codalab/lib/bundle_cli.py
@@ -101,7 +101,11 @@ from codalab.worker.download_util import BundleTarget
 from codalab.worker.bundle_state import State, LinkFormat
 from codalab.rest.worksheet_block_schemas import BlockModes
 from codalab.worker.file_util import get_path_size
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
 
+tracer = trace.get_tracer(__name__)
 
 # Command groupings
 BUNDLE_COMMANDS = (
@@ -1006,11 +1010,15 @@ class BundleCLI(object):
         ),
     )
     def do_help_command(self, args):
-        self.print_version()
-        if args.command:
-            self.do_command([args.command, '--help'])
-            return
-        print(Commands.help_text(args.verbose, args.markdown), file=self.stdout)
+        with tracer.start_as_current_span(
+            "help", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self.print_version()
+            if args.command:
+                self.do_command([args.command, '--help'])
+                return
+            print(Commands.help_text(args.verbose, args.markdown), file=self.stdout)
 
     @Commands.command(
         'store',
@@ -1046,56 +1054,65 @@ class BundleCLI(object):
         ),
     )
     def do_store_command(self, args):
-        client = self.manager.current_client()
-        if args.command == 'add':
-            bundle_store_info = {
-                "name": args.name,
-                "storage_type": args.storage_type,
-                "storage_format": args.storage_format,
-                "url": args.url,
-                "authentication": args.authentication,
-            }
-            if args.url is not None:
-                inferred_type = parse_linked_bundle_url(args.url).storage_type
-                if args.storage_type is None:
-                    bundle_store_info["storage_type"] = inferred_type
-                elif args.storage_type != inferred_type:
-                    raise UsageError(
-                        f"Bundle store {args.url} only supports storage type: {inferred_type}"
-                    )
-            new_bundle_store = client.create('bundle_stores', bundle_store_info)
-            print(new_bundle_store["id"], file=self.stdout)
-        elif args.command == 'ls':
-            bundle_stores = client.fetch('bundle_stores')
-            self.print_table(["id", "name", "storage_type", "storage_format"], bundle_stores)
-        elif args.command == 'rm':
-            client.delete('bundle_stores', resource_ids=[args.bundle_store_uuid])
-            print(args.bundle_store_uuid, file=self.stdout)
-        else:
-            raise UsageError(
-                f"cl store {args.command} is not supported. Only the following subcommands are supported: 'cl store add', 'cl store ls', 'cl store rm'."
-            )
+        with tracer.start_as_current_span(
+            "store", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client = self.manager.current_client()
+            if args.command == 'add':
+                bundle_store_info = {
+                    "name": args.name,
+                    "storage_type": args.storage_type,
+                    "storage_format": args.storage_format,
+                    "url": args.url,
+                    "authentication": args.authentication,
+                }
+                if args.url is not None:
+                    inferred_type = parse_linked_bundle_url(args.url).storage_type
+                    if args.storage_type is None:
+                        bundle_store_info["storage_type"] = inferred_type
+                    elif args.storage_type != inferred_type:
+                        raise UsageError(
+                            f"Bundle store {args.url} only supports storage type: {inferred_type}"
+                        )
+                new_bundle_store = client.create('bundle_stores', bundle_store_info)
+                print(new_bundle_store["id"], file=self.stdout)
+            elif args.command == 'ls':
+                bundle_stores = client.fetch('bundle_stores')
+                self.print_table(["id", "name", "storage_type", "storage_format"], bundle_stores)
+            elif args.command == 'rm':
+                client.delete('bundle_stores', resource_ids=[args.bundle_store_uuid])
+                print(args.bundle_store_uuid, file=self.stdout)
+            else:
+                raise UsageError(
+                    f"cl store {args.command} is not supported. Only the following subcommands are supported: 'cl store add', 'cl store ls', 'cl store rm'."
+                )
 
     @Commands.command('status', aliases=('st',), help='Show current client status.')
     def do_status_command(self, args):
-        client, worksheet_uuid = self.manager.get_current_worksheet_uuid()
-        worksheet_info = client.fetch('worksheets', worksheet_uuid)
+        with tracer.start_as_current_span(
+            "status", kind=trace.SpanKind.CLIENT,
+        ):
 
-        if not self.headless:
-            print("codalab_home: %s" % self.manager.codalab_home, file=self.stdout)
-            print("session: %s" % self.manager.session_name(), file=self.stdout)
-            address = self.manager.session()['address']
-            print("client_version: %s" % CODALAB_VERSION, file=self.stdout)
-            print("server_version: %s" % worksheet_info['meta']['version'], file=self.stdout)
-            print("address: %s" % address, file=self.stdout)
-            state = self.manager.state['auth'].get(address, {})
-            if 'username' in state:
-                print("username: %s" % state['username'], file=self.stdout)
-
-        print(
-            "current_worksheet: %s" % self.worksheet_url_and_name(worksheet_info), file=self.stdout
-        )
-        print("user: %s" % self.simple_user_str(client.fetch('user')), file=self.stdout)
+            client, worksheet_uuid = self.manager.get_current_worksheet_uuid()
+            worksheet_info = client.fetch('worksheets', worksheet_uuid)
+
+            if not self.headless:
+                print("codalab_home: %s" % self.manager.codalab_home, file=self.stdout)
+                print("session: %s" % self.manager.session_name(), file=self.stdout)
+                address = self.manager.session()['address']
+                print("client_version: %s" % CODALAB_VERSION, file=self.stdout)
+                print("server_version: %s" % worksheet_info['meta']['version'], file=self.stdout)
+                print("address: %s" % address, file=self.stdout)
+                state = self.manager.state['auth'].get(address, {})
+                if 'username' in state:
+                    print("username: %s" % state['username'], file=self.stdout)
+
+            print(
+                "current_worksheet: %s" % self.worksheet_url_and_name(worksheet_info),
+                file=self.stdout,
+            )
+            print("user: %s" % self.simple_user_str(client.fetch('user')), file=self.stdout)
 
     @Commands.command(
         'logout',
@@ -1109,13 +1126,17 @@ class BundleCLI(object):
         ),
     )
     def do_logout_command(self, args):
-        self._fail_if_headless(args)
-        if args.alias:
-            address = self.manager.apply_alias(args.alias)
-            self.manager.logout(address)
-        else:
-            client = self.manager.current_client()
-            self.manager.logout(client.address)
+        with tracer.start_as_current_span(
+            "logout", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            if args.alias:
+                address = self.manager.apply_alias(args.alias)
+                self.manager.logout(address)
+            else:
+                client = self.manager.current_client()
+                self.manager.logout(client.address)
 
     @Commands.command(
         'alias',
@@ -1140,23 +1161,28 @@ class BundleCLI(object):
         Show, add, modify, delete aliases (mappings from names to instances).
         Only modifies the CLI configuration, doesn't need a REST client.
         """
-        self._fail_if_headless(args)
-        aliases = self.manager.config['aliases']
-        if args.name:
-            instance = aliases.get(args.name)
-            if args.remove:
-                del aliases[args.name]
-                self.manager.save_config()
-            elif args.instance:
-                aliases[args.name] = args.instance
-                self.manager.save_config()
+        with tracer.start_as_current_span(
+            "alias", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            aliases = self.manager.config['aliases']
+            if args.name:
+                instance = aliases.get(args.name)
+                if args.remove:
+                    del aliases[args.name]
+                    self.manager.save_config()
+                elif args.instance:
+                    aliases[args.name] = args.instance
+                    self.manager.save_config()
+                else:
+                    print(
+                        args.name + ': ' + formatting.verbose_contents_str(instance),
+                        file=self.stdout,
+                    )
             else:
-                print(
-                    args.name + ': ' + formatting.verbose_contents_str(instance), file=self.stdout
-                )
-        else:
-            for name, instance in aliases.items():
-                print(name + ': ' + instance, file=self.stdout)
+                for name, instance in aliases.items():
+                    print(name + ': ' + instance, file=self.stdout)
 
     @Commands.command(
         'config',
@@ -1179,43 +1205,47 @@ class BundleCLI(object):
         """
         Only modifies the CLI configuration, doesn't need a REST client.
         """
-        self._fail_if_headless(args)
-        config = self.manager.config
-
-        # Suppose key = "a/b/c".
-
-        # Traverse "a/b" to the appropriate section of the config.
-        path = args.key.split('/')
-        for x in path[:-1]:
-            if x not in config:
-                config[x] = {}
-            config = config[x]
-
-        def auto_convert_type(value):
-            if value == 'true':
-                return True
-            if value == 'false':
-                return False
-            try:
-                return int(value)
-            except Exception:
-                pass
-            try:
-                return float(value)
-            except Exception:
-                pass
-            return value
-
-        # Set "c" to the value.
-        key = path[-1]
-        if args.remove:  # Remove key
-            del config[key]
-            self.manager.save_config()
-        if args.value:  # Modify value
-            config[key] = auto_convert_type(args.value)
-            self.manager.save_config()
-        else:  # Print out value
-            print(config[key])
+        with tracer.start_as_current_span(
+            "config", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            config = self.manager.config
+
+            # Suppose key = "a/b/c".
+
+            # Traverse "a/b" to the appropriate section of the config.
+            path = args.key.split('/')
+            for x in path[:-1]:
+                if x not in config:
+                    config[x] = {}
+                config = config[x]
+
+            def auto_convert_type(value):
+                if value == 'true':
+                    return True
+                if value == 'false':
+                    return False
+                try:
+                    return int(value)
+                except Exception:
+                    pass
+                try:
+                    return float(value)
+                except Exception:
+                    pass
+                return value
+
+            # Set "c" to the value.
+            key = path[-1]
+            if args.remove:  # Remove key
+                del config[key]
+                self.manager.save_config()
+            if args.value:  # Modify value
+                config[key] = auto_convert_type(args.value)
+                self.manager.save_config()
+            else:  # Print out value
+                print(config[key])
 
     @Commands.command(
         'workers',
@@ -1223,50 +1253,54 @@ class BundleCLI(object):
         arguments=(),
     )
     def do_workers_command(self, args):
-        client = self.manager.current_client()
-        raw_info = client.get_workers_info()
-        raw_info.sort(key=lambda r: r['worker_id'])
-
-        columns = [
-            'worker_id',
-            'cpus',
-            'gpus',
-            'memory',
-            'free_disk',
-            'last_checkin',
-            'group',
-            'tag',
-            'runs',
-            'shared_file_system',
-            'tag_exclusive',
-            'exit_after_num_runs',
-            'is_terminating',
-        ]
+        with tracer.start_as_current_span(
+            "workers", kind=trace.SpanKind.CLIENT,
+        ):
 
-        data = []
+            client = self.manager.current_client()
+            raw_info = client.get_workers_info()
+            raw_info.sort(key=lambda r: r['worker_id'])
+
+            columns = [
+                'worker_id',
+                'cpus',
+                'gpus',
+                'memory',
+                'free_disk',
+                'last_checkin',
+                'group',
+                'tag',
+                'runs',
+                'shared_file_system',
+                'tag_exclusive',
+                'exit_after_num_runs',
+                'is_terminating',
+            ]
 
-        for worker in raw_info:
-            data.append(
-                {
-                    'worker_id': worker['worker_id'],
-                    'cpus': '{}/{}'.format(worker['cpus_in_use'], worker['cpus']),
-                    'gpus': '{}/{}'.format(worker['gpus_in_use'], worker['gpus']),
-                    'memory': formatting.size_str(worker['memory_bytes']),
-                    'free_disk': formatting.size_str(worker['free_disk_bytes']),
-                    'last_checkin': '{} ago'.format(
-                        formatting.duration_str(int(time.time()) - worker['checkin_time'])
-                    ),
-                    'group': worker['group_uuid'],
-                    'tag': worker['tag'],
-                    'runs': ",".join([uuid[0:8] for uuid in worker['run_uuids']]),
-                    'shared_file_system': worker['shared_file_system'],
-                    'tag_exclusive': worker['tag_exclusive'],
-                    'exit_after_num_runs': worker['exit_after_num_runs'],
-                    'is_terminating': worker['is_terminating'],
-                }
-            )
+            data = []
+
+            for worker in raw_info:
+                data.append(
+                    {
+                        'worker_id': worker['worker_id'],
+                        'cpus': '{}/{}'.format(worker['cpus_in_use'], worker['cpus']),
+                        'gpus': '{}/{}'.format(worker['gpus_in_use'], worker['gpus']),
+                        'memory': formatting.size_str(worker['memory_bytes']),
+                        'free_disk': formatting.size_str(worker['free_disk_bytes']),
+                        'last_checkin': '{} ago'.format(
+                            formatting.duration_str(int(time.time()) - worker['checkin_time'])
+                        ),
+                        'group': worker['group_uuid'],
+                        'tag': worker['tag'],
+                        'runs': ",".join([uuid[0:8] for uuid in worker['run_uuids']]),
+                        'shared_file_system': worker['shared_file_system'],
+                        'tag_exclusive': worker['tag_exclusive'],
+                        'exit_after_num_runs': worker['exit_after_num_runs'],
+                        'is_terminating': worker['is_terminating'],
+                    }
+                )
 
-        self.print_table(columns, data)
+            self.print_table(columns, data)
 
     @Commands.command(
         'upload',
@@ -1348,150 +1382,161 @@ class BundleCLI(object):
         + EDIT_ARGUMENTS,
     )
     def do_upload_command(self, args):
-        from codalab.lib import zip_util
-
-        if args.contents is None and not args.path:
-            raise UsageError("Nothing to upload.")
-
-        if args.contents is not None and args.path:
-            raise UsageError(
-                "Upload does not support mixing content strings and paths(local files and URLs)."
-            )
-
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "upload", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Build bundle info
-        metadata = self.get_missing_metadata(UploadedBundle, args, initial_metadata={})
-        if args.contents is not None and metadata['name'] is None:
-            metadata['name'] = 'contents'
-        if not args.pack and zip_util.path_is_archive(metadata['name']):
-            # name = 'test.zip' => name = 'test'
-            metadata['name'] = zip_util.strip_archive_ext(metadata['name'])
-        bundle_info = {
-            'bundle_type': 'dataset',  # TODO: deprecate Dataset and ProgramBundles
-            'metadata': metadata,
-        }
+            from codalab.lib import zip_util
 
-        # Option 1: --link
-        if args.link:
-            if len(args.path) != 1:
-                raise UsageError("Only a single path can be uploaded when using --link.")
-            # If link_url is a relative path, prepend the current working directory to it.
-            bundle_info['metadata']['link_url'] = (
-                args.path[0]
-                if os.path.isabs(args.path[0])
-                else os.path.join(os.getcwd(), args.path[0])
-            )
-            bundle_info['metadata']['link_format'] = LinkFormat.RAW
+            if args.contents is None and not args.path:
+                raise UsageError("Nothing to upload.")
 
-            new_bundle = client.create('bundles', bundle_info, params={'worksheet': worksheet_uuid})
+            if args.contents is not None and args.path:
+                raise UsageError(
+                    "Upload does not support mixing content strings and paths(local files and URLs)."
+                )
 
-        # Option 2: Upload contents string
-        elif args.contents is not None:
-            contents_buffer = BytesIO(args.contents.encode())
-            new_bundle = client.create('bundles', bundle_info, params={'worksheet': worksheet_uuid})
-            client.upload_contents_blob(
-                new_bundle['id'],
-                fileobj=contents_buffer,
-                params={
-                    'filename': 'contents',
-                    'unpack': False,
-                    'state_on_success': State.READY,
-                    'finalize_on_success': True,
-                    'use_azure_blob_beta': args.use_azure_blob_beta,
-                    'store': metadata.get('store') or '',
-                },
-            )
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+
+            # Build bundle info
+            metadata = self.get_missing_metadata(UploadedBundle, args, initial_metadata={})
+            if args.contents is not None and metadata['name'] is None:
+                metadata['name'] = 'contents'
+            if not args.pack and zip_util.path_is_archive(metadata['name']):
+                # name = 'test.zip' => name = 'test'
+                metadata['name'] = zip_util.strip_archive_ext(metadata['name'])
+            bundle_info = {
+                'bundle_type': 'dataset',  # TODO: deprecate Dataset and ProgramBundles
+                'metadata': metadata,
+            }
 
-        # Option 3: Upload URL(s)
-        elif any(map(path_util.path_is_url, args.path)):
-            if not all(map(path_util.path_is_url, args.path)):
-                raise UsageError("URLs and local files cannot be uploaded in the same bundle.")
-            if len(args.path) > 1:
-                raise UsageError("Only one URL can be specified at a time.")
-            bundle_info['metadata']['source_url'] = str(args.path)
-
-            new_bundle = client.create('bundles', bundle_info, params={'worksheet': worksheet_uuid})
-            client.upload_contents_blob(
-                new_bundle['id'],
-                params={
-                    'urls': args.path,
-                    'git': args.git,
-                    'state_on_success': State.READY,
-                    'finalize_on_success': True,
-                    'use_azure_blob_beta': args.use_azure_blob_beta,
-                    'store': metadata.get('store') or '',
-                },
-            )
+            # Option 1: --link
+            if args.link:
+                if len(args.path) != 1:
+                    raise UsageError("Only a single path can be uploaded when using --link.")
+                # If link_url is a relative path, prepend the current working directory to it.
+                bundle_info['metadata']['link_url'] = (
+                    args.path[0]
+                    if os.path.isabs(args.path[0])
+                    else os.path.join(os.getcwd(), args.path[0])
+                )
+                bundle_info['metadata']['link_format'] = LinkFormat.RAW
 
-        # Option 4: Upload file(s) from the local filesystem
-        else:
-            if self.headless:
-                raise UsageError("Local file paths not allowed without a filesystem.")
-            # Check that the upload paths exist
-            for path in args.path:
-                path_util.check_isvalid(path_util.normalize(path), 'upload')
-
-            # Canonicalize paths (e.g., removing trailing /)
-            sources = [path_util.normalize(path) for path in args.path]
-            # Calculate size of sources
-            total_bundle_size = sum([get_path_size(source) for source in sources])
-            user = client.fetch('user')
-            disk_left = user['disk_quota'] - user['disk_used']
-            if disk_left - total_bundle_size <= 0:
-                raise DiskQuotaExceededError(
-                    'Attempted to upload bundle of size %s with only %s remaining in user\'s disk quota.'
-                    % (formatting.size_str(total_bundle_size), formatting.size_str(disk_left))
+                new_bundle = client.create(
+                    'bundles', bundle_info, params={'worksheet': worksheet_uuid}
                 )
 
-            print("Preparing upload archive...", file=self.stderr)
-            if args.ignore:
-                print(
-                    "Excluding files and directories specified by %s." % args.ignore,
-                    file=self.stderr,
+            # Option 2: Upload contents string
+            elif args.contents is not None:
+                contents_buffer = BytesIO(args.contents.encode())
+                new_bundle = client.create(
+                    'bundles', bundle_info, params={'worksheet': worksheet_uuid}
+                )
+                client.upload_contents_blob(
+                    new_bundle['id'],
+                    fileobj=contents_buffer,
+                    params={
+                        'filename': 'contents',
+                        'unpack': False,
+                        'state_on_success': State.READY,
+                        'finalize_on_success': True,
+                        'use_azure_blob_beta': args.use_azure_blob_beta,
+                        'store': metadata.get('store') or '',
+                    },
                 )
 
-            packed = zip_util.pack_files_for_upload(
-                sources,
-                should_unpack=(not args.pack),
-                follow_symlinks=args.follow_symlinks,
-                exclude_patterns=args.exclude_patterns,
-                force_compression=args.force_compression,
-                ignore_file=args.ignore,
-            )
+            # Option 3: Upload URL(s)
+            elif any(map(path_util.path_is_url, args.path)):
+                if not all(map(path_util.path_is_url, args.path)):
+                    raise UsageError("URLs and local files cannot be uploaded in the same bundle.")
+                if len(args.path) > 1:
+                    raise UsageError("Only one URL can be specified at a time.")
+                bundle_info['metadata']['source_url'] = str(args.path)
 
-            # Create bundle.
-            # We must create the bundle right before we upload it because we
-            # perform some input validation in functions such as
-            # zip_util.pack_files_for_upload that we want to fail fast before
-            # we try to create or upload the bundle, otherwise you will be left
-            # with empty shells of failed uploading bundles on your worksheet.
-            new_bundle = client.create(
-                'bundles',
-                bundle_info,
-                params={'worksheet': worksheet_uuid, 'wait_for_upload': True},
-            )
-            print(
-                'Uploading %s (%s) to %s' % (packed['filename'], new_bundle['id'], client.address),
-                file=self.stderr,
-            )
-            progress = FileTransferProgress('Sent ', packed['filesize'], f=self.stderr)
-            with closing(packed['fileobj']), progress:
+                new_bundle = client.create(
+                    'bundles', bundle_info, params={'worksheet': worksheet_uuid}
+                )
                 client.upload_contents_blob(
                     new_bundle['id'],
-                    fileobj=packed['fileobj'],
                     params={
-                        'filename': packed['filename'],
-                        'unpack': packed['should_unpack'],
+                        'urls': args.path,
+                        'git': args.git,
                         'state_on_success': State.READY,
                         'finalize_on_success': True,
                         'use_azure_blob_beta': args.use_azure_blob_beta,
                         'store': metadata.get('store') or '',
                     },
-                    progress_callback=progress.update,
                 )
 
-        print(new_bundle['id'], file=self.stdout)
+            # Option 4: Upload file(s) from the local filesystem
+            else:
+                if self.headless:
+                    raise UsageError("Local file paths not allowed without a filesystem.")
+                # Check that the upload paths exist
+                for path in args.path:
+                    path_util.check_isvalid(path_util.normalize(path), 'upload')
+
+                # Canonicalize paths (e.g., removing trailing /)
+                sources = [path_util.normalize(path) for path in args.path]
+                # Calculate size of sources
+                total_bundle_size = sum([get_path_size(source) for source in sources])
+                user = client.fetch('user')
+                disk_left = user['disk_quota'] - user['disk_used']
+                if disk_left - total_bundle_size <= 0:
+                    raise DiskQuotaExceededError(
+                        'Attempted to upload bundle of size %s with only %s remaining in user\'s disk quota.'
+                        % (formatting.size_str(total_bundle_size), formatting.size_str(disk_left))
+                    )
+
+                print("Preparing upload archive...", file=self.stderr)
+                if args.ignore:
+                    print(
+                        "Excluding files and directories specified by %s." % args.ignore,
+                        file=self.stderr,
+                    )
+
+                packed = zip_util.pack_files_for_upload(
+                    sources,
+                    should_unpack=(not args.pack),
+                    follow_symlinks=args.follow_symlinks,
+                    exclude_patterns=args.exclude_patterns,
+                    force_compression=args.force_compression,
+                    ignore_file=args.ignore,
+                )
+
+                # Create bundle.
+                # We must create the bundle right before we upload it because we
+                # perform some input validation in functions such as
+                # zip_util.pack_files_for_upload that we want to fail fast before
+                # we try to create or upload the bundle, otherwise you will be left
+                # with empty shells of failed uploading bundles on your worksheet.
+                new_bundle = client.create(
+                    'bundles',
+                    bundle_info,
+                    params={'worksheet': worksheet_uuid, 'wait_for_upload': True},
+                )
+                print(
+                    'Uploading %s (%s) to %s'
+                    % (packed['filename'], new_bundle['id'], client.address),
+                    file=self.stderr,
+                )
+                progress = FileTransferProgress('Sent ', packed['filesize'], f=self.stderr)
+                with closing(packed['fileobj']), progress:
+                    client.upload_contents_blob(
+                        new_bundle['id'],
+                        fileobj=packed['fileobj'],
+                        params={
+                            'filename': packed['filename'],
+                            'unpack': packed['should_unpack'],
+                            'state_on_success': State.READY,
+                            'finalize_on_success': True,
+                            'use_azure_blob_beta': args.use_azure_blob_beta,
+                            'store': metadata.get('store') or '',
+                        },
+                        progress_callback=progress.update,
+                    )
+
+            print(new_bundle['id'], file=self.stdout)
 
     @Commands.command(
         'download',
@@ -1519,53 +1564,60 @@ class BundleCLI(object):
         ),
     )
     def do_download_command(self, args):
-        self._fail_if_headless(args)
+        with tracer.start_as_current_span(
+            "download", kind=trace.SpanKind.CLIENT,
+        ):
 
-        default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
-            args.worksheet_spec
-        )
-        client, worksheet_uuid, target = self.resolve_target(
-            default_client, default_worksheet_uuid, args.target_spec
-        )
+            self._fail_if_headless(args)
 
-        # Figure out where to download.
-        info = client.fetch('bundles', target.bundle_uuid)
-        if args.output_path:
-            local_path = args.output_path
-        else:
-            local_path = (
-                nested_dict_get(info, 'metadata', 'name', default='untitled')
-                if target.subpath == ''
-                else os.path.basename(target.subpath)
+            default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
+                args.worksheet_spec
             )
-        final_path = os.path.join(os.getcwd(), local_path)
-        if os.path.exists(final_path):
-            if args.force:
-                shutil.rmtree(final_path)
+            client, worksheet_uuid, target = self.resolve_target(
+                default_client, default_worksheet_uuid, args.target_spec
+            )
+
+            # Figure out where to download.
+            info = client.fetch('bundles', target.bundle_uuid)
+            if args.output_path:
+                local_path = args.output_path
             else:
-                print('Local file/directory \'%s\' already exists.' % local_path, file=self.stdout)
-                return
+                local_path = (
+                    nested_dict_get(info, 'metadata', 'name', default='untitled')
+                    if target.subpath == ''
+                    else os.path.basename(target.subpath)
+                )
+            final_path = os.path.join(os.getcwd(), local_path)
+            if os.path.exists(final_path):
+                if args.force:
+                    shutil.rmtree(final_path)
+                else:
+                    print(
+                        'Local file/directory \'%s\' already exists.' % local_path, file=self.stdout
+                    )
+                    return
 
-        # Do the download.
-        target_info = client.fetch_contents_info(target, 0)
-        if target_info['type'] == 'link':
-            raise UsageError('Downloading symlinks is not allowed.')
+            # Do the download.
+            target_info = client.fetch_contents_info(target, 0)
+            if target_info['type'] == 'link':
+                raise UsageError('Downloading symlinks is not allowed.')
 
-        print(
-            'Downloading %s/%s => %s' % (self.simple_bundle_str(info), target.subpath, final_path),
-            file=self.stdout,
-        )
+            print(
+                'Downloading %s/%s => %s'
+                % (self.simple_bundle_str(info), target.subpath, final_path),
+                file=self.stdout,
+            )
 
-        progress = FileTransferProgress('Received ', f=self.stderr)
-        contents = file_util.tracked(
-            client.fetch_contents_blob(target_info['resolved_target']), progress.update
-        )
-        with progress, closing(contents):
-            if target_info['type'] == 'directory':
-                un_tar_directory(contents, final_path, 'gz', force=args.force)
-            elif target_info['type'] == 'file':
-                with open(final_path, 'wb') as out:
-                    shutil.copyfileobj(contents, out)
+            progress = FileTransferProgress('Received ', f=self.stderr)
+            contents = file_util.tracked(
+                client.fetch_contents_blob(target_info['resolved_target']), progress.update
+            )
+            with progress, closing(contents):
+                if target_info['type'] == 'directory':
+                    un_tar_directory(contents, final_path, 'gz', force=args.force)
+                elif target_info['type'] == 'file':
+                    with open(final_path, 'wb') as out:
+                        shutil.copyfileobj(contents, out)
 
     def copy_bundle(
         self,
@@ -1717,18 +1769,22 @@ class BundleCLI(object):
         + EDIT_ARGUMENTS,
     )
     def do_make_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        targets = self.resolve_key_targets(client, worksheet_uuid, args.target_spec)
-        # Support anonymous make calls by replacing None keys with ''
-        targets = [('' if key is None else key, val) for key, val in targets]
-        metadata = self.get_missing_metadata(MakeBundle, args)
-        new_bundle = client.create(
-            'bundles',
-            self.derive_bundle(MakeBundle.BUNDLE_TYPE, None, targets, metadata),
-            params={'worksheet': worksheet_uuid},
-        )
+        with tracer.start_as_current_span(
+            "make", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            targets = self.resolve_key_targets(client, worksheet_uuid, args.target_spec)
+            # Support anonymous make calls by replacing None keys with ''
+            targets = [('' if key is None else key, val) for key, val in targets]
+            metadata = self.get_missing_metadata(MakeBundle, args)
+            new_bundle = client.create(
+                'bundles',
+                self.derive_bundle(MakeBundle.BUNDLE_TYPE, None, targets, metadata),
+                params={'worksheet': worksheet_uuid},
+            )
 
-        print(new_bundle['uuid'], file=self.stdout)
+            print(new_bundle['uuid'], file=self.stdout)
 
     def wait(self, client, args, uuid):
         """Wait for a run bundle to finish. Called by run and mimic."""
@@ -1807,70 +1863,79 @@ class BundleCLI(object):
         + WAIT_ARGUMENTS,
     )
     def do_run_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        args.target_spec, args.command = desugar_command(args.target_spec, args.command)
-        metadata = self.get_missing_metadata(RunBundle, args)
-        targets = self.resolve_key_targets(client, worksheet_uuid, args.target_spec)
-
-        if args.interactive:
-            from codalab.lib.interactive_session import InteractiveSession
-
-            # Disable cl run --interactive on headless systems
-            self._fail_if_headless(args)
-
-            # Fetch bundle locations from the server
-            bundle_uuids = [bundle_target.bundle_uuid for _, bundle_target in targets]
-            bundles_locations = client.get_bundles_locations(bundle_uuids)
-
-            docker_image = metadata.get('request_docker_image', None)
-            if not docker_image:
-                # If a Docker image is not specified, use the default CPU worker image for the interactive session
-                docker_image = self.manager.config['workers']['default_cpu_image']
+        with tracer.start_as_current_span(
+            "run", kind=trace.SpanKind.CLIENT,
+        ):
 
-            # Start an interactive session to allow users to figure out the command to run
-            session = InteractiveSession(
-                docker_image, args.command, self.manager, targets, bundles_locations, args.verbose
-            )
-            command = session.start()
-            session.cleanup()
-        else:
-            command = args.command
-
-        if not command:
-            raise UsageError('The command cannot be empty.')
-
-        params = {'worksheet': worksheet_uuid}
-        if args.after_sort_key:
-            params['after_sort_key'] = args.after_sort_key
-        if args.memoize:
-            dependencies = [
-                {'child_path': key, 'parent_uuid': bundle_target.bundle_uuid}
-                for key, bundle_target in targets
-            ]
-            # A list of matched uuids in the order they were created.
-            memoized_bundles = client.fetch(
-                'bundles', params={'command': command, 'dependencies': json.dumps(dependencies)}
-            )
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            args.target_spec, args.command = desugar_command(args.target_spec, args.command)
+            metadata = self.get_missing_metadata(RunBundle, args)
+            targets = self.resolve_key_targets(client, worksheet_uuid, args.target_spec)
+
+            if args.interactive:
+                from codalab.lib.interactive_session import InteractiveSession
+
+                # Disable cl run --interactive on headless systems
+                self._fail_if_headless(args)
+
+                # Fetch bundle locations from the server
+                bundle_uuids = [bundle_target.bundle_uuid for _, bundle_target in targets]
+                bundles_locations = client.get_bundles_locations(bundle_uuids)
+
+                docker_image = metadata.get('request_docker_image', None)
+                if not docker_image:
+                    # If a Docker image is not specified, use the default CPU worker image for the interactive session
+                    docker_image = self.manager.config['workers']['default_cpu_image']
+
+                # Start an interactive session to allow users to figure out the command to run
+                session = InteractiveSession(
+                    docker_image,
+                    args.command,
+                    self.manager,
+                    targets,
+                    bundles_locations,
+                    args.verbose,
+                )
+                command = session.start()
+                session.cleanup()
+            else:
+                command = args.command
+
+            if not command:
+                raise UsageError('The command cannot be empty.')
+
+            params = {'worksheet': worksheet_uuid}
+            if args.after_sort_key:
+                params['after_sort_key'] = args.after_sort_key
+            if args.memoize:
+                dependencies = [
+                    {'child_path': key, 'parent_uuid': bundle_target.bundle_uuid}
+                    for key, bundle_target in targets
+                ]
+                # A list of matched uuids in the order they were created.
+                memoized_bundles = client.fetch(
+                    'bundles', params={'command': command, 'dependencies': json.dumps(dependencies)}
+                )
 
-        if args.memoize and len(memoized_bundles) > 0:
-            new_bundle = memoized_bundles[-1]
-            print(new_bundle['uuid'], file=self.stdout)
-            self.copy_bundle(
-                source_client=client,
-                source_bundle_uuid=new_bundle['uuid'],
-                dest_client=client,
-                dest_worksheet_uuid=worksheet_uuid,
-                copy_dependencies=False,
-                add_to_worksheet=True,
-            )
-        else:
-            new_bundle = client.create(
-                'bundles',
-                self.derive_bundle(RunBundle.BUNDLE_TYPE, command, targets, metadata),
-                params=params,
-            )
-            print(new_bundle['uuid'], file=self.stdout)
-            self.wait(client, args, new_bundle['uuid'])
+            if args.memoize and len(memoized_bundles) > 0:
+                new_bundle = memoized_bundles[-1]
+                print(new_bundle['uuid'], file=self.stdout)
+                self.copy_bundle(
+                    source_client=client,
+                    source_bundle_uuid=new_bundle['uuid'],
+                    dest_client=client,
+                    dest_worksheet_uuid=worksheet_uuid,
+                    copy_dependencies=False,
+                    add_to_worksheet=True,
+                )
+            else:
+                new_bundle = client.create(
+                    'bundles',
+                    self.derive_bundle(RunBundle.BUNDLE_TYPE, command, targets, metadata),
+                    params=params,
+                )
+                print(new_bundle['uuid'], file=self.stdout)
+                self.wait(client, args, new_bundle['uuid'])
 
     @Commands.command(
         'edit',
@@ -1931,44 +1996,48 @@ class BundleCLI(object):
         ),
     )
     def do_edit_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "edit", kind=trace.SpanKind.CLIENT,
+        ):
 
-        info = client.fetch_one(
-            'bundles', params={'specs': args.bundle_spec, 'worksheet': worksheet_uuid}
-        )
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        bundle_subclass = get_bundle_subclass(info['bundle_type'])
-
-        metadata_update = {}
-        bundle_update = {}
-        if args.name:
-            metadata_update['name'] = args.name
-        if args.description:
-            metadata_update['description'] = args.description
-        if args.tags:
-            metadata_update['tags'] = args.tags
-        if args.anonymous is not None:
-            bundle_update['is_anonymous'] = args.anonymous
-        if args.freeze:
-            bundle_update['frozen'] = datetime.datetime.utcnow().isoformat()
-        if args.unfreeze:
-            bundle_update['frozen'] = None
-        if args.field:
-            metadata_update[args.field[0]] = args.field[1]
-
-        # Prompt user for edits via an editor when no edits provided by command line options
-        if not self.headless and not metadata_update and not bundle_update:
-            metadata_update = metadata_util.request_missing_metadata(
-                bundle_subclass, info['metadata']
+            info = client.fetch_one(
+                'bundles', params={'specs': args.bundle_spec, 'worksheet': worksheet_uuid}
             )
 
-        if bundle_update or metadata_update:
-            bundle_update.update({'id': info['id'], 'bundle_type': info['bundle_type']})
-            if metadata_update:
-                bundle_update['metadata'] = metadata_update
+            bundle_subclass = get_bundle_subclass(info['bundle_type'])
+
+            metadata_update = {}
+            bundle_update = {}
+            if args.name:
+                metadata_update['name'] = args.name
+            if args.description:
+                metadata_update['description'] = args.description
+            if args.tags:
+                metadata_update['tags'] = args.tags
+            if args.anonymous is not None:
+                bundle_update['is_anonymous'] = args.anonymous
+            if args.freeze:
+                bundle_update['frozen'] = datetime.datetime.utcnow().isoformat()
+            if args.unfreeze:
+                bundle_update['frozen'] = None
+            if args.field:
+                metadata_update[args.field[0]] = args.field[1]
+
+            # Prompt user for edits via an editor when no edits provided by command line options
+            if not self.headless and not metadata_update and not bundle_update:
+                metadata_update = metadata_util.request_missing_metadata(
+                    bundle_subclass, info['metadata']
+                )
+
+            if bundle_update or metadata_update:
+                bundle_update.update({'id': info['id'], 'bundle_type': info['bundle_type']})
+                if metadata_update:
+                    bundle_update['metadata'] = metadata_update
 
-            client.update('bundles', bundle_update)
-            print("Saved metadata for bundle %s." % (info['id']), file=self.stdout)
+                client.update('bundles', bundle_update)
+                print("Saved metadata for bundle %s." % (info['id']), file=self.stdout)
 
     @Commands.command(
         'detach',
@@ -1997,59 +2066,66 @@ class BundleCLI(object):
         Removes the given bundles from the given worksheet (but importantly
         doesn't delete the actual bundles, unlike rm).
         """
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+        with tracer.start_as_current_span(
+            "detach", kind=trace.SpanKind.CLIENT,
+        ):
 
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        # Resolve all the bundles first, then detach.
-        # This is important since some of the bundle specs (^1 ^2) are relative.
-        bundle_uuids = self.target_specs_to_bundle_uuids(client, worksheet_uuid, args.bundle_spec)
-        worksheet_info = client.fetch(
-            'worksheets', worksheet_uuid, params={'include': ['items', 'items.bundle']}
-        )
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
 
-        # Number the bundles: c c a b c => 3 2 1 1 1
-        items = worksheet_info['items']
-        indices = [None] * len(
-            items
-        )  # Parallel array to items that stores the index associated with that bundle uuid
-        uuid2index = (
-            {}
-        )  # bundle uuid => index of the bundle (at the end, number of times it occurs on the worksheet)
-        for i, item in reversed(list(enumerate(items))):
-            if item['type'] == worksheet_util.TYPE_BUNDLE:
-                uuid = item['bundle']['id']
-                indices[i] = uuid2index[uuid] = uuid2index.get(uuid, 0) + 1
-
-        # Detach the items.
-        new_items = []
-        for i, item in enumerate(items):
-            detach = False
-            if item['type'] == worksheet_util.TYPE_BUNDLE:
-                uuid = item['bundle']['id']
-                # If want to detach uuid, then make sure we're detaching the
-                # right index or if the index is not specified, that it's
-                # unique.
-                if uuid in bundle_uuids:
-                    if args.index is None:
-                        if uuid2index[uuid] != 1:
-                            raise UsageError(
-                                'bundle %s shows up more than once, need to specify index' % uuid
-                            )
-                        detach = True
-                    else:
-                        if args.index > uuid2index[uuid]:
-                            raise UsageError(
-                                'bundle %s shows up %d times, can\'t get index %d'
-                                % (uuid, uuid2index[uuid], args.index)
-                            )
-                        if args.index == indices[i]:
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            # Resolve all the bundles first, then detach.
+            # This is important since some of the bundle specs (^1 ^2) are relative.
+            bundle_uuids = self.target_specs_to_bundle_uuids(
+                client, worksheet_uuid, args.bundle_spec
+            )
+            worksheet_info = client.fetch(
+                'worksheets', worksheet_uuid, params={'include': ['items', 'items.bundle']}
+            )
+
+            # Number the bundles: c c a b c => 3 2 1 1 1
+            items = worksheet_info['items']
+            indices = [None] * len(
+                items
+            )  # Parallel array to items that stores the index associated with that bundle uuid
+            uuid2index = (
+                {}
+            )  # bundle uuid => index of the bundle (at the end, number of times it occurs on the worksheet)
+            for i, item in reversed(list(enumerate(items))):
+                if item['type'] == worksheet_util.TYPE_BUNDLE:
+                    uuid = item['bundle']['id']
+                    indices[i] = uuid2index[uuid] = uuid2index.get(uuid, 0) + 1
+
+            # Detach the items.
+            new_items = []
+            for i, item in enumerate(items):
+                detach = False
+                if item['type'] == worksheet_util.TYPE_BUNDLE:
+                    uuid = item['bundle']['id']
+                    # If want to detach uuid, then make sure we're detaching the
+                    # right index or if the index is not specified, that it's
+                    # unique.
+                    if uuid in bundle_uuids:
+                        if args.index is None:
+                            if uuid2index[uuid] != 1:
+                                raise UsageError(
+                                    'bundle %s shows up more than once, need to specify index'
+                                    % uuid
+                                )
                             detach = True
-            if not detach:
-                new_items.append(item)
+                        else:
+                            if args.index > uuid2index[uuid]:
+                                raise UsageError(
+                                    'bundle %s shows up %d times, can\'t get index %d'
+                                    % (uuid, uuid2index[uuid], args.index)
+                                )
+                            if args.index == indices[i]:
+                                detach = True
+                if not detach:
+                    new_items.append(item)
 
-        client.create(
-            'worksheet-items', data=new_items, params={'replace': True, 'uuid': worksheet_uuid}
-        )
+            client.create(
+                'worksheet-items', data=new_items, params={'replace': True, 'uuid': worksheet_uuid}
+            )
 
     @Commands.command(
         'rm',
@@ -2096,32 +2172,40 @@ class BundleCLI(object):
         ),
     )
     def do_rm_command(self, args):
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        # Resolve all the bundles first, then delete.
-        # This is important since some of the bundle specs (^1 ^2) are relative.
-        bundle_uuids = self.target_specs_to_bundle_uuids(client, worksheet_uuid, args.bundle_spec)
-        deleted_uuids = client.delete(
-            'bundles',
-            bundle_uuids,
-            params={
-                'force': args.force,
-                'recursive': args.recursive,
-                'data-only': args.data_only,
-                'dry-run': args.dry_run,
-            },
-        )['meta']['ids']
+        with tracer.start_as_current_span(
+            "rm", kind=trace.SpanKind.CLIENT,
+        ):
 
-        if args.dry_run:
-            bundles = client.fetch('bundles', params={'specs': deleted_uuids, 'include': ['owner']})
-            print(
-                'This command would permanently remove the following bundles (not doing so yet):',
-                file=self.stdout,
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            # Resolve all the bundles first, then delete.
+            # This is important since some of the bundle specs (^1 ^2) are relative.
+            bundle_uuids = self.target_specs_to_bundle_uuids(
+                client, worksheet_uuid, args.bundle_spec
             )
-            self.print_bundle_info_list(bundles, uuid_only=False, print_ref=False)
-        else:
-            for uuid in deleted_uuids:
-                print(uuid, file=self.stdout)
+            deleted_uuids = client.delete(
+                'bundles',
+                bundle_uuids,
+                params={
+                    'force': args.force,
+                    'recursive': args.recursive,
+                    'data-only': args.data_only,
+                    'dry-run': args.dry_run,
+                },
+            )['meta']['ids']
+
+            if args.dry_run:
+                bundles = client.fetch(
+                    'bundles', params={'specs': deleted_uuids, 'include': ['owner']}
+                )
+                print(
+                    'This command would permanently remove the following bundles (not doing so yet):',
+                    file=self.stdout,
+                )
+                self.print_bundle_info_list(bundles, uuid_only=False, print_ref=False)
+            else:
+                for uuid in deleted_uuids:
+                    print(uuid, file=self.stdout)
 
     @Commands.command(
         'search',
@@ -2184,48 +2268,56 @@ class BundleCLI(object):
         ),
     )
     def do_search_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-
-        bundles = client.fetch(
-            'bundles',
-            params={'worksheet': worksheet_uuid, 'keywords': args.keywords, 'include': ['owner']},
-        )
-
-        # Print direct numeric result
-        if 'meta' in bundles:
-            print(bundles['meta']['result'], file=self.stdout)
-            return
+        with tracer.start_as_current_span(
+            "search", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Print table
-        if len(bundles) > 0:
-            self.print_bundle_info_list(
-                bundles, uuid_only=args.uuid_only, print_ref=False, fields=args.field.split(",")
-            )
-        elif not args.uuid_only:
-            print(NO_RESULTS_FOUND, file=self.stderr)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        # Add the bundles to the current worksheet
-        if args.append:
-            client.create(
-                'worksheet-items',
-                data=[
-                    {
-                        'worksheet': JsonApiRelationship('worksheets', worksheet_uuid),
-                        'bundle': JsonApiRelationship('bundles', bundle['uuid']),
-                        'type': worksheet_util.TYPE_BUNDLE,
-                    }
-                    for bundle in bundles
-                ],
-                params={'uuid': worksheet_uuid},
-            )
-            worksheet_info = client.fetch('worksheets', worksheet_uuid)
-            print(
-                'Added %d bundles to %s'
-                % (len(bundles), self.worksheet_url_and_name(worksheet_info)),
-                file=self.stdout,
+            bundles = client.fetch(
+                'bundles',
+                params={
+                    'worksheet': worksheet_uuid,
+                    'keywords': args.keywords,
+                    'include': ['owner'],
+                },
             )
 
-        return {'refs': self.create_reference_map('bundle', bundles)}
+            # Print direct numeric result
+            if 'meta' in bundles:
+                print(bundles['meta']['result'], file=self.stdout)
+                return
+
+            # Print table
+            if len(bundles) > 0:
+                self.print_bundle_info_list(
+                    bundles, uuid_only=args.uuid_only, print_ref=False, fields=args.field.split(",")
+                )
+            elif not args.uuid_only:
+                print(NO_RESULTS_FOUND, file=self.stderr)
+
+            # Add the bundles to the current worksheet
+            if args.append:
+                client.create(
+                    'worksheet-items',
+                    data=[
+                        {
+                            'worksheet': JsonApiRelationship('worksheets', worksheet_uuid),
+                            'bundle': JsonApiRelationship('bundles', bundle['uuid']),
+                            'type': worksheet_util.TYPE_BUNDLE,
+                        }
+                        for bundle in bundles
+                    ],
+                    params={'uuid': worksheet_uuid},
+                )
+                worksheet_info = client.fetch('worksheets', worksheet_uuid)
+                print(
+                    'Added %d bundles to %s'
+                    % (len(bundles), self.worksheet_url_and_name(worksheet_info)),
+                    file=self.stdout,
+                )
+
+            return {'refs': self.create_reference_map('bundle', bundles)}
 
     def create_reference_map(self, info_type, info_list):
         """
@@ -2264,29 +2356,33 @@ class BundleCLI(object):
         ),
     )
     def do_ls_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        worksheet_info = client.fetch(
-            'worksheets',
-            worksheet_uuid,
-            params={
-                'include': [
-                    'owner',
-                    'group_permissions',
-                    'items',
-                    'items.bundle',
-                    'items.bundle.owner',
-                ]
-            },
-        )
-        if not args.uuid_only:
-            print(self._worksheet_description(worksheet_info), file=self.stdout)
-        bundle_info_list = [
-            item['bundle'] for item in worksheet_info['items'] if item['type'] == 'bundle'
-        ]
-        self.print_bundle_info_list(
-            bundle_info_list, args.uuid_only, print_ref=True, fields=args.field.split(",")
-        )
-        return {'refs': self.create_reference_map('bundle', bundle_info_list)}
+        with tracer.start_as_current_span(
+            "ls", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            worksheet_info = client.fetch(
+                'worksheets',
+                worksheet_uuid,
+                params={
+                    'include': [
+                        'owner',
+                        'group_permissions',
+                        'items',
+                        'items.bundle',
+                        'items.bundle.owner',
+                    ]
+                },
+            )
+            if not args.uuid_only:
+                print(self._worksheet_description(worksheet_info), file=self.stdout)
+            bundle_info_list = [
+                item['bundle'] for item in worksheet_info['items'] if item['type'] == 'bundle'
+            ]
+            self.print_bundle_info_list(
+                bundle_info_list, args.uuid_only, print_ref=True, fields=args.field.split(",")
+            )
+            return {'refs': self.create_reference_map('bundle', bundle_info_list)}
 
     def _worksheet_description(self, worksheet_info):
         fields = [
@@ -2367,46 +2463,54 @@ class BundleCLI(object):
         ),
     )
     def do_info_command(self, args):
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "info", kind=trace.SpanKind.CLIENT,
+        ):
 
-        bundles = client.fetch(
-            'bundles',
-            params={
-                'specs': args.bundle_spec,
-                'worksheet': worksheet_uuid,
-                'include': ['owner']
-                + (['children', 'group_permissions', 'host_worksheets'] if args.verbose else []),
-            },
-        )
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        for i, info in enumerate(bundles):
-            if args.field:
-                # Display individual fields (arbitrary genpath)
-                values = []
-                for genpath in args.field.split(','):
-                    if worksheet_util.is_file_genpath(genpath):
-                        value = contents_str(
-                            client.interpret_file_genpaths([(info['id'], genpath, None)])[0]
-                        )
-                    else:
-                        value = worksheet_util.interpret_genpath(info, genpath)
-                    values.append(value)
-                print('\t'.join(map(str, values)), file=self.stdout)
-            else:
-                # Display all the fields
-                if i > 0:
-                    print()
-                self.print_basic_info(client, info, args.raw)
-                if args.verbose:
-                    self.print_children(info)
-                    self.print_host_worksheets(info)
-                    self.print_permissions(info)
-                    self.print_contents(client, info)
-
-        # Headless client should fire OpenBundle UI action if no special flags used
-        if self.headless and not (args.field or args.raw or args.verbose):
-            return ui_actions.serialize([ui_actions.OpenBundle(bundle['id']) for bundle in bundles])
+            bundles = client.fetch(
+                'bundles',
+                params={
+                    'specs': args.bundle_spec,
+                    'worksheet': worksheet_uuid,
+                    'include': ['owner']
+                    + (
+                        ['children', 'group_permissions', 'host_worksheets'] if args.verbose else []
+                    ),
+                },
+            )
+
+            for i, info in enumerate(bundles):
+                if args.field:
+                    # Display individual fields (arbitrary genpath)
+                    values = []
+                    for genpath in args.field.split(','):
+                        if worksheet_util.is_file_genpath(genpath):
+                            value = contents_str(
+                                client.interpret_file_genpaths([(info['id'], genpath, None)])[0]
+                            )
+                        else:
+                            value = worksheet_util.interpret_genpath(info, genpath)
+                        values.append(value)
+                    print('\t'.join(map(str, values)), file=self.stdout)
+                else:
+                    # Display all the fields
+                    if i > 0:
+                        print()
+                    self.print_basic_info(client, info, args.raw)
+                    if args.verbose:
+                        self.print_children(info)
+                        self.print_host_worksheets(info)
+                        self.print_permissions(info)
+                        self.print_contents(client, info)
+
+            # Headless client should fire OpenBundle UI action if no special flags used
+            if self.headless and not (args.field or args.raw or args.verbose):
+                return ui_actions.serialize(
+                    [ui_actions.OpenBundle(bundle['id']) for bundle in bundles]
+                )
 
     @staticmethod
     def key_value_str(key, value):
@@ -2536,30 +2640,34 @@ class BundleCLI(object):
         ),
     )
     def do_mount_command(self, args):
-        if bundle_fuse.fuse_is_available:
-            self._fail_if_headless(args)  # Disable on headless systems
+        with tracer.start_as_current_span(
+            "mount", kind=trace.SpanKind.CLIENT,
+        ):
 
-            default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
-                args.worksheet_spec
-            )
-            client, worksheet_uuid, target = self.resolve_target(
-                default_client, default_worksheet_uuid, args.target_spec
-            )
+            if bundle_fuse.fuse_is_available:
+                self._fail_if_headless(args)  # Disable on headless systems
 
-            mountpoint = path_util.normalize(args.mountpoint)
-            path_util.check_isvalid(mountpoint, 'mount')
-            print(
-                'BundleFUSE mounting bundle {} on {}'.format(target.bundle_uuid, mountpoint),
-                file=self.stdout,
-            )
-            print(
-                'BundleFUSE will run and maintain the mounted filesystem in the foreground. CTRL-C to cancel.',
-                file=self.stdout,
-            )
-            bundle_fuse.bundle_mount(client, mountpoint, target.bundle_uuid, args.verbose)
-            print('BundleFUSE shutting down.', file=self.stdout)
-        else:
-            print('fuse is not installed', file=self.stdout)
+                default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
+                    args.worksheet_spec
+                )
+                client, worksheet_uuid, target = self.resolve_target(
+                    default_client, default_worksheet_uuid, args.target_spec
+                )
+
+                mountpoint = path_util.normalize(args.mountpoint)
+                path_util.check_isvalid(mountpoint, 'mount')
+                print(
+                    'BundleFUSE mounting bundle {} on {}'.format(target.bundle_uuid, mountpoint),
+                    file=self.stdout,
+                )
+                print(
+                    'BundleFUSE will run and maintain the mounted filesystem in the foreground. CTRL-C to cancel.',
+                    file=self.stdout,
+                )
+                bundle_fuse.bundle_mount(client, mountpoint, target.bundle_uuid, args.verbose)
+                print('BundleFUSE shutting down.', file=self.stdout)
+            else:
+                print('fuse is not installed', file=self.stdout)
 
     @Commands.command(
         'netcat',
@@ -2588,17 +2696,21 @@ class BundleCLI(object):
         ),
     )
     def do_netcat_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        client, worksheet_uuid, target = self.resolve_target(
-            client, worksheet_uuid, args.bundle_spec
-        )
-        message = args.message
-        if args.file:
-            with open(args.file) as f:
-                message += f.read()
-        contents = client.netcat(target.bundle_uuid, port=args.port, data={"message": message})
-        with closing(contents):
-            shutil.copyfileobj(contents, self.stdout.buffer)
+        with tracer.start_as_current_span(
+            "netcat", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            client, worksheet_uuid, target = self.resolve_target(
+                client, worksheet_uuid, args.bundle_spec
+            )
+            message = args.message
+            if args.file:
+                with open(args.file) as f:
+                    message += f.read()
+            contents = client.netcat(target.bundle_uuid, port=args.port, data={"message": message})
+            with closing(contents):
+                shutil.copyfileobj(contents, self.stdout.buffer)
 
     @Commands.command(
         'cat',
@@ -2623,18 +2735,23 @@ class BundleCLI(object):
         ),
     )
     def do_cat_command(self, args):
+        with tracer.start_as_current_span(
+            "cat", kind=trace.SpanKind.CLIENT,
+        ):
 
-        default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
-            args.worksheet_spec
-        )
-        client, worksheet_uuid, target = self.resolve_target(
-            default_client, default_worksheet_uuid, args.target_spec
-        )
-        info = self.print_target_info(client, target, head=args.head, tail=args.tail)
-        if info is None:
-            raise UsageError(
-                "Target '{}' doesn't exist in bundle {}".format(target.subpath, target.bundle_uuid)
+            default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
+                args.worksheet_spec
+            )
+            client, worksheet_uuid, target = self.resolve_target(
+                default_client, default_worksheet_uuid, args.target_spec
             )
+            info = self.print_target_info(client, target, head=args.head, tail=args.tail)
+            if info is None:
+                raise UsageError(
+                    "Target '{}' doesn't exist in bundle {}".format(
+                        target.subpath, target.bundle_uuid
+                    )
+                )
 
     # Helper: shared between info and cat
     def print_target_info(self, client, target, head=None, tail=None):
@@ -2720,26 +2837,30 @@ class BundleCLI(object):
         ),
     )
     def do_wait_command(self, args):
-        self._fail_if_headless(args)
+        with tracer.start_as_current_span(
+            "wait", kind=trace.SpanKind.CLIENT,
+        ):
 
-        default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
-            args.worksheet_spec
-        )
-        client, worksheet_uuid, target = self.resolve_target(
-            default_client, default_worksheet_uuid, args.target_spec
-        )
+            self._fail_if_headless(args)
 
-        # Figure files to display
-        subpaths = []
-        if args.tail:
-            if target.subpath == '':
-                subpaths = ['stdout', 'stderr']
-            else:
-                subpaths = [target.subpath]
-        state = self.follow_targets(client, target.bundle_uuid, subpaths)
-        if state != State.READY:
-            self.exit(state)
-        print(target.bundle_uuid, file=self.stdout)
+            default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
+                args.worksheet_spec
+            )
+            client, worksheet_uuid, target = self.resolve_target(
+                default_client, default_worksheet_uuid, args.target_spec
+            )
+
+            # Figure files to display
+            subpaths = []
+            if args.tail:
+                if target.subpath == '':
+                    subpaths = ['stdout', 'stderr']
+                else:
+                    subpaths = [target.subpath]
+            state = self.follow_targets(client, target.bundle_uuid, subpaths)
+            if state != State.READY:
+                self.exit(state)
+            print(target.bundle_uuid, file=self.stdout)
 
     def follow_targets(self, client, bundle_uuid, subpaths, from_start=False):
         """
@@ -2845,7 +2966,11 @@ class BundleCLI(object):
         + MIMIC_ARGUMENTS,
     )
     def do_mimic_command(self, args):
-        self.mimic(args)
+        with tracer.start_as_current_span(
+            "mimic", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self.mimic(args)
 
     @Commands.command(
         'macro',
@@ -2873,36 +2998,40 @@ class BundleCLI(object):
         """
         Just like do_mimic_command.
         """
-        # For a macro, it's important that the name be not-null, so that we
-        # don't create bundles called '<macro_name>-out', which would clash
-        # next time we try to use the macro.
-        if not getattr(args, metadata_util.metadata_key_to_argument('name')):
-            setattr(args, metadata_util.metadata_key_to_argument('name'), 'new')
-
-        # Reduce to the mimic case
-        named_user_inputs, named_macro_inputs, numbered_user_inputs = [], [], []
-
-        for bundle in args.bundles:
-            if ':' in bundle:
-                input_name, input_bundle = bundle.split(':', 1)
-                named_user_inputs.append(input_bundle)
-                named_macro_inputs.append(args.macro_name + '-in-' + input_name)
-            else:
-                numbered_user_inputs.append(bundle)
+        with tracer.start_as_current_span(
+            "macro", kind=trace.SpanKind.CLIENT,
+        ):
 
-        numbered_macro_inputs = [
-            args.macro_name + '-in' + str(i + 1) for i in range(len(numbered_user_inputs))
-        ]
+            # For a macro, it's important that the name be not-null, so that we
+            # don't create bundles called '<macro_name>-out', which would clash
+            # next time we try to use the macro.
+            if not getattr(args, metadata_util.metadata_key_to_argument('name')):
+                setattr(args, metadata_util.metadata_key_to_argument('name'), 'new')
 
-        args.bundles = (
-            numbered_macro_inputs
-            + named_macro_inputs
-            + [args.macro_name + '-out']
-            + numbered_user_inputs
-            + named_user_inputs
-        )
+            # Reduce to the mimic case
+            named_user_inputs, named_macro_inputs, numbered_user_inputs = [], [], []
+
+            for bundle in args.bundles:
+                if ':' in bundle:
+                    input_name, input_bundle = bundle.split(':', 1)
+                    named_user_inputs.append(input_bundle)
+                    named_macro_inputs.append(args.macro_name + '-in-' + input_name)
+                else:
+                    numbered_user_inputs.append(bundle)
+
+            numbered_macro_inputs = [
+                args.macro_name + '-in' + str(i + 1) for i in range(len(numbered_user_inputs))
+            ]
+
+            args.bundles = (
+                numbered_macro_inputs
+                + named_macro_inputs
+                + [args.macro_name + '-out']
+                + numbered_user_inputs
+                + named_user_inputs
+            )
 
-        self.mimic(args)
+            self.mimic(args)
 
     def mimic(self, args):
         """
@@ -2978,13 +3107,21 @@ class BundleCLI(object):
         ),
     )
     def do_kill_command(self, args):
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+        with tracer.start_as_current_span(
+            "kill", kind=trace.SpanKind.CLIENT,
+        ):
 
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        bundle_uuids = self.target_specs_to_bundle_uuids(client, worksheet_uuid, args.bundle_spec)
-        for bundle_uuid in bundle_uuids:
-            print(bundle_uuid, file=self.stdout)
-        client.create('bundle-actions', [{'type': 'kill', 'uuid': uuid} for uuid in bundle_uuids])
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            bundle_uuids = self.target_specs_to_bundle_uuids(
+                client, worksheet_uuid, args.bundle_spec
+            )
+            for bundle_uuid in bundle_uuids:
+                print(bundle_uuid, file=self.stdout)
+            client.create(
+                'bundle-actions', [{'type': 'kill', 'uuid': uuid} for uuid in bundle_uuids]
+            )
 
     @Commands.command(
         'write',
@@ -3001,22 +3138,26 @@ class BundleCLI(object):
         ),
     )
     def do_write_command(self, args):
-        default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
-            args.worksheet_spec
-        )
-        client, worksheet_uuid, target = self.resolve_target(
-            default_client, default_worksheet_uuid, args.target_spec
-        )
-        client.create(
-            'bundle-actions',
-            {
-                'type': 'write',
-                'uuid': target.bundle_uuid,
-                'subpath': target.subpath,
-                'string': args.string,
-            },
-        )
-        print(target.bundle_uuid, file=self.stdout)
+        with tracer.start_as_current_span(
+            "write", kind=trace.SpanKind.CLIENT,
+        ):
+
+            default_client, default_worksheet_uuid = self.parse_client_worksheet_uuid(
+                args.worksheet_spec
+            )
+            client, worksheet_uuid, target = self.resolve_target(
+                default_client, default_worksheet_uuid, args.target_spec
+            )
+            client.create(
+                'bundle-actions',
+                {
+                    'type': 'write',
+                    'uuid': target.bundle_uuid,
+                    'subpath': target.subpath,
+                    'string': args.string,
+                },
+            )
+            print(target.bundle_uuid, file=self.stdout)
 
     @Commands.command(
         'open',
@@ -3035,19 +3176,25 @@ class BundleCLI(object):
         ),
     )
     def do_open_command(self, args):
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "open", kind=trace.SpanKind.CLIENT,
+        ):
 
-        bundles = client.fetch(
-            'bundles', params={'specs': args.bundle_spec, 'worksheet': worksheet_uuid},
-        )
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        for info in bundles:
-            webbrowser.open(self.bundle_url(info['id']))
+            bundles = client.fetch(
+                'bundles', params={'specs': args.bundle_spec, 'worksheet': worksheet_uuid},
+            )
 
-        # Headless client should fire OpenBundle UI action
-        if self.headless:
-            return ui_actions.serialize([ui_actions.OpenBundle(bundle['id']) for bundle in bundles])
+            for info in bundles:
+                webbrowser.open(self.bundle_url(info['id']))
+
+            # Headless client should fire OpenBundle UI action
+            if self.headless:
+                return ui_actions.serialize(
+                    [ui_actions.OpenBundle(bundle['id']) for bundle in bundles]
+                )
 
     def bundle_url(self, bundle_uuid):
         return '%s%s%s' % (self.manager.session()['address'], BUNDLES_URL_SEPARATOR, bundle_uuid)
@@ -3082,11 +3229,15 @@ class BundleCLI(object):
         ),
     )
     def do_new_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        new_worksheet = client.create('worksheets', data={'name': args.name})
-        print(new_worksheet['uuid'], file=self.stdout)
-        if self.headless:
-            return ui_actions.serialize([ui_actions.OpenWorksheet(new_worksheet['uuid'])])
+        with tracer.start_as_current_span(
+            "new", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            new_worksheet = client.create('worksheets', data={'name': args.name})
+            print(new_worksheet['uuid'], file=self.stdout)
+            if self.headless:
+                return ui_actions.serialize([ui_actions.OpenWorksheet(new_worksheet['uuid'])])
 
     ITEM_DESCRIPTION = (
         textwrap.dedent(
@@ -3134,73 +3285,79 @@ class BundleCLI(object):
         ),
     )
     def do_add_command(self, args):
-        curr_client, curr_worksheet_uuid = self.manager.get_current_worksheet_uuid()
-        dest_client, dest_worksheet_uuid = self.parse_client_worksheet_uuid(args.dest_worksheet)
+        with tracer.start_as_current_span(
+            "add", kind=trace.SpanKind.CLIENT,
+        ):
 
-        if args.item_type != 'bundle' and args.copy_dependencies:
-            raise UsageError("-d/--copy_dependencies flag only applies when adding bundles.")
+            curr_client, curr_worksheet_uuid = self.manager.get_current_worksheet_uuid()
+            dest_client, dest_worksheet_uuid = self.parse_client_worksheet_uuid(args.dest_worksheet)
+
+            if args.item_type != 'bundle' and args.copy_dependencies:
+                raise UsageError("-d/--copy_dependencies flag only applies when adding bundles.")
+
+            if args.item_type == 'text':
+                for item_spec in args.item_spec:
+                    if item_spec.startswith('%'):
+                        dest_client.create(
+                            'worksheet-items',
+                            data={
+                                'type': worksheet_util.TYPE_DIRECTIVE,
+                                'worksheet': JsonApiRelationship('worksheets', dest_worksheet_uuid),
+                                'value': item_spec[1:].strip(),
+                            },
+                            params={'uuid': dest_worksheet_uuid},
+                        )
+                    else:
+                        dest_client.create(
+                            'worksheet-items',
+                            data={
+                                'type': worksheet_util.TYPE_MARKUP,
+                                'worksheet': JsonApiRelationship('worksheets', dest_worksheet_uuid),
+                                'value': item_spec,
+                            },
+                            params={'uuid': dest_worksheet_uuid},
+                        )
 
-        if args.item_type == 'text':
-            for item_spec in args.item_spec:
-                if item_spec.startswith('%'):
-                    dest_client.create(
-                        'worksheet-items',
-                        data={
-                            'type': worksheet_util.TYPE_DIRECTIVE,
-                            'worksheet': JsonApiRelationship('worksheets', dest_worksheet_uuid),
-                            'value': item_spec[1:].strip(),
-                        },
-                        params={'uuid': dest_worksheet_uuid},
+            elif args.item_type == 'bundle':
+                for bundle_spec in args.item_spec:
+                    (source_client, source_worksheet_uuid, source_target) = self.resolve_target(
+                        curr_client, curr_worksheet_uuid, bundle_spec
                     )
-                else:
+                    # copy (or add only if bundle already exists on destination)
+                    self.copy_bundle(
+                        source_client,
+                        source_target.bundle_uuid,
+                        dest_client,
+                        dest_worksheet_uuid,
+                        copy_dependencies=args.copy_dependencies,
+                        add_to_worksheet=True,
+                    )
+
+            elif args.item_type == 'worksheet':
+                for worksheet_spec in args.item_spec:
+                    source_client, worksheet_spec = self.parse_spec(worksheet_spec)
+                    if source_client.address != dest_client.address:
+                        raise UsageError("You cannot add worksheet links across instances.")
+
+                    # a base_worksheet_uuid is only applicable if we're on the source client
+                    base_worksheet_uuid = (
+                        curr_worksheet_uuid if source_client is curr_client else None
+                    )
+                    subworksheet_uuid = self.resolve_worksheet_uuid(
+                        source_client, base_worksheet_uuid, worksheet_spec
+                    )
+
+                    # add worksheet
                     dest_client.create(
                         'worksheet-items',
                         data={
-                            'type': worksheet_util.TYPE_MARKUP,
+                            'type': worksheet_util.TYPE_WORKSHEET,
                             'worksheet': JsonApiRelationship('worksheets', dest_worksheet_uuid),
-                            'value': item_spec,
+                            'subworksheet': JsonApiRelationship('worksheets', subworksheet_uuid),
                         },
                         params={'uuid': dest_worksheet_uuid},
                     )
 
-        elif args.item_type == 'bundle':
-            for bundle_spec in args.item_spec:
-                (source_client, source_worksheet_uuid, source_target) = self.resolve_target(
-                    curr_client, curr_worksheet_uuid, bundle_spec
-                )
-                # copy (or add only if bundle already exists on destination)
-                self.copy_bundle(
-                    source_client,
-                    source_target.bundle_uuid,
-                    dest_client,
-                    dest_worksheet_uuid,
-                    copy_dependencies=args.copy_dependencies,
-                    add_to_worksheet=True,
-                )
-
-        elif args.item_type == 'worksheet':
-            for worksheet_spec in args.item_spec:
-                source_client, worksheet_spec = self.parse_spec(worksheet_spec)
-                if source_client.address != dest_client.address:
-                    raise UsageError("You cannot add worksheet links across instances.")
-
-                # a base_worksheet_uuid is only applicable if we're on the source client
-                base_worksheet_uuid = curr_worksheet_uuid if source_client is curr_client else None
-                subworksheet_uuid = self.resolve_worksheet_uuid(
-                    source_client, base_worksheet_uuid, worksheet_spec
-                )
-
-                # add worksheet
-                dest_client.create(
-                    'worksheet-items',
-                    data={
-                        'type': worksheet_util.TYPE_WORKSHEET,
-                        'worksheet': JsonApiRelationship('worksheets', dest_worksheet_uuid),
-                        'subworksheet': JsonApiRelationship('worksheets', subworksheet_uuid),
-                    },
-                    params={'uuid': dest_worksheet_uuid},
-                )
-
     @Commands.command(
         'work',
         aliases=('w',),
@@ -3223,29 +3380,33 @@ class BundleCLI(object):
         ),
     )
     def do_work_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        worksheet_info = client.fetch('worksheets', worksheet_uuid)
-        if args.worksheet_spec:
-            if args.uuid_only:
-                print(worksheet_info['uuid'], file=self.stdout)
-            return self.change_current_worksheet(
-                client, worksheet_uuid, verbose=(not args.uuid_only)
-            )
-        else:
-            if worksheet_info:
+        with tracer.start_as_current_span(
+            "work", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            worksheet_info = client.fetch('worksheets', worksheet_uuid)
+            if args.worksheet_spec:
                 if args.uuid_only:
                     print(worksheet_info['uuid'], file=self.stdout)
+                return self.change_current_worksheet(
+                    client, worksheet_uuid, verbose=(not args.uuid_only)
+                )
+            else:
+                if worksheet_info:
+                    if args.uuid_only:
+                        print(worksheet_info['uuid'], file=self.stdout)
+                    else:
+                        print(
+                            'Currently on worksheet: %s'
+                            % (self.worksheet_url_and_name(worksheet_info)),
+                            file=self.stdout,
+                        )
                 else:
                     print(
-                        'Currently on worksheet: %s'
-                        % (self.worksheet_url_and_name(worksheet_info)),
+                        'Not on any worksheet. Use `cl new` or `cl work` to switch to one.',
                         file=self.stdout,
                     )
-            else:
-                print(
-                    'Not on any worksheet. Use `cl new` or `cl work` to switch to one.',
-                    file=self.stdout,
-                )
 
     def change_current_worksheet(self, client, worksheet_uuid, verbose=False):
         """
@@ -3329,67 +3490,71 @@ class BundleCLI(object):
         ),
     )
     def do_wedit_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        worksheet_info = client.fetch(
-            'worksheets',
-            worksheet_uuid,
-            params={'include': ['items', 'items.bundle', 'items.subworksheet']},
-        )
-        if (
-            args.freeze
-            or args.unfreeze
-            or any(
-                arg is not None
-                for arg in (args.name, args.title, args.tags, args.owner_spec, args.anonymous)
-            )
+        with tracer.start_as_current_span(
+            "wedit", kind=trace.SpanKind.CLIENT,
         ):
-            # Update the worksheet metadata.
-            info = {'id': worksheet_info['id']}
-            if args.name is not None:
-                info['name'] = args.name
-            if args.title is not None:
-                info['title'] = args.title
-            if args.tags is not None:
-                info['tags'] = args.tags
-            if args.owner_spec is not None:
-                owner = client.fetch('users', args.owner_spec)
-                info['owner'] = JsonApiRelationship('users', owner['id'])
-            if args.freeze:
-                info['frozen'] = datetime.datetime.utcnow().isoformat()
-            if args.unfreeze:
-                info['frozen'] = None
-            if args.anonymous is not None:
-                info['is_anonymous'] = args.anonymous
 
-            client.update('worksheets', info)
-            print(
-                'Saved worksheet metadata for %s(%s).'
-                % (worksheet_info['name'], worksheet_info['uuid']),
-                file=self.stdout,
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            worksheet_info = client.fetch(
+                'worksheets',
+                worksheet_uuid,
+                params={'include': ['items', 'items.bundle', 'items.subworksheet']},
             )
-        else:
-            if self.headless:
-                return ui_actions.serialize([ui_actions.SetEditMode(True)])
+            if (
+                args.freeze
+                or args.unfreeze
+                or any(
+                    arg is not None
+                    for arg in (args.name, args.title, args.tags, args.owner_spec, args.anonymous)
+                )
+            ):
+                # Update the worksheet metadata.
+                info = {'id': worksheet_info['id']}
+                if args.name is not None:
+                    info['name'] = args.name
+                if args.title is not None:
+                    info['title'] = args.title
+                if args.tags is not None:
+                    info['tags'] = args.tags
+                if args.owner_spec is not None:
+                    owner = client.fetch('users', args.owner_spec)
+                    info['owner'] = JsonApiRelationship('users', owner['id'])
+                if args.freeze:
+                    info['frozen'] = datetime.datetime.utcnow().isoformat()
+                if args.unfreeze:
+                    info['frozen'] = None
+                if args.anonymous is not None:
+                    info['is_anonymous'] = args.anonymous
+
+                client.update('worksheets', info)
+                print(
+                    'Saved worksheet metadata for %s(%s).'
+                    % (worksheet_info['name'], worksheet_info['uuid']),
+                    file=self.stdout,
+                )
+            else:
+                if self.headless:
+                    return ui_actions.serialize([ui_actions.SetEditMode(True)])
 
-            # Either get a list of lines from the given file or request it from the user in an editor.
-            if args.file:
-                if args.file == '-':
-                    lines = sys.stdin.readlines()
+                # Either get a list of lines from the given file or request it from the user in an editor.
+                if args.file:
+                    if args.file == '-':
+                        lines = sys.stdin.readlines()
+                    else:
+                        with codecs.open(args.file, encoding='utf-8', mode='r') as infile:
+                            lines = infile.readlines()
+                    lines = [line.rstrip() for line in lines]
                 else:
-                    with codecs.open(args.file, encoding='utf-8', mode='r') as infile:
-                        lines = infile.readlines()
-                lines = [line.rstrip() for line in lines]
-            else:
-                worksheet_info['items'] = list(map(self.unpack_item, worksheet_info['items']))
-                lines = worksheet_util.request_lines(worksheet_info)
+                    worksheet_info['items'] = list(map(self.unpack_item, worksheet_info['items']))
+                    lines = worksheet_util.request_lines(worksheet_info)
 
-            # Update worksheet
-            client.update_worksheet_raw(worksheet_info['id'], lines)
-            print(
-                'Saved worksheet items for %s(%s).'
-                % (worksheet_info['name'], worksheet_info['uuid']),
-                file=self.stdout,
-            )
+                # Update worksheet
+                client.update_worksheet_raw(worksheet_info['id'], lines)
+                print(
+                    'Saved worksheet items for %s(%s).'
+                    % (worksheet_info['name'], worksheet_info['uuid']),
+                    file=self.stdout,
+                )
 
     @staticmethod
     def unpack_item(item):
@@ -3426,33 +3591,37 @@ class BundleCLI(object):
         ),
     )
     def do_print_command(self, args):
-        self._fail_if_headless(args)
+        with tracer.start_as_current_span(
+            "print", kind=trace.SpanKind.CLIENT,
+        ):
 
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        worksheet_info = client.fetch(
-            'worksheets',
-            worksheet_uuid,
-            params={
-                'include': [
-                    'owner',
-                    'group_permissions',
-                    'items',
-                    'items.bundle',
-                    'items.bundle.owner',
-                    'items.subworksheet',
-                ]
-            },
-        )
-        worksheet_info['items'] = list(map(self.unpack_item, worksheet_info['items']))
+            self._fail_if_headless(args)
 
-        if args.raw:
-            lines = worksheet_util.get_worksheet_lines(worksheet_info)
-            for line in lines:
-                print(line, file=self.stdout)
-        else:
-            print(self._worksheet_description(worksheet_info), file=self.stdout)
-            interpreted_blocks = client.fetch_interpreted_worksheet(worksheet_uuid)['blocks']
-            self.display_blocks(client, worksheet_info, interpreted_blocks)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            worksheet_info = client.fetch(
+                'worksheets',
+                worksheet_uuid,
+                params={
+                    'include': [
+                        'owner',
+                        'group_permissions',
+                        'items',
+                        'items.bundle',
+                        'items.bundle.owner',
+                        'items.subworksheet',
+                    ]
+                },
+            )
+            worksheet_info['items'] = list(map(self.unpack_item, worksheet_info['items']))
+
+            if args.raw:
+                lines = worksheet_util.get_worksheet_lines(worksheet_info)
+                for line in lines:
+                    print(line, file=self.stdout)
+            else:
+                print(self._worksheet_description(worksheet_info), file=self.stdout)
+                interpreted_blocks = client.fetch_interpreted_worksheet(worksheet_uuid)['blocks']
+                self.display_blocks(client, worksheet_info, interpreted_blocks)
 
     def display_blocks(self, client, worksheet_info, interpreted_blocks):
         for block in interpreted_blocks:
@@ -3522,33 +3691,37 @@ class BundleCLI(object):
         ),
     )
     def do_wls_command(self, args):
-        if args.address:
-            address = self.manager.apply_alias(args.address)
-            client = self.manager.client(address)
-        else:
-            client = self.manager.current_client()
+        with tracer.start_as_current_span(
+            "wls", kind=trace.SpanKind.CLIENT,
+        ):
 
-        worksheet_dicts = client.fetch(
-            'worksheets',
-            params={'keywords': args.keywords, 'include': ['owner', 'group_permissions']},
-        )
+            if args.address:
+                address = self.manager.apply_alias(args.address)
+                client = self.manager.client(address)
+            else:
+                client = self.manager.current_client()
 
-        if args.uuid_only:
-            for row in worksheet_dicts:
-                print(row['uuid'], file=self.stdout)
-        else:
-            if worksheet_dicts:
-                self.print_result_limit_info(len((worksheet_dicts)))
+            worksheet_dicts = client.fetch(
+                'worksheets',
+                params={'keywords': args.keywords, 'include': ['owner', 'group_permissions']},
+            )
+
+            if args.uuid_only:
                 for row in worksheet_dicts:
-                    row['owner'] = self.simple_user_str(row['owner'])
-                    row['permissions'] = group_permissions_str(row['group_permissions'])
-                post_funcs = {'uuid': UUID_POST_FUNC}
-                self.print_table(
-                    ('uuid', 'name', 'owner', 'permissions'), worksheet_dicts, post_funcs
-                )
+                    print(row['uuid'], file=self.stdout)
             else:
-                print(NO_RESULTS_FOUND, file=self.stderr)
-        return {'refs': self.create_reference_map('worksheet', worksheet_dicts)}
+                if worksheet_dicts:
+                    self.print_result_limit_info(len((worksheet_dicts)))
+                    for row in worksheet_dicts:
+                        row['owner'] = self.simple_user_str(row['owner'])
+                        row['permissions'] = group_permissions_str(row['group_permissions'])
+                    post_funcs = {'uuid': UUID_POST_FUNC}
+                    self.print_table(
+                        ('uuid', 'name', 'owner', 'permissions'), worksheet_dicts, post_funcs
+                    )
+                else:
+                    print(NO_RESULTS_FOUND, file=self.stderr)
+            return {'refs': self.create_reference_map('worksheet', worksheet_dicts)}
 
     @Commands.command(
         'wrm',
@@ -3571,17 +3744,21 @@ class BundleCLI(object):
         ),
     )
     def do_wrm_command(self, args):
-        delete_current = False
-        client, current_worksheet = self.manager.get_current_worksheet_uuid()
-        for worksheet_spec in args.worksheet_spec:
-            client, worksheet_uuid = self.parse_client_worksheet_uuid(worksheet_spec)
-            if (client, worksheet_uuid) == (client, current_worksheet):
-                delete_current = True
-            client.delete('worksheets', worksheet_uuid, params={'force': args.force})
-
-        if delete_current:
-            # Go to home worksheet
-            return self.change_current_worksheet(client, None, verbose=True)
+        with tracer.start_as_current_span(
+            "wrm", kind=trace.SpanKind.CLIENT,
+        ):
+
+            delete_current = False
+            client, current_worksheet = self.manager.get_current_worksheet_uuid()
+            for worksheet_spec in args.worksheet_spec:
+                client, worksheet_uuid = self.parse_client_worksheet_uuid(worksheet_spec)
+                if (client, worksheet_uuid) == (client, current_worksheet):
+                    delete_current = True
+                client.delete('worksheets', worksheet_uuid, params={'force': args.force})
+
+            if delete_current:
+                # Go to home worksheet
+                return self.change_current_worksheet(client, None, verbose=True)
 
     @Commands.command(
         'wadd',
@@ -3607,56 +3784,60 @@ class BundleCLI(object):
         ),
     )
     def do_wadd_command(self, args):
-        # Source worksheet
-        (source_client, source_worksheet_uuid) = self.parse_client_worksheet_uuid(
-            args.source_worksheet_spec
-        )
-        source_items = source_client.fetch(
-            'worksheets', source_worksheet_uuid, params={'include': ['items', 'items.bundle']}
-        )['items']
+        with tracer.start_as_current_span(
+            "wadd", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Destination worksheet
-        (dest_client, dest_worksheet_uuid) = self.parse_client_worksheet_uuid(
-            args.dest_worksheet_spec
-        )
+            # Source worksheet
+            (source_client, source_worksheet_uuid) = self.parse_client_worksheet_uuid(
+                args.source_worksheet_spec
+            )
+            source_items = source_client.fetch(
+                'worksheets', source_worksheet_uuid, params={'include': ['items', 'items.bundle']}
+            )['items']
 
-        valid_source_items = []
-        # Save all items to the destination worksheet
-        for item in source_items:
-            if item['type'] == worksheet_util.TYPE_BUNDLE:
-                if item['bundle']['state'] not in [State.READY, State.FAILED]:
-                    print(
-                        'Skipping bundle {} because it has non-final state {}'.format(
-                            item['bundle']['id'], item['bundle']['state']
-                        ),
-                        file=self.stdout,
-                    )
-                    continue
-            item['worksheet'] = JsonApiRelationship('worksheets', dest_worksheet_uuid)
-            valid_source_items.append(item)
+            # Destination worksheet
+            (dest_client, dest_worksheet_uuid) = self.parse_client_worksheet_uuid(
+                args.dest_worksheet_spec
+            )
 
-        dest_client.create(
-            'worksheet-items',
-            valid_source_items,
-            params={'replace': args.replace, 'uuid': dest_worksheet_uuid},
-        )
+            valid_source_items = []
+            # Save all items to the destination worksheet
+            for item in source_items:
+                if item['type'] == worksheet_util.TYPE_BUNDLE:
+                    if item['bundle']['state'] not in [State.READY, State.FAILED]:
+                        print(
+                            'Skipping bundle {} because it has non-final state {}'.format(
+                                item['bundle']['id'], item['bundle']['state']
+                            ),
+                            file=self.stdout,
+                        )
+                        continue
+                item['worksheet'] = JsonApiRelationship('worksheets', dest_worksheet_uuid)
+                valid_source_items.append(item)
 
-        # Copy over the bundles
-        for item in valid_source_items:
-            if item['type'] == worksheet_util.TYPE_BUNDLE:
-                self.copy_bundle(
-                    source_client,
-                    item['bundle']['id'],
-                    dest_client,
-                    dest_worksheet_uuid,
-                    copy_dependencies=False,
-                    add_to_worksheet=False,
-                )
+            dest_client.create(
+                'worksheet-items',
+                valid_source_items,
+                params={'replace': args.replace, 'uuid': dest_worksheet_uuid},
+            )
 
-        print(
-            'Copied %s worksheet items to %s.' % (len(valid_source_items), dest_worksheet_uuid),
-            file=self.stdout,
-        )
+            # Copy over the bundles
+            for item in valid_source_items:
+                if item['type'] == worksheet_util.TYPE_BUNDLE:
+                    self.copy_bundle(
+                        source_client,
+                        item['bundle']['id'],
+                        dest_client,
+                        dest_worksheet_uuid,
+                        copy_dependencies=False,
+                        add_to_worksheet=False,
+                    )
+
+            print(
+                'Copied %s worksheet items to %s.' % (len(valid_source_items), dest_worksheet_uuid),
+                file=self.stdout,
+            )
 
     @Commands.command(
         'wopen',
@@ -3676,24 +3857,28 @@ class BundleCLI(object):
         ),
     )
     def do_wopen_command(self, args):
-        worksheet_uuids = (
-            [self.manager.get_current_worksheet_uuid()[1]]
-            if not args.worksheet_spec
-            else [
-                self.parse_client_worksheet_uuid(worksheet_spec)[1]
-                for worksheet_spec in args.worksheet_spec
-            ]
-        )
-
-        for worksheet_uuid in worksheet_uuids:
-            webbrowser.open(self.worksheet_url(worksheet_uuid))
+        with tracer.start_as_current_span(
+            "wopen", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Headless client should fire OpenWorksheet UI action
-        if self.headless:
-            return ui_actions.serialize(
-                [ui_actions.OpenWorksheet(worksheet_uuid) for worksheet_uuid in worksheet_uuids]
+            worksheet_uuids = (
+                [self.manager.get_current_worksheet_uuid()[1]]
+                if not args.worksheet_spec
+                else [
+                    self.parse_client_worksheet_uuid(worksheet_spec)[1]
+                    for worksheet_spec in args.worksheet_spec
+                ]
             )
 
+            for worksheet_uuid in worksheet_uuids:
+                webbrowser.open(self.worksheet_url(worksheet_uuid))
+
+            # Headless client should fire OpenWorksheet UI action
+            if self.headless:
+                return ui_actions.serialize(
+                    [ui_actions.OpenWorksheet(worksheet_uuid) for worksheet_uuid in worksheet_uuids]
+                )
+
     #############################################################################
     # CLI methods for commands related to groups and permissions follow!
     #############################################################################
@@ -3711,27 +3896,31 @@ class BundleCLI(object):
         ),
     )
     def do_gls_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        user_id = client.fetch('user')['id']
-        groups = client.fetch('groups')
-
-        if groups:
-            for group in groups:
-                group['uuid'] = group['id']
-                if any(member['id'] == user_id for member in group['admins']):
-                    group['role'] = 'admin'
-                elif group['owner'] and group['owner']['id'] == user_id:
-                    group['role'] = 'owner'
-                else:
-                    group['role'] = 'member'
-                # Set owner string for print_table
-                # group['owner'] may be None (i.e. for the public group)
-                if group['owner']:
-                    group['owner'] = self.simple_user_str(group['owner'])
+        with tracer.start_as_current_span(
+            "gls", kind=trace.SpanKind.CLIENT,
+        ):
 
-            self.print_table(('name', 'uuid', 'owner', 'role'), groups)
-        else:
-            print('No groups found.', file=self.stdout)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            user_id = client.fetch('user')['id']
+            groups = client.fetch('groups')
+
+            if groups:
+                for group in groups:
+                    group['uuid'] = group['id']
+                    if any(member['id'] == user_id for member in group['admins']):
+                        group['role'] = 'admin'
+                    elif group['owner'] and group['owner']['id'] == user_id:
+                        group['role'] = 'owner'
+                    else:
+                        group['role'] = 'member'
+                    # Set owner string for print_table
+                    # group['owner'] may be None (i.e. for the public group)
+                    if group['owner']:
+                        group['owner'] = self.simple_user_str(group['owner'])
+
+                self.print_table(('name', 'uuid', 'owner', 'role'), groups)
+            else:
+                print('No groups found.', file=self.stdout)
 
     @Commands.command(
         'gnew',
@@ -3743,9 +3932,13 @@ class BundleCLI(object):
         ),
     )
     def do_gnew_command(self, args):
-        client = self.manager.current_client()
-        group = client.create('groups', {'name': args.name})
-        print('Created new group %s(%s).' % (group['name'], group['id']), file=self.stdout)
+        with tracer.start_as_current_span(
+            "gnew", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client = self.manager.current_client()
+            group = client.create('groups', {'name': args.name})
+            print('Created new group %s(%s).' % (group['name'], group['id']), file=self.stdout)
 
     @Commands.command(
         'grm',
@@ -3759,10 +3952,14 @@ class BundleCLI(object):
         ),
     )
     def do_grm_command(self, args):
-        client = self.manager.current_client()
-        group = client.fetch('groups', args.group_spec)
-        client.delete('groups', group['id'])
-        print('Deleted group %s(%s).' % (group['name'], group['id']), file=self.stdout)
+        with tracer.start_as_current_span(
+            "grm", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client = self.manager.current_client()
+            group = client.fetch('groups', args.group_spec)
+            client.delete('groups', group['id'])
+            print('Deleted group %s(%s).' % (group['name'], group['id']), file=self.stdout)
 
     @Commands.command(
         'ginfo',
@@ -3776,35 +3973,41 @@ class BundleCLI(object):
         ),
     )
     def do_ginfo_command(self, args):
-        client = self.manager.current_client()
-        group = client.fetch('groups', args.group_spec)
+        with tracer.start_as_current_span(
+            "ginfo", kind=trace.SpanKind.CLIENT,
+        ):
 
-        members = []
-        # group['owner'] may be a falsey null-relationship (i.e. for the public group)
-        if group['owner']:
-            members.append(
-                {
-                    'role': 'owner',
-                    'user': '%s(%s)' % (group['owner']['user_name'], group['owner']['id']),
-                }
-            )
-        for member in group['admins']:
-            members.append(
-                {
-                    'role': 'admin',
-                    'user': '%s(%s)' % (member.get('user_name', '[deleted user]'), member['id']),
-                }
-            )
-        for member in group['members']:
-            members.append(
-                {
-                    'role': 'member',
-                    'user': '%s(%s)' % (member.get('user_name', '[deleted user]'), member['id']),
-                }
-            )
+            client = self.manager.current_client()
+            group = client.fetch('groups', args.group_spec)
 
-        print('Members of group %s(%s):' % (group['name'], group['id']), file=self.stdout)
-        self.print_table(('user', 'role'), members)
+            members = []
+            # group['owner'] may be a falsey null-relationship (i.e. for the public group)
+            if group['owner']:
+                members.append(
+                    {
+                        'role': 'owner',
+                        'user': '%s(%s)' % (group['owner']['user_name'], group['owner']['id']),
+                    }
+                )
+            for member in group['admins']:
+                members.append(
+                    {
+                        'role': 'admin',
+                        'user': '%s(%s)'
+                        % (member.get('user_name', '[deleted user]'), member['id']),
+                    }
+                )
+            for member in group['members']:
+                members.append(
+                    {
+                        'role': 'member',
+                        'user': '%s(%s)'
+                        % (member.get('user_name', '[deleted user]'), member['id']),
+                    }
+                )
+
+            print('Members of group %s(%s):' % (group['name'], group['id']), file=self.stdout)
+            self.print_table(('user', 'role'), members)
 
     @Commands.command(
         'uadd',
@@ -3825,22 +4028,26 @@ class BundleCLI(object):
         ),
     )
     def do_uadd_command(self, args):
-        client = self.manager.current_client()
-
-        user = client.fetch('users', args.user_spec)
-        group = client.fetch('groups', args.group_spec)
-        client.create_relationship(
-            'groups',
-            group['id'],
-            'admins' if args.admin else 'members',
-            JsonApiRelationship('users', user['id']),
-        )
+        with tracer.start_as_current_span(
+            "uadd", kind=trace.SpanKind.CLIENT,
+        ):
 
-        print(
-            '%s in group %s as %s'
-            % (user['user_name'], group['name'], 'admin' if args.admin else 'member'),
-            file=self.stdout,
-        )
+            client = self.manager.current_client()
+
+            user = client.fetch('users', args.user_spec)
+            group = client.fetch('groups', args.group_spec)
+            client.create_relationship(
+                'groups',
+                group['id'],
+                'admins' if args.admin else 'members',
+                JsonApiRelationship('users', user['id']),
+            )
+
+            print(
+                '%s in group %s as %s'
+                % (user['user_name'], group['name'], 'admin' if args.admin else 'member'),
+                file=self.stdout,
+            )
 
     @Commands.command(
         'urm',
@@ -3855,28 +4062,33 @@ class BundleCLI(object):
         ),
     )
     def do_urm_command(self, args):
-        client = self.manager.current_client()
-        user = client.fetch('users', args.user_spec)
-        group = client.fetch('groups', args.group_spec)
+        with tracer.start_as_current_span(
+            "urm", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Get the first member that matches the target user ID
-        member = next(
-            [m for m in group['members'] + group['admins'] if m['id'] == user['id']], None
-        )
+            client = self.manager.current_client()
+            user = client.fetch('users', args.user_spec)
+            group = client.fetch('groups', args.group_spec)
 
-        if member is None:
-            print(
-                '%s is not a member of group %s.' % (user['user_name'], group['name']),
-                file=self.stdout,
-            )
-        else:
-            client.delete_relationship(
-                'groups', group['id'], 'members', JsonApiRelationship('users', user['id'])
-            )
-            print(
-                'Removed %s from group %s.' % (user['user_name'], group['name']), file=self.stdout
+            # Get the first member that matches the target user ID
+            member = next(
+                [m for m in group['members'] + group['admins'] if m['id'] == user['id']], None
             )
 
+            if member is None:
+                print(
+                    '%s is not a member of group %s.' % (user['user_name'], group['name']),
+                    file=self.stdout,
+                )
+            else:
+                client.delete_relationship(
+                    'groups', group['id'], 'members', JsonApiRelationship('users', user['id'])
+                )
+                print(
+                    'Removed %s from group %s.' % (user['user_name'], group['name']),
+                    file=self.stdout,
+                )
+
     @Commands.command(
         'perm',
         help='Set a group\'s permissions for a bundle.',
@@ -3899,31 +4111,37 @@ class BundleCLI(object):
         ),
     )
     def do_perm_command(self, args):
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+        with tracer.start_as_current_span(
+            "perm", kind=trace.SpanKind.CLIENT,
+        ):
 
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
-        group = client.fetch('groups', args.group_spec)
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
 
-        bundle_uuids = self.target_specs_to_bundle_uuids(client, worksheet_uuid, args.bundle_spec)
-        new_permission = parse_permission(args.permission_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+            group = client.fetch('groups', args.group_spec)
 
-        client.create(
-            'bundle-permissions',
-            [
-                {
-                    'group': JsonApiRelationship('groups', group['id']),
-                    'bundle': JsonApiRelationship('bundles', uuid),
-                    'permission': new_permission,
-                }
-                for uuid in bundle_uuids
-            ],
-        )
+            bundle_uuids = self.target_specs_to_bundle_uuids(
+                client, worksheet_uuid, args.bundle_spec
+            )
+            new_permission = parse_permission(args.permission_spec)
 
-        print(
-            "Group %s(%s) has %s permission on %d bundles."
-            % (group['name'], group['id'], permission_str(new_permission), len(bundle_uuids)),
-            file=self.stdout,
-        )
+            client.create(
+                'bundle-permissions',
+                [
+                    {
+                        'group': JsonApiRelationship('groups', group['id']),
+                        'bundle': JsonApiRelationship('bundles', uuid),
+                        'permission': new_permission,
+                    }
+                    for uuid in bundle_uuids
+                ],
+            )
+
+            print(
+                "Group %s(%s) has %s permission on %d bundles."
+                % (group['name'], group['id'], permission_str(new_permission), len(bundle_uuids)),
+                file=self.stdout,
+            )
 
     @Commands.command(
         'wperm',
@@ -3937,30 +4155,34 @@ class BundleCLI(object):
         ),
     )
     def do_wperm_command(self, args):
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "wperm", kind=trace.SpanKind.CLIENT,
+        ):
 
-        worksheet = client.fetch('worksheets', worksheet_uuid)
-        group = client.fetch('groups', args.group_spec)
-        new_permission = parse_permission(args.permission_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        client.create(
-            'worksheet-permissions',
-            {
-                'group': JsonApiRelationship('groups', group['id']),
-                'worksheet': JsonApiRelationship('worksheets', worksheet_uuid),
-                'permission': new_permission,
-            },
-        )
+            worksheet = client.fetch('worksheets', worksheet_uuid)
+            group = client.fetch('groups', args.group_spec)
+            new_permission = parse_permission(args.permission_spec)
 
-        print(
-            "Group %s has %s permission on worksheet %s."
-            % (
-                self.simple_group_str(group),
-                permission_str(new_permission),
-                self.worksheet_url_and_name(worksheet),
-            ),
-            file=self.stdout,
-        )
+            client.create(
+                'worksheet-permissions',
+                {
+                    'group': JsonApiRelationship('groups', group['id']),
+                    'worksheet': JsonApiRelationship('worksheets', worksheet_uuid),
+                    'permission': new_permission,
+                },
+            )
+
+            print(
+                "Group %s has %s permission on worksheet %s."
+                % (
+                    self.simple_group_str(group),
+                    permission_str(new_permission),
+                    self.worksheet_url_and_name(worksheet),
+                ),
+                file=self.stdout,
+            )
 
     @Commands.command(
         'chown',
@@ -3982,18 +4204,27 @@ class BundleCLI(object):
         """
         Change the owner of bundles.
         """
-        args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
-        client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
+        with tracer.start_as_current_span(
+            "chown", kind=trace.SpanKind.CLIENT,
+        ):
 
-        bundle_uuids = self.target_specs_to_bundle_uuids(client, worksheet_uuid, args.bundle_spec)
-        owner_id = client.fetch('users', args.user_spec)['id']
+            args.bundle_spec = spec_util.expand_specs(args.bundle_spec)
+            client, worksheet_uuid = self.parse_client_worksheet_uuid(args.worksheet_spec)
 
-        client.update(
-            'bundles',
-            [{'id': id_, 'owner': JsonApiRelationship('users', owner_id)} for id_ in bundle_uuids],
-        )
-        for uuid in bundle_uuids:
-            print(uuid, file=self.stdout)
+            bundle_uuids = self.target_specs_to_bundle_uuids(
+                client, worksheet_uuid, args.bundle_spec
+            )
+            owner_id = client.fetch('users', args.user_spec)['id']
+
+            client.update(
+                'bundles',
+                [
+                    {'id': id_, 'owner': JsonApiRelationship('users', owner_id)}
+                    for id_ in bundle_uuids
+                ],
+            )
+            for uuid in bundle_uuids:
+                print(uuid, file=self.stdout)
 
     #############################################################################
     # CLI methods for commands related to users follow!
@@ -4043,38 +4274,42 @@ class BundleCLI(object):
         """
         Edit properties of users.
         """
-        if args.grant_access and args.remove_access:
-            raise UsageError('Can\'t both grant and remove access for a user.')
-        client = self.manager.current_client()
-
-        # Build user info
-        user_info = {
-            key: getattr(args, key)
-            for key in ('first_name', 'last_name', 'affiliation', 'url')
-            if getattr(args, key) is not None
-        }
-        if args.time_quota is not None:
-            user_info['time_quota'] = formatting.parse_duration(args.time_quota)
-        if args.parallel_run_quota is not None:
-            user_info['parallel_run_quota'] = args.parallel_run_quota
-        if args.disk_quota is not None:
-            user_info['disk_quota'] = formatting.parse_size(args.disk_quota)
-        if args.grant_access:
-            user_info['has_access'] = True
-        if args.remove_access:
-            user_info['has_access'] = False
-        if not user_info:
-            raise UsageError("No fields to update.")
-
-        # Send update request
-        if args.user_spec is None:
-            # If user id is not specified, update the authenticated user
-            user = client.update_authenticated_user(user_info)
-        else:
-            # Resolve user id from user spec
-            user_info['id'] = client.fetch('users', args.user_spec)['id']
-            user = client.update('users', user_info)
-        self.print_user_info(user)
+        with tracer.start_as_current_span(
+            "uedit", kind=trace.SpanKind.CLIENT,
+        ):
+
+            if args.grant_access and args.remove_access:
+                raise UsageError('Can\'t both grant and remove access for a user.')
+            client = self.manager.current_client()
+
+            # Build user info
+            user_info = {
+                key: getattr(args, key)
+                for key in ('first_name', 'last_name', 'affiliation', 'url')
+                if getattr(args, key) is not None
+            }
+            if args.time_quota is not None:
+                user_info['time_quota'] = formatting.parse_duration(args.time_quota)
+            if args.parallel_run_quota is not None:
+                user_info['parallel_run_quota'] = args.parallel_run_quota
+            if args.disk_quota is not None:
+                user_info['disk_quota'] = formatting.parse_size(args.disk_quota)
+            if args.grant_access:
+                user_info['has_access'] = True
+            if args.remove_access:
+                user_info['has_access'] = False
+            if not user_info:
+                raise UsageError("No fields to update.")
+
+            # Send update request
+            if args.user_spec is None:
+                # If user id is not specified, update the authenticated user
+                user = client.update_authenticated_user(user_info)
+            else:
+                # Resolve user id from user spec
+                user_info['id'] = client.fetch('users', args.user_spec)['id']
+                user = client.update('users', user_info)
+            self.print_user_info(user)
 
     @Commands.command(
         'uls',
@@ -4112,23 +4347,27 @@ class BundleCLI(object):
         Search for specific users.
         If no argument is passed, we assume the user is searching for a keyword of an empty string.
         """
-        client = self.manager.current_client()
-        users = client.fetch('users', params={'keywords': args.keywords or ''})
-        # Print direct numeric result
-        if 'meta' in users:
-            print(users['meta']['results'], file=self.stdout)
-            return
+        with tracer.start_as_current_span(
+            "uls", kind=trace.SpanKind.CLIENT,
+        ):
 
-        # Print table
-        if len(users) > 0:
-            if args.field:
-                columns = args.field.split(',')
+            client = self.manager.current_client()
+            users = client.fetch('users', params={'keywords': args.keywords or ''})
+            # Print direct numeric result
+            if 'meta' in users:
+                print(users['meta']['results'], file=self.stdout)
+                return
+
+            # Print table
+            if len(users) > 0:
+                if args.field:
+                    columns = args.field.split(',')
+                else:
+                    columns = ('user_name', 'first_name', 'last_name', 'affiliation', 'date_joined')
+                self.print_result_limit_info(len(users))
+                self.uls_print_table(columns, users, user_defined=args.field)
             else:
-                columns = ('user_name', 'first_name', 'last_name', 'affiliation', 'date_joined')
-            self.print_result_limit_info(len(users))
-            self.uls_print_table(columns, users, user_defined=args.field)
-        else:
-            print(NO_RESULTS_FOUND, file=self.stderr)
+                print(NO_RESULTS_FOUND, file=self.stderr)
 
     @Commands.command(
         'uinfo',
@@ -4146,12 +4385,16 @@ class BundleCLI(object):
         """
         Edit properties of users.
         """
-        client = self.manager.current_client()
-        if args.user_spec is None:
-            user = client.fetch('user')
-        else:
-            user = client.fetch('users', args.user_spec)
-        self.print_user_info(user, args.field)
+        with tracer.start_as_current_span(
+            "uinfo", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client = self.manager.current_client()
+            if args.user_spec is None:
+                user = client.fetch('user')
+            else:
+                user = client.fetch('users', args.user_spec)
+            self.print_user_info(user, args.field)
 
     def print_users_info(self, users):
         for user in users:
@@ -4229,11 +4472,15 @@ class BundleCLI(object):
         """
         Delete user.
         """
-        client = self.manager.current_client()
-        user = client.fetch('users', args.user_spec)
+        with tracer.start_as_current_span(
+            "ufarewell", kind=trace.SpanKind.CLIENT,
+        ):
+
+            client = self.manager.current_client()
+            user = client.fetch('users', args.user_spec)
 
-        client.delete('users', user['id'])
-        print('Deleted user %s(%s).' % (user['user_name'], user['id']), file=self.stdout)
+            client.delete('users', user['id'])
+            print('Deleted user %s(%s).' % (user['user_name'], user['id']), file=self.stdout)
 
     #############################################################################
     # Local-only commands follow!
@@ -4258,32 +4505,38 @@ class BundleCLI(object):
         ),
     )
     def do_events_command(self, args):
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-
-        # Build query
-        query_info = {
-            'user': args.user,
-            'command': args.match_command,
-            'args': args.args,
-            'uuid': args.uuid,
-            'count': args.count,
-            'group_by': args.group_by,
-        }
-        info = self.manager.model().get_events_log_info(query_info, args.offset, args.limit)
-        if 'counts' in info:
-            for row in info['counts']:
-                print('\t'.join(map(str, list(row))), file=self.stdout)
-        if 'events' in info:
-            for event in info['events']:
-                row = [
-                    event.end_time.strftime('%Y-%m-%d %X') if event.end_time is not None else '',
-                    '%.3f' % event.duration if event.duration is not None else '',
-                    '%s(%s)' % (event.user_name, event.user_id),
-                    event.command,
-                    event.args,
-                ]
-                print('\t'.join(row), file=self.stdout)
+        with tracer.start_as_current_span(
+            "events", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+
+            # Build query
+            query_info = {
+                'user': args.user,
+                'command': args.match_command,
+                'args': args.args,
+                'uuid': args.uuid,
+                'count': args.count,
+                'group_by': args.group_by,
+            }
+            info = self.manager.model().get_events_log_info(query_info, args.offset, args.limit)
+            if 'counts' in info:
+                for row in info['counts']:
+                    print('\t'.join(map(str, list(row))), file=self.stdout)
+            if 'events' in info:
+                for event in info['events']:
+                    row = [
+                        event.end_time.strftime('%Y-%m-%d %X')
+                        if event.end_time is not None
+                        else '',
+                        '%.3f' % event.duration if event.duration is not None else '',
+                        '%s(%s)' % (event.user_name, event.user_id),
+                        event.command,
+                        event.args,
+                    ]
+                    print('\t'.join(row), file=self.stdout)
 
     @Commands.command(
         'reset',
@@ -4298,12 +4551,16 @@ class BundleCLI(object):
         """
         Delete everything - be careful!
         """
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-        if not args.commit:
-            raise UsageError('If you really want to delete EVERYTHING, use --commit')
-        print('Deleting entire database...', file=self.stdout)
-        self.manager.model()._reset()
+        with tracer.start_as_current_span(
+            "reset", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+            if not args.commit:
+                raise UsageError('If you really want to delete EVERYTHING, use --commit')
+            print('Deleting entire database...', file=self.stdout)
+            self.manager.model()._reset()
 
     @Commands.command(
         'bs-add-partition',
@@ -4329,15 +4586,20 @@ class BundleCLI(object):
         """
         Add the specified target location as a new partition available for use by the filesystem.
         """
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-        # This operation only allowed if we're using MultiDiskBundleStore
-        if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
-            print(
-                "This command can only be run when MultiDiskBundleStore is in use.", file=sys.stderr
-            )
-            sys.exit(1)
-        self.manager.bundle_store().add_partition(args.path, args.name)
+        with tracer.start_as_current_span(
+            "bs_add_partition", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+            # This operation only allowed if we're using MultiDiskBundleStore
+            if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
+                print(
+                    "This command can only be run when MultiDiskBundleStore is in use.",
+                    file=sys.stderr,
+                )
+                sys.exit(1)
+            self.manager.bundle_store().add_partition(args.path, args.name)
 
     @Commands.command(
         'bs-rm-partition',
@@ -4345,14 +4607,19 @@ class BundleCLI(object):
         arguments=(Commands.Argument('partition', help='The partition you want to remove.'),),
     )
     def do_rm_partition_command(self, args):
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-        if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
-            print(
-                "This command can only be run when MultiDiskBundleStore is in use.", file=sys.stderr
-            )
-            sys.exit(1)
-        self.manager.bundle_store().rm_partition(args.partition)
+        with tracer.start_as_current_span(
+            "bs_rm_partition", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+            if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
+                print(
+                    "This command can only be run when MultiDiskBundleStore is in use.",
+                    file=sys.stderr,
+                )
+                sys.exit(1)
+            self.manager.bundle_store().rm_partition(args.partition)
 
     @Commands.command(
         'bs-ls-partitions',
@@ -4360,14 +4627,19 @@ class BundleCLI(object):
         arguments=(),
     )
     def do_ls_partitions_command(self, args):
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-        if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
-            print(
-                "This command can only be run when MultiDiskBundleStore is in use.", file=sys.stderr
-            )
-            sys.exit(1)
-        self.manager.bundle_store().ls_partitions()
+        with tracer.start_as_current_span(
+            "bs_ls_partitions", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+            if not isinstance(self.manager.bundle_store(), MultiDiskBundleStore):
+                print(
+                    "This command can only be run when MultiDiskBundleStore is in use.",
+                    file=sys.stderr,
+                )
+                sys.exit(1)
+            self.manager.bundle_store().ls_partitions()
 
     @Commands.command(
         'bs-health-check',
@@ -4394,12 +4666,16 @@ class BundleCLI(object):
         ),
     )
     def do_bs_health_check(self, args):
-        self._fail_if_headless(args)
-        self._fail_if_not_local(args)
-        print('Performing Health Check...', file=sys.stderr)
-        self.manager.bundle_store().health_check(
-            self.manager.model(), args.force, args.data_hash, args.repair
-        )
+        with tracer.start_as_current_span(
+            "bs_health_check", kind=trace.SpanKind.CLIENT,
+        ):
+
+            self._fail_if_headless(args)
+            self._fail_if_not_local(args)
+            print('Performing Health Check...', file=sys.stderr)
+            self.manager.bundle_store().health_check(
+                self.manager.model(), args.force, args.data_hash, args.repair
+            )
 
     def _fail_if_headless(self, args):
         if self.headless:
diff --git a/codalab/model/bundle_model.py b/codalab/model/bundle_model.py
index a121c91c..d08be99b 100644
--- a/codalab/model/bundle_model.py
+++ b/codalab/model/bundle_model.py
@@ -9,6 +9,7 @@ import re
 import time
 import logging
 import json
+import functools
 
 from dateutil import parser
 from uuid import uuid4
@@ -62,12 +63,27 @@ from codalab.rest.util import get_group_info
 from codalab.worker.bundle_state import State
 from codalab.worker.worker_run_state import RunStage
 from typing import List
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 logger = logging.getLogger(__name__)
 
 SEARCH_KEYWORD_REGEX = re.compile('^([\.\w/]*)=(.*)$')
 SEARCH_RESULTS_LIMIT = 10
 
+def otel(func):
+    """Wrap the function in an opentelemetry span with the function anme"""
+    @functools.wraps(func)
+    def wrapper_otel(*args, **kwargs):
+        with tracer.start_as_current_span(
+                func.__name__,
+                kind=trace.SpanKind.SERVER,
+        ):
+            return func(*args, **kwargs)
+    return wrapper_otel
 
 def str_key_dict(row):
     """
@@ -105,6 +121,7 @@ class BundleModel(object):
     def decode_str(self, value):
         raise NotImplementedError
 
+    @otel
     def _reset(self):
         """
         Do a drop / create table to clear and reset the schema of all tables.
@@ -113,6 +130,7 @@ class BundleModel(object):
         db_metadata.drop_all(self.engine)
         self.create_tables()
 
+    @otel
     def create_tables(self):
         """
         Create all CodaLab bundle tables if they do not already exist.
@@ -179,7 +197,7 @@ class BundleModel(object):
     # ==========================================================================
     # Bundle info accessor methods
     # ==========================================================================
-
+    @otel
     def get_bundle(self, uuid):
         """
         Retrieve a bundle from the database given its uuid.
@@ -192,6 +210,7 @@ class BundleModel(object):
             raise IntegrityError('Found multiple bundles with uuid %s' % (uuid,))
         return bundles[0]
 
+    @otel
     def get_bundle_names(self, uuids):
         """
         Fetch the bundle names of the given uuids.
@@ -199,6 +218,7 @@ class BundleModel(object):
         """
         return self.get_bundle_metadata(uuids, "name")
 
+    @otel
     def get_bundle_metadata(self, uuids, metadata_key):
         """
         Fetch a single metadata value from the bundles referenced
@@ -220,6 +240,7 @@ class BundleModel(object):
             ).fetchall()
             return dict((row.bundle_uuid, row.metadata_value) for row in rows)
 
+    @otel
     def get_owner_ids(self, table, uuids):
         """
         Fetch the owners of the given uuids (for either bundles or worksheets).
@@ -233,12 +254,15 @@ class BundleModel(object):
             ).fetchall()
             return dict((row.uuid, row.owner_id) for row in rows)
 
+    @otel
     def get_bundle_owner_ids(self, uuids):
         return self.get_owner_ids(cl_bundle, uuids)
 
+    @otel
     def get_worksheet_owner_ids(self, uuids):
         return self.get_owner_ids(cl_worksheet, uuids)
 
+    @otel
     def get_bundle_worker(self, uuid):
         """
         Returns information about the worker that the given bundle is running
@@ -265,6 +289,7 @@ class BundleModel(object):
                 'socket_id': worker_row.socket_id,
             }
 
+    @otel
     def get_children_uuids(self, uuids):
         """
         Get all bundles that depend on the bundle with the given uuids.
@@ -281,6 +306,7 @@ class BundleModel(object):
             result[row.parent_uuid].append(row.child_uuid)
         return result
 
+    @otel
     def get_host_worksheet_uuids(self, bundle_uuids, max_worksheets):
         """
         Get up to n host_worksheet uuids per bundle uuid. n of 0 will return an empty dictionary.
@@ -310,6 +336,7 @@ class BundleModel(object):
             ).fetchall()
         return dict((row.bundle_uuid, row.worksheet_uuids.split(',')) for row in rows)
 
+    @otel
     def get_all_host_worksheet_uuids(self, bundle_uuids):
         """
         Return list of all worksheet uuids that contain the given bundle_uuids.
@@ -330,6 +357,7 @@ class BundleModel(object):
             result[uuid] = list(set(result[uuid]))
         return result
 
+    @otel
     def get_self_and_descendants(self, uuids, depth):
         """
         Get all bundles that depend on bundles with the given uuids.
@@ -351,6 +379,7 @@ class BundleModel(object):
             depth -= 1
         return visited
 
+    @otel
     def search_bundles(self, user_id, keywords):
         """
         Returns a bundle search result dict where:
@@ -660,6 +689,7 @@ class BundleModel(object):
             return {'result': result, 'is_aggregate': True}
         return {'result': result, 'is_aggregate': False}
 
+    @otel
     def get_bundle_uuids(self, conditions, max_results):
         """
         Returns a list of bundle_uuids that have match the conditions.
@@ -710,6 +740,7 @@ class BundleModel(object):
 
         return self._execute_query(query)
 
+    @otel
     def get_memoized_bundles(self, user_id, command, dependencies):
         """
         Get a list of bundle UUIDs that match with input command and dependencies in the order of they were created.
@@ -786,6 +817,7 @@ class BundleModel(object):
 
         return self._execute_query(query)
 
+    @otel
     def batch_get_bundles(self, **kwargs):
         """
         Return a list of bundles given a SQLAlchemy clause on the cl_bundle table.
@@ -832,6 +864,7 @@ class BundleModel(object):
     # Server-side bundle state machine methods
     # ==========================================================================
 
+    @otel
     def transition_bundle_starting(self, bundle, user_id, worker_id):
         """
         Transitions bundle to STARTING state:
@@ -871,6 +904,7 @@ class BundleModel(object):
 
             return True
 
+    @otel
     def transition_bundle_staged(self, bundle):
         """
         Transitions bundle to STAGED state:
@@ -900,6 +934,7 @@ class BundleModel(object):
             )
             return True
 
+    @otel
     def transition_bundle_preparing(self, bundle, user_id, worker_id, start_time, remote):
         """
         Transitions bundle to PREPARING state:
@@ -935,6 +970,7 @@ class BundleModel(object):
 
         return True
 
+    @otel
     def transition_bundle_running(self, bundle, worker_run, row, user_id, worker_id, connection):
         """
         Transitions bundle to RUNNING state:
@@ -996,6 +1032,7 @@ class BundleModel(object):
 
         return True
 
+    @otel
     def transition_bundle_worker_offline(self, bundle):
         """
         Transitions bundle to WORKER_OFFLINE state:
@@ -1036,6 +1073,7 @@ class BundleModel(object):
             self.update_bundle(bundle, bundle_update, connection)
         return True
 
+    @otel
     def transition_bundle_finalizing(self, bundle, worker_run, connection):
         """
         Transitions bundle to FINALIZING state:
@@ -1058,6 +1096,7 @@ class BundleModel(object):
         self.update_bundle(bundle, bundle_update, connection)
         return True
 
+    @otel
     def transition_bundle_finished(self, bundle, bundle_location):
         """
         Transitions bundle to READY or FAILED state:
@@ -1093,6 +1132,7 @@ class BundleModel(object):
     # Bundle state machine helper functions
     # ==========================================================================
 
+    @otel
     def update_disk_metadata(self, bundle, bundle_location, enforce_disk_quota=False):
         """
         Computes the disk use and data hash of the given bundle.
@@ -1119,6 +1159,7 @@ class BundleModel(object):
         self.update_bundle(bundle, bundle_update)
         self.update_user_disk_used(bundle.owner_id)
 
+    @otel
     def bundle_checkin(self, bundle, worker_run, user_id, worker_id):
         """
         Updates the database tables with the most recent bundle information from worker
@@ -1150,6 +1191,7 @@ class BundleModel(object):
             # State isn't one we can check in for
             return False
 
+    @otel
     def save_bundle(self, bundle):
         """
         Save a bundle. On success, sets the Bundle object's id from the result.
@@ -1168,6 +1210,7 @@ class BundleModel(object):
             self.do_multirow_insert(connection, cl_bundle_metadata, metadata_values)
             bundle.id = result.lastrowid
 
+    @otel
     def update_bundle(self, bundle, update, connection=None, delete=False):
         """
         For each key-value pair in the update dictionary, add or update key-value pair. Note
@@ -1237,6 +1280,7 @@ class BundleModel(object):
             with self.engine.begin() as connection:
                 do_update(connection)
 
+    @otel
     def get_bundle_dependencies(self, uuid):
         with self.engine.begin() as connection:
             dependency_rows = connection.execute(
@@ -1246,12 +1290,14 @@ class BundleModel(object):
             ).fetchall()
         return [Dependency(dep_val) for dep_val in dependency_rows]
 
+    @otel
     def get_bundle_state(self, uuid):
         result_dict = self.get_bundle_states([uuid])
         if uuid not in result_dict:
             raise NotFoundError('Could not find bundle with uuid %s' % uuid)
         return result_dict[uuid]
 
+    @otel
     def get_bundle_states(self, uuids):
         """
         Return {uuid: state, ...}
@@ -1262,6 +1308,7 @@ class BundleModel(object):
             ).fetchall()
             return dict((r.uuid, r.state) for r in rows)
 
+    @otel
     def get_bundle_storage_info(self, uuid):
         """
         Return (storage_type, is_dir) for the bundle
@@ -1272,6 +1319,7 @@ class BundleModel(object):
             return None, None
         return result_dict[uuid]
 
+    @otel
     def get_bundle_storage_infos(self, uuids):
         """
         Return {uuid: (storage_type, is_dir), ...}
@@ -1284,6 +1332,7 @@ class BundleModel(object):
             ).fetchall()
             return dict((r.uuid, (r.storage_type, r.is_dir)) for r in rows)
 
+    @otel
     def delete_bundles(self, uuids):
         """
         Delete bundles with the given uuids.
@@ -1312,6 +1361,7 @@ class BundleModel(object):
             connection.execute(cl_worker_run.delete().where(cl_worker_run.c.run_uuid.in_(uuids)))
             connection.execute(cl_bundle.delete().where(cl_bundle.c.uuid.in_(uuids)))
 
+    @otel
     def remove_data_hash_references(self, uuids):
         with self.engine.begin() as connection:
             connection.execute(
@@ -1322,6 +1372,7 @@ class BundleModel(object):
     # Worksheet-related model methods follow!
     # ==========================================================================
 
+    @otel
     def get_worksheet(self, uuid, fetch_items):
         """
         Get a worksheet given its uuid.
@@ -1334,6 +1385,7 @@ class BundleModel(object):
             raise IntegrityError('Found multiple worksheets with uuid %s' % (uuid,))
         return worksheets[0]
 
+    @otel
     def batch_get_worksheets(self, fetch_items, **kwargs):
         """
         Get a list of worksheets, all of which satisfy the clause given by kwargs.
@@ -1390,6 +1442,7 @@ class BundleModel(object):
                 worksheet_values[item_row['worksheet_uuid']]['items'].append(item_row)
         return [Worksheet(value) for value in worksheet_values.values()]
 
+    @otel
     def search_worksheets(self, user_id, keywords):
         """
         Return a list of row dicts, one per worksheet. These dicts do NOT contain
@@ -1604,6 +1657,7 @@ class BundleModel(object):
             row_dicts.append(row)
         return row_dicts
 
+    @otel
     def new_worksheet(self, worksheet):
         """
         Save the given (empty) worksheet to the database. On success, set its id.
@@ -1622,6 +1676,7 @@ class BundleModel(object):
             result = connection.execute(cl_worksheet.insert().values(worksheet_value))
             worksheet.id = result.lastrowid
 
+    @otel
     def add_worksheet_items(self, worksheet_uuid, items, after_sort_key=None, replace=[]):
         """
         Add worksheet items *items* to the position *after_sort_key* to the worksheet,
@@ -1689,6 +1744,7 @@ class BundleModel(object):
             self.do_multirow_insert(connection, cl_worksheet_item, items_to_insert)
         self.update_worksheet_last_modified_date(worksheet_uuid)
 
+    @otel
     def add_shadow_worksheet_items(self, old_bundle_uuid, new_bundle_uuid):
         """
         For each occurrence of old_bundle_uuid in any worksheet, add
@@ -1715,6 +1771,7 @@ class BundleModel(object):
                 new_items.append(new_item)
                 connection.execute(cl_worksheet_item.insert().values(new_item))
 
+    @otel
     def update_worksheet_item_value(self, id, value):
         """
         Update the value of a worksheet item, aka updating a markdown item.
@@ -1730,6 +1787,7 @@ class BundleModel(object):
             else:
                 connection.execute(cl_worksheet_item.delete().where(cl_worksheet_item.c.id == id))
 
+    @otel
     def update_worksheet_items(self, worksheet_uuid, last_item_id, length, new_items):
         """
         Updates the worksheet with the given uuid. If there were exactly
@@ -1772,6 +1830,7 @@ class BundleModel(object):
             self.do_multirow_insert(connection, cl_worksheet_item, new_item_values)
         self.update_worksheet_last_modified_date(worksheet_uuid)
 
+    @otel
     def update_worksheet_last_modified_date(self, worksheet_id):
         """
         Update worksheet's last modified date to now.
@@ -1780,6 +1839,7 @@ class BundleModel(object):
         worksheet = self.get_worksheet(worksheet_id, fetch_items=False)
         self.update_worksheet_metadata(worksheet, {})
 
+    @otel
     def update_worksheet_metadata(self, worksheet, info):
         """
         Update the given worksheet's metadata.
@@ -1816,6 +1876,7 @@ class BundleModel(object):
                     cl_worksheet.update().where(cl_worksheet.c.uuid == worksheet.uuid).values(info)
                 )
 
+    @otel
     def delete_worksheet(self, worksheet_uuid):
         """
         Delete the worksheet with the given uuid.
@@ -1845,6 +1906,7 @@ class BundleModel(object):
     # Group and permission-related methods
     # ===========================================================================
 
+    @otel
     def _create_default_groups(self):
         """
         Create system-defined groups. This is called by create_tables.
@@ -1863,6 +1925,7 @@ class BundleModel(object):
             group_dict = groups[0]
         self.public_group_uuid = group_dict['uuid']
 
+    @otel
     def create_group(self, group_dict):
         """
         Create the group specified by the given row dict.
@@ -1873,6 +1936,7 @@ class BundleModel(object):
             group_dict['id'] = result.lastrowid
         return group_dict
 
+    @otel
     def batch_get_groups(self, **kwargs):
         """
         Get a list of groups, all of which satisfy the clause given by kwargs.
@@ -1885,6 +1949,7 @@ class BundleModel(object):
         values = {row.uuid: str_key_dict(row) for row in rows}
         return [value for value in values.values()]
 
+    @otel
     def batch_get_all_groups(self, spec_filters, group_filters, user_group_filters):
         """
         Get a list of groups by querying the group table and/or the user_group table.
@@ -1950,6 +2015,7 @@ class BundleModel(object):
             values = {row['uuid']: row for row in rows}
             return [value for value in values.values()]
 
+    @otel
     def delete_group(self, uuid):
         """
         Delete the group with the given uuid.
@@ -1968,6 +2034,7 @@ class BundleModel(object):
             connection.execute(cl_user_group.delete().where(cl_user_group.c.group_uuid == uuid))
             connection.execute(cl_group.delete().where(cl_group.c.uuid == uuid))
 
+    @otel
     def add_user_in_group(self, user_id, group_uuid, is_admin):
         """
         Add user as a member of a group.
@@ -1978,6 +2045,7 @@ class BundleModel(object):
             row['id'] = result.lastrowid
         return row
 
+    @otel
     def delete_user_in_group(self, user_id, group_uuid):
         """
         Add user as a member of a group.
@@ -1989,6 +2057,7 @@ class BundleModel(object):
                 .where(cl_user_group.c.group_uuid == group_uuid)
             )
 
+    @otel
     def update_user_in_group(self, user_id, group_uuid, is_admin):
         """
         Update user role in group.
@@ -2001,6 +2070,7 @@ class BundleModel(object):
                 .values({'is_admin': is_admin})
             )
 
+    @otel
     def batch_get_user_in_group(self, **kwargs):
         """
         Return list of user-group entries matching the specified |kwargs|.
@@ -2014,6 +2084,7 @@ class BundleModel(object):
                 return []
         return [str_key_dict(row) for row in rows]
 
+    @otel
     def get_user_groups(self, user_id):
         """
         Get the list of groups that the user belongs to
@@ -2025,6 +2096,7 @@ class BundleModel(object):
             groups += [row['group_uuid'] for row in self.batch_get_user_in_group(user_id=user_id)]
         return groups
 
+    @otel
     def set_group_permission(self, table, group_uuid, object_uuid, new_permission):
         """
         Atomically set group permission on object. Does NOT check for user
@@ -2072,16 +2144,19 @@ class BundleModel(object):
                         .where(table.c.object_uuid == object_uuid)
                     )
 
+    @otel
     def set_group_bundle_permission(self, group_uuid, bundle_uuid, new_permission):
         return self.set_group_permission(
             cl_group_bundle_permission, group_uuid, bundle_uuid, new_permission
         )
 
+    @otel
     def set_group_worksheet_permission(self, group_uuid, worksheet_uuid, new_permission):
         return self.set_group_permission(
             cl_group_worksheet_permission, group_uuid, worksheet_uuid, new_permission
         )
 
+    @otel
     def batch_get_group_permissions(self, table, user_id, object_uuids):
         """
         Return map from object_uuid to list of {group_uuid: ..., group_name: ..., permission: ...}
@@ -2115,14 +2190,17 @@ class BundleModel(object):
                 )
             return result
 
+    @otel
     def batch_get_group_bundle_permissions(self, user_id, bundle_uuids):
         return self.batch_get_group_permissions(cl_group_bundle_permission, user_id, bundle_uuids)
 
+    @otel
     def batch_get_group_worksheet_permissions(self, user_id, worksheet_uuids):
         return self.batch_get_group_permissions(
             cl_group_worksheet_permission, user_id, worksheet_uuids
         )
 
+    @otel
     def get_group_permissions(self, table, user_id, object_uuid):
         """
         Return list of {group_uuid: ..., group_name: ..., permission: ...} entries for the given object.
@@ -2130,12 +2208,15 @@ class BundleModel(object):
         """
         return self.batch_get_group_permissions(table, user_id, [object_uuid])[object_uuid]
 
+    @otel
     def get_group_bundle_permissions(self, user_id, bundle_uuid):
         return self.get_group_permissions(cl_group_bundle_permission, user_id, bundle_uuid)
 
+    @otel
     def get_group_worksheet_permissions(self, user_id, worksheet_uuid):
         return self.get_group_permissions(cl_group_worksheet_permission, user_id, worksheet_uuid)
 
+    @otel
     def get_user_permissions(self, table, user_id, object_uuids, owner_ids):
         """
         Gets the set of permissions granted to the given user on the given objects.
@@ -2169,11 +2250,13 @@ class BundleModel(object):
                         )
         return object_permissions
 
+    @otel
     def get_user_bundle_permissions(self, user_id, bundle_uuids, owner_ids):
         return self.get_user_permissions(
             cl_group_bundle_permission, user_id, bundle_uuids, owner_ids
         )
 
+    @otel
     def get_user_worksheet_permissions(self, user_id, worksheet_uuids, owner_ids):
         return self.get_user_permissions(
             cl_group_worksheet_permission, user_id, worksheet_uuids, owner_ids
@@ -2181,6 +2264,7 @@ class BundleModel(object):
 
     # Operations on the query log
     @staticmethod
+    @otel
     def date_handler(obj):
         """
         Helper function to serialize DataTime
@@ -2191,12 +2275,14 @@ class BundleModel(object):
     # User-related methods follow!
     # ===========================================================================
 
+    @otel
     def find_user(self, user_spec, check_active=True):
         user = self.get_user(user_id=user_spec, username=user_spec, check_active=check_active)
         if user is None:
             raise NotFoundError("User matching %r not found" % user_spec)
         return user
 
+    @otel
     def get_user(self, user_id=None, username=None, check_active=True):
         """
         Get user.
@@ -2218,6 +2304,7 @@ class BundleModel(object):
             return result['results'][0]
         return None
 
+    @otel
     def get_users(
         self,
         keywords=None,
@@ -2379,6 +2466,7 @@ class BundleModel(object):
             results = [User(row) for row in rows]
             return {'results': results, 'is_aggregate': False}
 
+    @otel
     def user_exists(self, username, email):
         """
         Check whether user with given username or email exists.
@@ -2395,6 +2483,7 @@ class BundleModel(object):
 
         return row is not None and row.is_active
 
+    @otel
     def add_user(
         self,
         username,
@@ -2470,6 +2559,7 @@ class BundleModel(object):
 
         return user_id, verification_key
 
+    @otel
     def delete_user(self, user_id=None):
         """
         Delete the user with the given uuid.
@@ -2504,6 +2594,7 @@ class BundleModel(object):
             # Delete User
             connection.execute(cl_user.delete().where(cl_user.c.user_id == user_id))
 
+    @otel
     def get_verification_key(self, user_id):
         """
         Get verification key for given user.
@@ -2539,6 +2630,7 @@ class BundleModel(object):
 
         return key
 
+    @otel
     def verify_user(self, key):
         """
         Verify user with given verification key.
@@ -2568,6 +2660,7 @@ class BundleModel(object):
 
         return True
 
+    @otel
     def is_verified(self, user_id):
         """
         Checks if the user is verified or not.
@@ -2583,6 +2676,7 @@ class BundleModel(object):
 
             return verified_row is not None
 
+    @otel
     def new_user_reset_code(self, user_id):
         """
         Generate a new password reset code.
@@ -2601,6 +2695,7 @@ class BundleModel(object):
 
         return code
 
+    @otel
     def get_reset_code_user_id(self, code, delete=False):
         """
         Check if reset code is valid.
@@ -2628,6 +2723,7 @@ class BundleModel(object):
 
         return user_id
 
+    @otel
     def get_user_info(self, user_id, fetch_extra=False):
         """
         Return the user info corresponding to |user_id|.
@@ -2656,6 +2752,7 @@ class BundleModel(object):
                 del user_info['last_login']
         return user_info
 
+    @otel
     def update_user_info(self, user_info):
         """
         Update the given user's info with |user_info|.
@@ -2665,6 +2762,7 @@ class BundleModel(object):
                 cl_user.update().where(cl_user.c.user_id == user_info['user_id']).values(user_info)
             )
 
+    @otel
     def increment_user_time_used(self, user_id, amount):
         """
         User used some time.
@@ -2673,6 +2771,7 @@ class BundleModel(object):
         user_info['time_used'] += amount
         self.update_user_info(user_info)
 
+    @otel
     def get_user_time_quota_left(self, user_id, user_info=None):
         if not user_info:
             user_info = self.get_user_info(user_id)
@@ -2680,6 +2779,7 @@ class BundleModel(object):
         time_used = user_info['time_used']
         return time_quota - time_used
 
+    @otel
     def get_user_parallel_run_quota_left(self, user_id, user_info=None):
         if not user_info:
             user_info = self.get_user_info(user_id)
@@ -2699,12 +2799,14 @@ class BundleModel(object):
             ).fetchall()
         return parallel_run_quota - len(active_runs)
 
+    @otel
     def update_user_last_login(self, user_id):
         """
         Update user's last login date to now.
         """
         self.update_user_info({'user_id': user_id, 'last_login': datetime.datetime.utcnow()})
 
+    @otel
     def _get_disk_used(self, user_id):
         # TODO(Ashwin): don't include linked bundles
         return (
@@ -2714,11 +2816,13 @@ class BundleModel(object):
             or 0
         )
 
+    @otel
     def get_user_disk_quota_left(self, user_id, user_info=None):
         if not user_info:
             user_info = self.get_user_info(user_id)
         return user_info['disk_quota'] - user_info['disk_used']
 
+    @otel
     def update_user_disk_used(self, user_id):
         user_info = self.get_user_info(user_id)
         # Compute from scratch for simplicity
@@ -2729,6 +2833,7 @@ class BundleModel(object):
     # OAuth-related methods follow!
     # ===========================================================================
 
+    @otel
     def _create_default_clients(self):
         DEFAULT_CLIENTS = [
             ('codalab_cli_client', 'CodaLab CLI'),
@@ -2751,6 +2856,7 @@ class BundleModel(object):
                     )
                 )
 
+    @otel
     def get_oauth2_client(self, client_id):
         with self.engine.begin() as connection:
             row = connection.execute(
@@ -2762,12 +2868,14 @@ class BundleModel(object):
 
         return OAuth2Client(self, **row)
 
+    @otel
     def save_oauth2_client(self, client):
         with self.engine.begin() as connection:
             result = connection.execute(oauth2_client.insert().values(client.columns))
             client.id = result.lastrowid
         return client
 
+    @otel
     def get_oauth2_token(self, access_token=None, refresh_token=None):
         if access_token is not None:
             clause = oauth2_token.c.access_token == access_token
@@ -2784,6 +2892,7 @@ class BundleModel(object):
 
         return OAuth2Token(self, **row)
 
+    @otel
     def find_oauth2_token(self, client_id, user_id, expires_after):
         with self.engine.begin() as connection:
             row = connection.execute(
@@ -2803,12 +2912,14 @@ class BundleModel(object):
 
         return OAuth2Token(self, **row)
 
+    @otel
     def save_oauth2_token(self, token):
         with self.engine.begin() as connection:
             result = connection.execute(oauth2_token.insert().values(token.columns))
             token.id = result.lastrowid
         return token
 
+    @otel
     def clear_oauth2_tokens(self, client_id, user_id):
         with self.engine.begin() as connection:
             connection.execute(
@@ -2821,10 +2932,12 @@ class BundleModel(object):
                 )
             )
 
+    @otel
     def delete_oauth2_token(self, token_id):
         with self.engine.begin() as connection:
             connection.execute(oauth2_auth_code.delete().where(oauth2_token.c.id == token_id))
 
+    @otel
     def get_oauth2_auth_code(self, client_id, code):
         with self.engine.begin() as connection:
             row = connection.execute(
@@ -2840,12 +2953,14 @@ class BundleModel(object):
 
         return OAuth2AuthCode(self, **row)
 
+    @otel
     def save_oauth2_auth_code(self, grant):
         with self.engine.begin() as connection:
             result = connection.execute(oauth2_auth_code.insert().values(grant.columns))
             grant.id = result.lastrowid
         return grant
 
+    @otel
     def delete_oauth2_auth_code(self, auth_code_id):
         with self.engine.begin() as connection:
             connection.execute(
@@ -2855,6 +2970,7 @@ class BundleModel(object):
     # ===========================================================================
     # Bundle Store methods follow!
     # ===========================================================================
+    @otel
     def get_bundle_stores(self, user_id: int) -> List[dict]:
         """
         Returns all bundle stores owned by the root user or the current user.
@@ -2893,6 +3009,7 @@ class BundleModel(object):
                 for row in rows
             )
 
+    @otel
     def create_bundle_store(
         self,
         user_id: int,
@@ -2928,6 +3045,7 @@ class BundleModel(object):
             connection.execute(cl_bundle_store.insert().values(bundle_store_value))
         return uuid
 
+    @otel
     def update_bundle_store(self, user_id: int, uuid: str, update_fields: dict) -> None:
         """
         Update a bundle store
@@ -2945,6 +3063,7 @@ class BundleModel(object):
                 .values(update_fields)
             )
 
+    @otel
     def get_bundle_store(self, user_id: int, uuid: str = None, name: str = None) -> dict:
         """
         Return the bundle store corresponding to the specified uuid or name.
@@ -2994,6 +3113,7 @@ class BundleModel(object):
                 'url': row.url,
             }
 
+    @otel
     def delete_bundle_store(self, user_id: int, uuid: str) -> None:
         """
         Delete a bundle store given its uuid. We can only delete the bundle store if there are
@@ -3024,6 +3144,7 @@ class BundleModel(object):
     # Multiple bundle locations methods follow!
     # ===========================================================================
 
+    @otel
     def get_bundle_locations(self, bundle_uuid: str) -> List[dict]:
         """
         Returns all bundle locations associated with the specified bundle.
@@ -3063,6 +3184,7 @@ class BundleModel(object):
                 for row in rows
             ]
 
+    @otel
     def add_bundle_location(self, bundle_uuid: str, bundle_store_uuid: str) -> None:
         """
         Adds a new bundle location to the specified bundle.
@@ -3078,6 +3200,7 @@ class BundleModel(object):
             }
             connection.execute(cl_bundle_location.insert().values(bundle_location_value))
 
+    @otel
     def get_bundle_location(self, bundle_uuid: str, bundle_store_uuid: str) -> dict:
         """
         Returns data about the location associated with the specified bundle and bundle store.
diff --git a/codalab/model/mysql_model.py b/codalab/model/mysql_model.py
index 8f676070..b8ad3512 100644
--- a/codalab/model/mysql_model.py
+++ b/codalab/model/mysql_model.py
@@ -8,6 +8,7 @@ from sqlalchemy.pool import Pool
 
 from codalab.model.bundle_model import BundleModel
 from codalab.common import UsageError
+from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
 
 
 @event.listens_for(Pool, "checkout")
@@ -49,6 +50,7 @@ class MySQLModel(BundleModel):
             pool_recycle=3600,
             encoding='utf-8',
         )
+        SQLAlchemyInstrumentor().instrument(engine=engine)
         super(MySQLModel, self).__init__(engine, default_user_info, root_user_id, system_user_id)
 
     def do_multirow_insert(self, connection, table, values):
diff --git a/codalab/model/sqlite_model.py b/codalab/model/sqlite_model.py
index 6880d4aa..3095be58 100644
--- a/codalab/model/sqlite_model.py
+++ b/codalab/model/sqlite_model.py
@@ -6,6 +6,7 @@ from sqlalchemy import create_engine
 from sqlalchemy.pool import StaticPool
 
 from codalab.model.bundle_model import BundleModel
+from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
 
 
 class SQLiteModel(BundleModel):
@@ -19,4 +20,5 @@ class SQLiteModel(BundleModel):
             connect_args={'check_same_thread': False},
             poolclass=StaticPool,
         )
+        SQLAlchemyInstrumentor().instrument(engine=engine)
         super(SQLiteModel, self).__init__(engine, default_user_info, root_user_id, system_user_id)
diff --git a/codalab/model/worker_model.py b/codalab/model/worker_model.py
index 468b42b9..ebf6ab28 100644
--- a/codalab/model/worker_model.py
+++ b/codalab/model/worker_model.py
@@ -5,6 +5,7 @@ import logging
 import os
 import socket
 import time
+import functools
 
 from sqlalchemy import and_, select
 
@@ -16,9 +17,23 @@ from codalab.model.tables import (
     worker_run as cl_worker_run,
     worker_dependency as cl_worker_dependency,
 )
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
 
+tracer = trace.get_tracer(__name__)
 logger = logging.getLogger(__name__)
 
+def otel(func):
+    """Wrap the function in an opentelemetry span with the function anme"""
+    @functools.wraps(func)
+    def wrapper_otel(*args, **kwargs):
+        with tracer.start_as_current_span(
+                func.__name__,
+                kind=trace.SpanKind.SERVER,
+        ):
+            return func(*args, **kwargs)
+    return wrapper_otel
 
 class WorkerModel(object):
     """
@@ -37,6 +52,7 @@ class WorkerModel(object):
         self._engine = engine
         self._socket_dir = socket_dir
 
+    @otel
     def worker_checkin(
         self,
         user_id,
@@ -122,13 +138,16 @@ class WorkerModel(object):
         return socket_id
 
     @staticmethod
+    @otel
     def _serialize_dependencies(dependencies):
         return json.dumps(dependencies, separators=(',', ':'))
 
     @staticmethod
+    @otel
     def _deserialize_dependencies(blob):
         return list(map(tuple, json.loads(blob)))
 
+    @otel
     def worker_cleanup(self, user_id, worker_id):
         """
         Deletes the worker and all associated data from the database as well
@@ -172,6 +191,7 @@ class WorkerModel(object):
                 )
             )
 
+    @otel
     def get_workers(self):
         """
         Returns information about all the workers in the database. The return
@@ -216,6 +236,7 @@ class WorkerModel(object):
             worker_dict[(row.user_id, row.worker_id)]['run_uuids'].append(row.run_uuid)
         return list(worker_dict.values())
 
+    @otel
     def update_workers(self, user_id, worker_id, update):
         """
         Update the designated worker with columns and values
@@ -240,6 +261,7 @@ class WorkerModel(object):
                     .values(update)
                 )
 
+    @otel
     def allocate_socket(self, user_id, worker_id, conn=None):
         """
         Allocates a unique socket ID.
@@ -257,6 +279,7 @@ class WorkerModel(object):
         else:
             return do(conn)
 
+    @otel
     def deallocate_socket(self, socket_id):
         """
         Cleans up the socket, removing the associated file in the socket
@@ -266,15 +289,18 @@ class WorkerModel(object):
         with self._engine.begin() as conn:
             conn.execute(cl_worker_socket.delete().where(cl_worker_socket.c.socket_id == socket_id))
 
+    @otel
     def _socket_path(self, socket_id):
         return os.path.join(self._socket_dir, str(socket_id))
 
+    @otel
     def _cleanup_socket(self, socket_id):
         try:
             os.remove(self._socket_path(socket_id))
         except OSError:
             pass
 
+    @otel
     def start_listening(self, socket_id):
         """
         Returns a Python socket object that can be used to accept connections on
@@ -292,6 +318,7 @@ class WorkerModel(object):
 
     ACK = b'a'
 
+    @otel
     def get_stream(self, sock, timeout_secs):
         """
         Receives a single message on the given socket and returns a file-like
@@ -313,6 +340,7 @@ class WorkerModel(object):
         except socket.timeout:
             return None
 
+    @otel
     def get_json_message(self, sock, timeout_secs):
         """
         Receives a single message on the given socket and returns the message
@@ -328,6 +356,7 @@ class WorkerModel(object):
         with closing(fileobj):
             return json.loads(fileobj.read().decode())
 
+    @otel
     def send_stream(self, socket_id, fileobj, timeout_secs):
         """
         Streams the given file-like object to the given socket.
@@ -360,6 +389,7 @@ class WorkerModel(object):
 
         return False
 
+    @otel
     def send_json_message(self, socket_id, message, timeout_secs, autoretry=True):
         """
         Sends a JSON message to the given socket, retrying until it is received
@@ -418,6 +448,7 @@ class WorkerModel(object):
 
         return False
 
+    @otel
     def has_reply_permission(self, user_id, worker_id, socket_id):
         """
         Checks whether the given user running a worker with the given ID can
diff --git a/codalab/rest/account.py b/codalab/rest/account.py
index a3683d1f..5cb05819 100644
--- a/codalab/rest/account.py
+++ b/codalab/rest/account.py
@@ -12,6 +12,11 @@ from codalab.common import UsageError
 from codalab.objects.user import User
 from codalab.server.authenticated_plugin import AuthenticatedPlugin, UserVerifiedPlugin
 from codalab.server.cookie import LoginCookie
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 def send_verification_key(username, email, key):
@@ -29,154 +34,194 @@ def send_verification_key(username, email, key):
 
 @get('/account/logout', name='logout', skip=UserVerifiedPlugin)
 def do_logout():
-    LoginCookie.clear()
-    redirect_uri = safe_uri(request.query.get('redirect_uri'))
-    return redirect(redirect_uri)
+    with tracer.start_as_current_span(
+        "/account/logout",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        LoginCookie.clear()
+        redirect_uri = safe_uri(request.query.get('redirect_uri'))
+        return redirect(redirect_uri)
 
 
 @post('/account/login')
 def do_login():
-    success_uri = request.forms.get('success_uri')
-    error_uri = request.forms.get('error_uri')
-    username = request.forms.get('username')
-    password = request.forms.get('password')
-
-    user = local.model.get_user(username=username)
-    if not (user and user.check_password(password)):
-        return redirect_with_query(
-            error_uri, {"error": "Login/password did not match.", "next": success_uri}
-        )
-
-    # Update last login
-    local.model.update_user_last_login(user.user_id)
-
-    # Save cookie in client
-    cookie = LoginCookie(user.user_id, max_age=30 * 24 * 60 * 60)
-    cookie.save()
-
-    # Redirect client to next page
-    if success_uri:
-        return redirect(safe_uri(success_uri))
-    else:
-        return redirect('/')
+    with tracer.start_as_current_span(
+        "/account/login",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        success_uri = request.forms.get('success_uri')
+        error_uri = request.forms.get('error_uri')
+        username = request.forms.get('username')
+        password = request.forms.get('password')
+
+        user = local.model.get_user(username=username)
+        if not (user and user.check_password(password)):
+            return redirect_with_query(
+                error_uri, {"error": "Login/password did not match.", "next": success_uri}
+            )
+
+        # Update last login
+        local.model.update_user_last_login(user.user_id)
+
+        # Save cookie in client
+        cookie = LoginCookie(user.user_id, max_age=30 * 24 * 60 * 60)
+        cookie.save()
+
+        # Redirect client to next page
+        if success_uri:
+            return redirect(safe_uri(success_uri))
+        else:
+            return redirect('/')
 
 
 @post('/account/signup')
 def do_signup():
-    success_uri = request.forms.get('success_uri')
-    error_uri = request.forms.get('error_uri')
-    username = request.forms.get('username')
-    email = request.forms.get('email')
-    first_name = request.forms.get('first_name')
-    last_name = request.forms.get('last_name')
-    password = request.forms.get('password')
-    affiliation = request.forms.get('affiliation')
-    token = request.forms.get('token')
-
-    errors = []
-
-    if not token:
-        errors.append('Google reCAPTCHA token is missing.')
-    else:
-        url = 'https://www.google.com/recaptcha/api/siteverify'
-        data = {
-            'secret': os.environ['CODALAB_RECAPTCHA_SECRET_KEY'],
-            'response': token,
-        }
-        res = requests.post(url, data)
+    with tracer.start_as_current_span(
+        "/account/signup",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        success_uri = request.forms.get('success_uri')
+        error_uri = request.forms.get('error_uri')
+        username = request.forms.get('username')
+        email = request.forms.get('email')
+        first_name = request.forms.get('first_name')
+        last_name = request.forms.get('last_name')
+        password = request.forms.get('password')
+        affiliation = request.forms.get('affiliation')
+        token = request.forms.get('token')
+
+        errors = []
+
+        if not token:
+            errors.append('Google reCAPTCHA token is missing.')
+        else:
+            url = 'https://www.google.com/recaptcha/api/siteverify'
+            data = {
+                'secret': os.environ['CODALAB_RECAPTCHA_SECRET_KEY'],
+                'response': token,
+            }
+            res = requests.post(url, data)
+
+            try:
+                data = res.json()
+                if not data.get('success'):
+                    errors.append('Google reCAPTCHA failed.')
+
+            except UsageError as e:
+                errors.append(str(e))
+
+        if request.user.is_authenticated:
+            errors.append(
+                "You are already logged in as %s, please log out before "
+                "creating a new account." % request.user.user_name
+            )
+
+        if request.forms.get('confirm_password') != password:
+            errors.append("Passwords do not match.")
+
+        if not spec_util.NAME_REGEX.match(username):
+            errors.append(
+                "Username must only contain letter, digits, hyphens, underscores, and periods."
+            )
 
         try:
-            data = res.json()
-            if not data.get('success'):
-                errors.append('Google reCAPTCHA failed.')
-
+            User.validate_password(password)
         except UsageError as e:
             errors.append(str(e))
 
-    if request.user.is_authenticated:
-        errors.append(
-            "You are already logged in as %s, please log out before "
-            "creating a new account." % request.user.user_name
+        # Only do a basic validation of email -- the only guaranteed way to check
+        # whether an email address is valid is by sending an actual email.
+        if not spec_util.BASIC_EMAIL_REGEX.match(email):
+            errors.append("Email address is invalid.")
+
+        if local.model.user_exists(username, email):
+            errors.append("User with this username or email already exists.")
+
+        if not NAME_REGEX.match(username):
+            errors.append(
+                "Username characters must be alphanumeric, underscores, periods, or dashes."
+            )
+
+        if errors:
+            return redirect_with_query(
+                error_uri,
+                {
+                    'error': ' '.join(errors),
+                    'next': success_uri,
+                    'email': email,
+                    'username': username,
+                    'first_name': first_name,
+                    'last_name': last_name,
+                    'affiliation': affiliation,
+                },
+            )
+
+        # If user leaves it blank, empty string is obtained - make it of NoneType.
+        if not affiliation:
+            affiliation = None
+
+        # Create unverified user
+        _, verification_key = local.model.add_user(
+            username, email, first_name, last_name, password, affiliation
         )
 
-    if request.forms.get('confirm_password') != password:
-        errors.append("Passwords do not match.")
+        # Send key
+        send_verification_key(username, email, verification_key)
 
-    if not spec_util.NAME_REGEX.match(username):
-        errors.append(
-            "Username must only contain letter, digits, hyphens, underscores, and periods."
-        )
-
-    try:
-        User.validate_password(password)
-    except UsageError as e:
-        errors.append(str(e))
-
-    # Only do a basic validation of email -- the only guaranteed way to check
-    # whether an email address is valid is by sending an actual email.
-    if not spec_util.BASIC_EMAIL_REGEX.match(email):
-        errors.append("Email address is invalid.")
-
-    if local.model.user_exists(username, email):
-        errors.append("User with this username or email already exists.")
-
-    if not NAME_REGEX.match(username):
-        errors.append("Username characters must be alphanumeric, underscores, periods, or dashes.")
-
-    if errors:
-        return redirect_with_query(
-            error_uri,
-            {
-                'error': ' '.join(errors),
-                'next': success_uri,
-                'email': email,
-                'username': username,
-                'first_name': first_name,
-                'last_name': last_name,
-                'affiliation': affiliation,
-            },
-        )
-
-    # If user leaves it blank, empty string is obtained - make it of NoneType.
-    if not affiliation:
-        affiliation = None
-
-    # Create unverified user
-    _, verification_key = local.model.add_user(
-        username, email, first_name, last_name, password, affiliation
-    )
-
-    # Send key
-    send_verification_key(username, email, verification_key)
-
-    # Redirect to success page
-    return redirect_with_query(success_uri, {'email': email})
+        # Redirect to success page
+        return redirect_with_query(success_uri, {'email': email})
 
 
 @get('/account/verify/<key>', skip=UserVerifiedPlugin)
 def do_verify(key):
-    if local.model.verify_user(key):
-        return redirect('/account/verify/success')
-    else:
-        return redirect('/account/verify/error')
+    with tracer.start_as_current_span(
+        "/account/verify/<key>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.key", key)
+        if local.model.verify_user(key):
+            return redirect('/account/verify/success')
+        else:
+            return redirect('/account/verify/error')
 
 
 @get('/account/resend', name='resend_key', skip=UserVerifiedPlugin)
 def resend_key():
-    if request.user.is_verified:
-        return redirect('/account/verify/success')
-    key = local.model.get_verification_key(request.user.user_id)
-    send_verification_key(request.user.user_name, request.user.email, key)
-    return redirect_with_query('/account/signup/success', {'email': request.user.email})
+    with tracer.start_as_current_span(
+        "/account/resend",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        if request.user.is_verified:
+            return redirect('/account/verify/success')
+        key = local.model.get_verification_key(request.user.user_id)
+        send_verification_key(request.user.user_name, request.user.email, key)
+        return redirect_with_query('/account/signup/success', {'email': request.user.email})
 
 
 @get('/account/css', skip=UserVerifiedPlugin)
 def css():
-    response.content_type = 'text/css'
-    if request.user.is_authenticated:
-        return template('user_authenticated_css', username=request.user.user_name)
-    else:
-        return template('user_not_authenticated_css')
+    with tracer.start_as_current_span(
+        "/account/css",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        response.content_type = 'text/css'
+        if request.user.is_authenticated:
+            return template('user_authenticated_css', username=request.user.user_name)
+        else:
+            return template('user_not_authenticated_css')
 
 
 @get('/account/reset', apply=AuthenticatedPlugin())
@@ -184,23 +229,33 @@ def request_reset_get():
     """
     Password reset endpoint for authenticated users.
     """
-    # Generate reset code
-    reset_code = local.model.new_user_reset_code(request.user.user_id)
-
-    # Send code
-    hostname = request.get_header('X-Forwarded-Host') or request.get_header('Host')
-    scheme = request.get_header('X-Forwarded-Proto')
-    user_name = request.user.first_name or request.user.user_name
-    local.emailer.send_email(
-        subject="CodaLab password reset link",
-        body=template(
-            'password_reset_body', user=user_name, scheme=scheme, hostname=hostname, code=reset_code
-        ),
-        recipient=request.user.email,
-    )
+    with tracer.start_as_current_span(
+        "/account/reset",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        # Generate reset code
+        reset_code = local.model.new_user_reset_code(request.user.user_id)
+
+        # Send code
+        hostname = request.get_header('X-Forwarded-Host') or request.get_header('Host')
+        scheme = request.get_header('X-Forwarded-Proto')
+        user_name = request.user.first_name or request.user.user_name
+        local.emailer.send_email(
+            subject="CodaLab password reset link",
+            body=template(
+                'password_reset_body',
+                user=user_name,
+                scheme=scheme,
+                hostname=hostname,
+                code=reset_code,
+            ),
+            recipient=request.user.email,
+        )
 
-    # Redirect to success page
-    return redirect('/account/reset/sent')
+        # Redirect to success page
+        return redirect('/account/reset/sent')
 
 
 @post('/account/reset')
@@ -208,31 +263,41 @@ def request_reset_post():
     """
     Password reset form POST endpoint.
     """
-    email = request.forms.get('email')
-    user = local.model.get_user(username=email)
-    if user is None:
-        # Redirect back to form page
-        return redirect_with_query(
-            '/account/reset', {'error': "User with email %s not found." % email}
+    with tracer.start_as_current_span(
+        "/account/reset",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        email = request.forms.get('email')
+        user = local.model.get_user(username=email)
+        if user is None:
+            # Redirect back to form page
+            return redirect_with_query(
+                '/account/reset', {'error': "User with email %s not found." % email}
+            )
+
+        # Generate reset code
+        reset_code = local.model.new_user_reset_code(user.user_id)
+
+        # Send code
+        hostname = request.get_header('X-Forwarded-Host') or request.get_header('Host')
+        scheme = request.get_header('X-Forwarded-Proto')
+        user_name = user.first_name or user.user_name
+        local.emailer.send_email(
+            subject="CodaLab password reset link",
+            body=template(
+                'password_reset_body',
+                user=user_name,
+                scheme=scheme,
+                hostname=hostname,
+                code=reset_code,
+            ),
+            recipient=email,
         )
 
-    # Generate reset code
-    reset_code = local.model.new_user_reset_code(user.user_id)
-
-    # Send code
-    hostname = request.get_header('X-Forwarded-Host') or request.get_header('Host')
-    scheme = request.get_header('X-Forwarded-Proto')
-    user_name = user.first_name or user.user_name
-    local.emailer.send_email(
-        subject="CodaLab password reset link",
-        body=template(
-            'password_reset_body', user=user_name, scheme=scheme, hostname=hostname, code=reset_code
-        ),
-        recipient=email,
-    )
-
-    # Redirect to success page
-    return redirect('/account/reset/sent')
+        # Redirect to success page
+        return redirect('/account/reset/sent')
 
 
 @get('/account/reset/verify/<code>')
@@ -242,10 +307,18 @@ def verify_reset_code(code):
     Does an initial verification of the reset code and redirects to the
     frontend page with the appropriate parameters.
     """
-    if local.model.get_reset_code_user_id(code, delete=False) is not None:
-        redirect_with_query('/account/reset/verified', {'code_valid': True, 'code': code})
-    else:
-        redirect_with_query('/account/reset/verified', {'code_valid': False})
+    with tracer.start_as_current_span(
+        f"/account/reset/verify/<code>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.code", code)
+        if local.model.get_reset_code_user_id(code, delete=False) is not None:
+            redirect_with_query('/account/reset/verified', {'code_valid': True, 'code': code})
+        else:
+            redirect_with_query('/account/reset/verified', {'code_valid': False})
 
 
 @post('/account/reset/finalize')
@@ -253,34 +326,40 @@ def reset_password():
     """
     Final password reset form POST endpoint.
     """
-    code = request.forms.get('code')
-    password = request.forms.get('password')
-    confirm_password = request.forms.get('confirm_password')
-
-    # Validate password
-    if confirm_password != password:
-        return redirect_with_query(
-            '/account/reset/verified',
-            {'code_valid': True, 'code': code, 'error': "Passwords do not match."},
-        )
-    try:
-        User.validate_password(password)
-    except UsageError as e:
-        return redirect_with_query(
-            '/account/reset/verified', {'code_valid': True, 'code': code, 'error': str(e)}
-        )
+    with tracer.start_as_current_span(
+        "/account/reset/finalize",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        code = request.forms.get('code')
+        password = request.forms.get('password')
+        confirm_password = request.forms.get('confirm_password')
+
+        # Validate password
+        if confirm_password != password:
+            return redirect_with_query(
+                '/account/reset/verified',
+                {'code_valid': True, 'code': code, 'error': "Passwords do not match."},
+            )
+        try:
+            User.validate_password(password)
+        except UsageError as e:
+            return redirect_with_query(
+                '/account/reset/verified', {'code_valid': True, 'code': code, 'error': str(e)}
+            )
 
-    # Verify reset code again and get user_id
-    user_id = local.model.get_reset_code_user_id(code, delete=True)
-    if user_id is None:
-        return redirect_with_query('/account/reset/verified', {'code_valid': False})
+        # Verify reset code again and get user_id
+        user_id = local.model.get_reset_code_user_id(code, delete=True)
+        if user_id is None:
+            return redirect_with_query('/account/reset/verified', {'code_valid': False})
 
-    # Update user password
-    user_info = local.model.get_user_info(user_id)
-    user_info['password'] = (User.encode_password(password, crypt_util.get_random_string()),)
-    local.model.update_user_info(user_info)
+        # Update user password
+        user_info = local.model.get_user_info(user_id)
+        user_info['password'] = (User.encode_password(password, crypt_util.get_random_string()),)
+        local.model.update_user_info(user_info)
 
-    return redirect('/account/reset/complete')
+        return redirect('/account/reset/complete')
 
 
 @post('/account/changeemail', apply=AuthenticatedPlugin(), skip=UserVerifiedPlugin)
@@ -288,26 +367,32 @@ def request_change_email():
     """
     Email change form POST endpoint.
     """
-    email = request.forms.get('email').strip()
-
-    if email == request.user.email:
-        return redirect_with_query(
-            '/account/changeemail', {'error': "Your email address is already %s." % email}
+    with tracer.start_as_current_span(
+        "/account/changeemail",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        email = request.forms.get('email').strip()
+
+        if email == request.user.email:
+            return redirect_with_query(
+                '/account/changeemail', {'error': "Your email address is already %s." % email}
+            )
+
+        if not spec_util.BASIC_EMAIL_REGEX.match(email):
+            return redirect_with_query('/account/changeemail', {'error': "Invalid email address."})
+
+        if local.model.user_exists(None, email):
+            return redirect_with_query(
+                '/account/changeemail', {'error': "User with this email already exists."}
+            )
+
+        local.model.update_user_info(
+            {'user_id': request.user.user_id, 'email': email, 'is_verified': False}
         )
 
-    if not spec_util.BASIC_EMAIL_REGEX.match(email):
-        return redirect_with_query('/account/changeemail', {'error': "Invalid email address."})
-
-    if local.model.user_exists(None, email):
-        return redirect_with_query(
-            '/account/changeemail', {'error': "User with this email already exists."}
-        )
-
-    local.model.update_user_info(
-        {'user_id': request.user.user_id, 'email': email, 'is_verified': False}
-    )
-
-    key = local.model.get_verification_key(request.user.user_id)
-    send_verification_key(request.user.user_name, request.user.email, key)
+        key = local.model.get_verification_key(request.user.user_id)
+        send_verification_key(request.user.user_name, request.user.email, key)
 
-    return redirect('/account/changeemail/sent')
+        return redirect('/account/changeemail/sent')
diff --git a/codalab/rest/bundle_actions.py b/codalab/rest/bundle_actions.py
index b9a285b2..019a59b7 100644
--- a/codalab/rest/bundle_actions.py
+++ b/codalab/rest/bundle_actions.py
@@ -6,6 +6,11 @@ from codalab.objects.permission import check_bundles_have_all_permission
 from codalab.rest.schemas import BundleActionSchema
 from codalab.server.authenticated_plugin import AuthenticatedProtectedPlugin
 from codalab.worker.bundle_state import State
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @post('/bundle-actions', apply=AuthenticatedProtectedPlugin())
@@ -14,33 +19,39 @@ def create_bundle_actions():
     Sends the message to the worker to do the bundle action, and adds the
     action string to the bundle metadata.
     """
-    actions = BundleActionSchema(strict=True, many=True).load(request.json).data
-
-    check_bundles_have_all_permission(local.model, request.user, [a['uuid'] for a in actions])
-    for action in actions:
-        bundle = local.model.get_bundle(action['uuid'])
-        if bundle.state in [State.READY, State.FAILED, State.KILLED]:
-            raise UsageError(
-                'Cannot execute this action on a bundle that is in the following states: ready, failed, killed. '
-                'Kill action can be executed on bundles in created, uploading, staged, making, starting, '
-                'running, preparing, or finalizing state.'
-            )
-
-        worker = local.model.get_bundle_worker(action['uuid'])
-        new_actions = getattr(bundle.metadata, 'actions', []) + [BundleAction.as_string(action)]
-
-        # The state updates of bundles in PREPARING, RUNNING, or FINALIZING state will be handled on the worker side.
-        if worker:
-            precondition(
-                local.worker_model.send_json_message(worker['socket_id'], action, 60),
-                'Unable to reach worker.',
-            )
-            local.model.update_bundle(bundle, {'metadata': {'actions': new_actions}})
-        else:
-            # The state updates of bundles in CREATED, UPLOADING, MAKING, STARTING or STAGED state
-            # will be handled on the rest-server side.
-            local.model.update_bundle(
-                bundle, {'state': State.KILLED, 'metadata': {'actions': new_actions}}
-            )
-
-    return BundleActionSchema(many=True).dump(actions).data
+    with tracer.start_as_current_span(
+        "/bundle-actions",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        actions = BundleActionSchema(strict=True, many=True).load(request.json).data
+
+        check_bundles_have_all_permission(local.model, request.user, [a['uuid'] for a in actions])
+        for action in actions:
+            bundle = local.model.get_bundle(action['uuid'])
+            if bundle.state in [State.READY, State.FAILED, State.KILLED]:
+                raise UsageError(
+                    'Cannot execute this action on a bundle that is in the following states: ready, failed, killed. '
+                    'Kill action can be executed on bundles in created, uploading, staged, making, starting, '
+                    'running, preparing, or finalizing state.'
+                )
+
+            worker = local.model.get_bundle_worker(action['uuid'])
+            new_actions = getattr(bundle.metadata, 'actions', []) + [BundleAction.as_string(action)]
+
+            # The state updates of bundles in PREPARING, RUNNING, or FINALIZING state will be handled on the worker side.
+            if worker:
+                precondition(
+                    local.worker_model.send_json_message(worker['socket_id'], action, 60),
+                    'Unable to reach worker.',
+                )
+                local.model.update_bundle(bundle, {'metadata': {'actions': new_actions}})
+            else:
+                # The state updates of bundles in CREATED, UPLOADING, MAKING, STARTING or STAGED state
+                # will be handled on the rest-server side.
+                local.model.update_bundle(
+                    bundle, {'state': State.KILLED, 'metadata': {'actions': new_actions}}
+                )
+
+        return BundleActionSchema(many=True).dump(actions).data
diff --git a/codalab/rest/bundles.py b/codalab/rest/bundles.py
index 923f46a0..e7d11924 100644
--- a/codalab/rest/bundles.py
+++ b/codalab/rest/bundles.py
@@ -46,8 +46,12 @@ from codalab.rest.util import get_bundle_infos, get_resource_ids, resolve_owner_
 from codalab.server.authenticated_plugin import AuthenticatedProtectedPlugin, ProtectedPlugin
 from codalab.worker.bundle_state import State
 from codalab.worker.download_util import BundleTarget
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
 
 logger = logging.getLogger(__name__)
+tracer = trace.get_tracer(__name__)
 
 
 @get('/bundles/<uuid:re:%s>' % spec_util.UUID_STR, apply=ProtectedPlugin())
@@ -61,10 +65,18 @@ def _fetch_bundle(uuid):
        for displaying the bundle info, `0` to omit them. Default is `0`.
      - `include`: comma-separated list of related resources to include, such as "owner"
     """
-    document = build_bundles_document([uuid])
-    precondition(len(document['data']) == 1, "data should have exactly one element")
-    document['data'] = document['data'][0]  # Flatten data list
-    return document
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        document = build_bundles_document([uuid])
+        precondition(len(document['data']) == 1, "data should have exactly one element")
+        document['data'] = document['data'][0]  # Flatten data list
+        return document
 
 
 @get('/bundles', apply=ProtectedPlugin())
@@ -120,40 +132,50 @@ def _fetch_bundles():
         2. the key should be able to uniquely identify a (child_path, parent_uuid) pair in the list.
     The returning result will be aggregated in the same way as 1.
     """
-    keywords = query_get_list('keywords')
-    specs = query_get_list('specs')
-    worksheet_uuid = request.query.get('worksheet')
-    descendant_depth = query_get_type(int, 'depth', None)
-    command = query_get_type(str, 'command', '')
-    dependencies = query_get_type(str, 'dependencies', '[]')
-
-    if keywords:
-        # Handle search keywords
-        keywords = resolve_owner_in_keywords(keywords)
-        search_result = local.model.search_bundles(request.user.user_id, keywords)
-        # Return simple dict if scalar result (e.g. .sum or .count queries)
-        if search_result['is_aggregate']:
-            return json_api_meta({}, {'result': search_result['result']})
-        # If not aggregate this is a list
-        bundle_uuids = search_result['result']
-    elif specs:
-        # Resolve bundle specs
-        bundle_uuids = canonicalize.get_bundle_uuids(
-            local.model, request.user, worksheet_uuid, specs
-        )
-    elif command:
-        bundle_uuids = local.model.get_memoized_bundles(request.user.user_id, command, dependencies)
-    else:
-        abort(
-            http.client.BAD_REQUEST,
-            "Request must include either 'keywords' " "or 'specs' query parameter",
-        )
+    with tracer.start_as_current_span(
+        "/bundles",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        keywords = query_get_list('keywords')
+        specs = query_get_list('specs')
+        worksheet_uuid = request.query.get('worksheet')
+        descendant_depth = query_get_type(int, 'depth', None)
+        command = query_get_type(str, 'command', '')
+        dependencies = query_get_type(str, 'dependencies', '[]')
+
+        if keywords:
+            # Handle search keywords
+            keywords = resolve_owner_in_keywords(keywords)
+            search_result = local.model.search_bundles(request.user.user_id, keywords)
+            # Return simple dict if scalar result (e.g. .sum or .count queries)
+            if search_result['is_aggregate']:
+                return json_api_meta({}, {'result': search_result['result']})
+            # If not aggregate this is a list
+            bundle_uuids = search_result['result']
+        elif specs:
+            # Resolve bundle specs
+            bundle_uuids = canonicalize.get_bundle_uuids(
+                local.model, request.user, worksheet_uuid, specs
+            )
+        elif command:
+            bundle_uuids = local.model.get_memoized_bundles(
+                request.user.user_id, command, dependencies
+            )
+        else:
+            abort(
+                http.client.BAD_REQUEST,
+                "Request must include either 'keywords' " "or 'specs' query parameter",
+            )
 
-    # Find all descendants down to the provided depth
-    if descendant_depth is not None:
-        bundle_uuids = local.model.get_self_and_descendants(bundle_uuids, depth=descendant_depth)
+        # Find all descendants down to the provided depth
+        if descendant_depth is not None:
+            bundle_uuids = local.model.get_self_and_descendants(
+                bundle_uuids, depth=descendant_depth
+            )
 
-    return build_bundles_document(bundle_uuids)
+        return build_bundles_document(bundle_uuids)
 
 
 def build_bundles_document(bundle_uuids):
@@ -234,98 +256,106 @@ def _create_bundles():
       copying bundles from another CodaLab instance, this prevents these new
       bundles from being executed by the BundleManager. Default is 0.
     """
-    worksheet_uuid = request.query.get('worksheet')
-    shadow_parent_uuid = request.query.get('shadow')
-    after_sort_key = request.query.get('after_sort_key')
-    detached = query_get_bool('detached', default=False)
-    after_image = query_get_bool('after_image', default=False)
-    if not detached and worksheet_uuid is None:
-        abort(
-            http.client.BAD_REQUEST,
-            "Parent worksheet id must be specified as" "'worksheet' query parameter",
-        )
-
-    # Deserialize bundle fields
-    bundles = (
-        BundleSchema(strict=True, many=True, dump_only=BUNDLE_CREATE_RESTRICTED_FIELDS)
-        .load(request.json)
-        .data
-    )
+    with tracer.start_as_current_span(
+        "/bundles",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        worksheet_uuid = request.query.get('worksheet')
+        shadow_parent_uuid = request.query.get('shadow')
+        after_sort_key = request.query.get('after_sort_key')
+        detached = query_get_bool('detached', default=False)
+        after_image = query_get_bool('after_image', default=False)
+        if not detached and worksheet_uuid is None:
+            abort(
+                http.client.BAD_REQUEST,
+                "Parent worksheet id must be specified as" "'worksheet' query parameter",
+            )
 
-    # Check for all necessary permissions
-    if not detached:
-        worksheet = local.model.get_worksheet(worksheet_uuid, fetch_items=False)
-        check_worksheet_has_all_permission(local.model, request.user, worksheet)
-        worksheet_util.check_worksheet_not_frozen(worksheet)
-    request.user.check_quota(need_time=True, need_disk=True)
+        # Deserialize bundle fields
+        bundles = (
+            BundleSchema(strict=True, many=True, dump_only=BUNDLE_CREATE_RESTRICTED_FIELDS)
+            .load(request.json)
+            .data
+        )
 
-    created_uuids = []
-    for bundle in bundles:
-        # Prep bundle info for saving into database
-        # Unfortunately cannot use the `construct` methods because they don't
-        # provide a uniform interface for constructing bundles for all types
-        # Hopefully this can all be unified after REST migration is complete
-        bundle_uuid = bundle.setdefault('uuid', spec_util.generate_uuid())
-        created_uuids.append(bundle_uuid)
-        bundle_class = get_bundle_subclass(bundle['bundle_type'])
-        bundle['owner_id'] = request.user.user_id
-
-        metadata = bundle.get("metadata", {})
-        if metadata.get("link_url"):
-            bundle['state'] = State.READY
-        elif issubclass(bundle_class, UploadedBundle) or query_get_bool('wait_for_upload', False):
-            bundle['state'] = State.UPLOADING
-        else:
-            bundle['state'] = State.CREATED
+        # Check for all necessary permissions
         if not detached:
-            bundle['is_anonymous'] = worksheet.is_anonymous  # inherit worksheet anonymity
-        else:
-            bundle['is_anonymous'] = False
-        bundle.setdefault('metadata', {})['created'] = int(time.time())
-        for dep in bundle.setdefault('dependencies', []):
-            dep['child_uuid'] = bundle_uuid
+            worksheet = local.model.get_worksheet(worksheet_uuid, fetch_items=False)
+            check_worksheet_has_all_permission(local.model, request.user, worksheet)
+            worksheet_util.check_worksheet_not_frozen(worksheet)
+        request.user.check_quota(need_time=True, need_disk=True)
 
-        # Create bundle object
-        bundle = bundle_class(bundle, strict=False)
+        created_uuids = []
+        for bundle in bundles:
+            # Prep bundle info for saving into database
+            # Unfortunately cannot use the `construct` methods because they don't
+            # provide a uniform interface for constructing bundles for all types
+            # Hopefully this can all be unified after REST migration is complete
+            bundle_uuid = bundle.setdefault('uuid', spec_util.generate_uuid())
+            created_uuids.append(bundle_uuid)
+            bundle_class = get_bundle_subclass(bundle['bundle_type'])
+            bundle['owner_id'] = request.user.user_id
+
+            metadata = bundle.get("metadata", {})
+            if metadata.get("link_url"):
+                bundle['state'] = State.READY
+            elif issubclass(bundle_class, UploadedBundle) or query_get_bool(
+                'wait_for_upload', False
+            ):
+                bundle['state'] = State.UPLOADING
+            else:
+                bundle['state'] = State.CREATED
+            if not detached:
+                bundle['is_anonymous'] = worksheet.is_anonymous  # inherit worksheet anonymity
+            else:
+                bundle['is_anonymous'] = False
+            bundle.setdefault('metadata', {})['created'] = int(time.time())
+            for dep in bundle.setdefault('dependencies', []):
+                dep['child_uuid'] = bundle_uuid
 
-        # Save bundle into model
-        local.model.save_bundle(bundle)
+            # Create bundle object
+            bundle = bundle_class(bundle, strict=False)
 
-        if not detached:
-            # Inherit worksheet permissions; else, only the user will have all permissions on the bundle
-            group_permissions = local.model.get_group_worksheet_permissions(
-                request.user.user_id, worksheet_uuid
-            )
-            set_bundle_permissions(
-                [
-                    {
-                        'object_uuid': bundle_uuid,
-                        'group_uuid': p['group_uuid'],
-                        'permission': p['permission'],
-                    }
-                    for p in group_permissions
-                ]
-            )
+            # Save bundle into model
+            local.model.save_bundle(bundle)
 
-        # Add as item to worksheet
-        if not detached:
-            if shadow_parent_uuid is None:
-                items = [worksheet_util.bundle_item(bundle_uuid)]
-                # Add a blank line after the image block in the worksheet source to ensure it is a separate block
-                if after_image:
-                    items.insert(0, worksheet_util.markup_item(''))
-                local.model.add_worksheet_items(worksheet_uuid, items, after_sort_key)
-            else:
-                local.model.add_shadow_worksheet_items(shadow_parent_uuid, bundle_uuid)
+            if not detached:
+                # Inherit worksheet permissions; else, only the user will have all permissions on the bundle
+                group_permissions = local.model.get_group_worksheet_permissions(
+                    request.user.user_id, worksheet_uuid
+                )
+                set_bundle_permissions(
+                    [
+                        {
+                            'object_uuid': bundle_uuid,
+                            'group_uuid': p['group_uuid'],
+                            'permission': p['permission'],
+                        }
+                        for p in group_permissions
+                    ]
+                )
+
+            # Add as item to worksheet
+            if not detached:
+                if shadow_parent_uuid is None:
+                    items = [worksheet_util.bundle_item(bundle_uuid)]
+                    # Add a blank line after the image block in the worksheet source to ensure it is a separate block
+                    if after_image:
+                        items.insert(0, worksheet_util.markup_item(''))
+                    local.model.add_worksheet_items(worksheet_uuid, items, after_sort_key)
+                else:
+                    local.model.add_shadow_worksheet_items(shadow_parent_uuid, bundle_uuid)
 
-    # Get created bundles
-    bundles_dict = get_bundle_infos(created_uuids)
+        # Get created bundles
+        bundles_dict = get_bundle_infos(created_uuids)
 
-    # Return bundles in original order
-    # Need to check if the UUID is in the dict, since there is a chance that a bundle is deleted
-    # right after being created.
-    bundles = [bundles_dict[uuid] for uuid in created_uuids if uuid in bundles_dict]
-    return BundleSchema(many=True).dump(bundles).data
+        # Return bundles in original order
+        # Need to check if the UUID is in the dict, since there is a chance that a bundle is deleted
+        # right after being created.
+        bundles = [bundles_dict[uuid] for uuid in created_uuids if uuid in bundles_dict]
+        return BundleSchema(many=True).dump(bundles).data
 
 
 @patch('/bundles', apply=AuthenticatedProtectedPlugin())
@@ -333,39 +363,45 @@ def _update_bundles():
     """
     Bulk update bundles.
     """
-    bundle_updates = (
-        BundleSchema(strict=True, many=True, dump_only=BUNDLE_UPDATE_RESTRICTED_FIELDS)
-        .load(request.json, partial=True)
-        .data
-    )
+    with tracer.start_as_current_span(
+        "/bundles",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        bundle_updates = (
+            BundleSchema(strict=True, many=True, dump_only=BUNDLE_UPDATE_RESTRICTED_FIELDS)
+            .load(request.json, partial=True)
+            .data
+        )
 
-    # Check permissions
-    bundle_uuids = [b.pop('uuid') for b in bundle_updates]
-    check_bundles_have_all_permission(local.model, request.user, bundle_uuids)
-    bundles = local.model.batch_get_bundles(uuid=bundle_uuids)
-    for bundle, update in zip(bundles, bundle_updates):
-        if "frozen" not in update:
-            bundle_util.check_bundle_not_frozen(bundle)
-        else:
-            # If we're freezing or unfreezing the bundle, check that
-            # the bundle is in a final state.
-            # If we're freezing, additionally check that the bundle is not already frozen.
-            bundle_util.check_bundle_freezable(bundle)
-            if update["frozen"]:
+        # Check permissions
+        bundle_uuids = [b.pop('uuid') for b in bundle_updates]
+        check_bundles_have_all_permission(local.model, request.user, bundle_uuids)
+        bundles = local.model.batch_get_bundles(uuid=bundle_uuids)
+        for bundle, update in zip(bundles, bundle_updates):
+            if "frozen" not in update:
                 bundle_util.check_bundle_not_frozen(bundle)
+            else:
+                # If we're freezing or unfreezing the bundle, check that
+                # the bundle is in a final state.
+                # If we're freezing, additionally check that the bundle is not already frozen.
+                bundle_util.check_bundle_freezable(bundle)
+                if update["frozen"]:
+                    bundle_util.check_bundle_not_frozen(bundle)
 
-    # Update bundles
-    for bundle, update in zip(bundles, bundle_updates):
-        local.model.update_bundle(bundle, update)
+        # Update bundles
+        for bundle, update in zip(bundles, bundle_updates):
+            local.model.update_bundle(bundle, update)
 
-    # Get updated bundles
-    bundles_dict = get_bundle_infos(bundle_uuids)
-    # Create list of bundles in original order
-    # Need to check if the UUID is in the dict, since there is a chance that a bundle is deleted
-    # right after being updated.
-    updated_bundles = [bundles_dict[uuid] for uuid in bundle_uuids if uuid in bundles_dict]
+        # Get updated bundles
+        bundles_dict = get_bundle_infos(bundle_uuids)
+        # Create list of bundles in original order
+        # Need to check if the UUID is in the dict, since there is a chance that a bundle is deleted
+        # right after being updated.
+        updated_bundles = [bundles_dict[uuid] for uuid in bundle_uuids if uuid in bundles_dict]
 
-    return BundleSchema(many=True).dump(updated_bundles).data
+        return BundleSchema(many=True).dump(updated_bundles).data
 
 
 @delete('/bundles', apply=AuthenticatedProtectedPlugin())
@@ -386,17 +422,23 @@ def _delete_bundles():
        the given parameters without actually deleting them, or 0 to perform
        the deletion. Default is 0.
     """
-    uuids = get_resource_ids(request.json, 'bundles')
-    force = query_get_bool('force', default=False)
-    recursive = query_get_bool('recursive', default=False)
-    data_only = query_get_bool('data-only', default=False)
-    dry_run = query_get_bool('dry-run', default=False)
-    deleted_uuids = delete_bundles(
-        uuids, force=force, recursive=recursive, data_only=data_only, dry_run=dry_run
-    )
+    with tracer.start_as_current_span(
+        "/bundles",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        uuids = get_resource_ids(request.json, 'bundles')
+        force = query_get_bool('force', default=False)
+        recursive = query_get_bool('recursive', default=False)
+        data_only = query_get_bool('data-only', default=False)
+        dry_run = query_get_bool('dry-run', default=False)
+        deleted_uuids = delete_bundles(
+            uuids, force=force, recursive=recursive, data_only=data_only, dry_run=dry_run
+        )
 
-    # Return list of deleted ids as meta
-    return json_api_meta({}, {'ids': deleted_uuids})
+        # Return list of deleted ids as meta
+        return json_api_meta({}, {'ids': deleted_uuids})
 
 
 @post('/bundle-permissions', apply=AuthenticatedProtectedPlugin())
@@ -407,9 +449,15 @@ def _set_bundle_permissions():
     A bundle permission created on a bundle-group pair will replace any
     existing permissions on the same bundle-group pair.
     """
-    new_permissions = BundlePermissionSchema(strict=True, many=True).load(request.json).data
-    set_bundle_permissions(new_permissions)
-    return BundlePermissionSchema(many=True).dump(new_permissions).data
+    with tracer.start_as_current_span(
+        "/bundle-permissions",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        new_permissions = BundlePermissionSchema(strict=True, many=True).load(request.json).data
+        set_bundle_permissions(new_permissions)
+        return BundlePermissionSchema(many=True).dump(new_permissions).data
 
 
 @get('/bundles/locations', apply=AuthenticatedProtectedPlugin())
@@ -420,13 +468,19 @@ def _fetch_locations():
     Query parameters:
     - `uuids`: List of bundle UUID's to get the locations for
     """
-    bundle_uuids = query_get_list('uuids')
-    bundle_link_urls = local.model.get_bundle_metadata(bundle_uuids, "link_url")
-    uuids_to_locations = {
-        uuid: bundle_link_urls.get(uuid) or local.bundle_store.get_bundle_location(uuid)
-        for uuid in bundle_uuids
-    }
-    return dict(data=uuids_to_locations)
+    with tracer.start_as_current_span(
+        "/bundles/locations",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        bundle_uuids = query_get_list('uuids')
+        bundle_link_urls = local.model.get_bundle_metadata(bundle_uuids, "link_url")
+        uuids_to_locations = {
+            uuid: bundle_link_urls.get(uuid) or local.bundle_store.get_bundle_location(uuid)
+            for uuid in bundle_uuids
+        }
+        return dict(data=uuids_to_locations)
 
 
 @get(
@@ -440,9 +494,17 @@ def _fetch_bundle_locations(bundle_uuid: str):
     Query parameters:
     - `bundle_uuid`: Bundle UUID to get the locations for
     """
-    bundle_locations = local.model.get_bundle_locations(bundle_uuid)
+    with tracer.start_as_current_span(
+        "/bundles/<bundle_uuid>/locations/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.bundle_uuid", bundle_uuid)
+        bundle_locations = local.model.get_bundle_locations(bundle_uuid)
 
-    return BundleLocationListSchema(many=True).dump(bundle_locations).data
+        return BundleLocationListSchema(many=True).dump(bundle_locations).data
 
 
 @post(
@@ -456,11 +518,19 @@ def _add_bundle_location(bundle_uuid: str):
     Query parameters:
     - `bundle_uuid`: Bundle UUID corresponding to the new location
     """
-    new_location = BundleLocationSchema(many=True).load(request.json).data[0]
-    new_location["uuid"] = local.model.add_bundle_location(
-        new_location['bundle_uuid'], new_location['bundle_store_uuid']
-    )
-    return BundleLocationSchema(many=True).dump([new_location]).data
+    with tracer.start_as_current_span(
+        "/bundles/<bundle_uuid>/locations/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.bundle_uuid", bundle_uuid)
+        new_location = BundleLocationSchema(many=True).load(request.json).data[0]
+        new_location["uuid"] = local.model.add_bundle_location(
+            new_location['bundle_uuid'], new_location['bundle_store_uuid']
+        )
+        return BundleLocationSchema(many=True).dump([new_location]).data
 
 
 @get(
@@ -475,8 +545,17 @@ def _fetch_bundle_location(bundle_uuid: str, bundle_store_uuid: str):
     - `bundle_uuid`: Bundle UUID to get the location for
     - `bundle_store_uuid`: Bundle Store UUID to get the location for
     """
-    bundle_location = local.model.get_bundle_location(bundle_uuid, bundle_store_uuid)
-    return BundleLocationListSchema(many=True).dump(bundle_location).data
+    with tracer.start_as_current_span(
+        "/bundles/<bundle_uuid>/locations/<bundle_store_uuid>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.bundle_uuid", bundle_uuid)
+        current_span.set_attribute("operation.bundle_store_uuid", bundle_store_uuid)
+        bundle_location = local.model.get_bundle_location(bundle_uuid, bundle_store_uuid)
+        return BundleLocationListSchema(many=True).dump(bundle_location).data
 
 
 @get('/bundle_stores', apply=AuthenticatedProtectedPlugin())
@@ -492,8 +571,14 @@ def _fetch_bundle_stores():
     - `storage_format`: the format in which storage is being stored (UNCOMPRESSED, COMPRESSED_V1, etc)
     - `url`: a self-referential URL that points to the bundle store.
     """
-    bundle_stores = local.model.get_bundle_stores(request.user.user_id)
-    return BundleStoreSchema(many=True).dump(bundle_stores).data
+    with tracer.start_as_current_span(
+        "/bundle_stores",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        bundle_stores = local.model.get_bundle_stores(request.user.user_id)
+        return BundleStoreSchema(many=True).dump(bundle_stores).data
 
 
 @post('/bundle_stores', apply=AuthenticatedProtectedPlugin())
@@ -508,28 +593,37 @@ def _add_bundle_store():
         - `authentication`: key for authentication that the bundle store uses.
     Returns the data of the created bundle store.
     """
-    new_bundle_store = BundleStoreSchema(strict=True, many=True).load(request.json).data[0]
-    storage_type = new_bundle_store.get('storage_type')
-    storage_format = new_bundle_store.get('storage_format')
-    if storage_format is None:
-        if storage_type in (StorageType.AZURE_BLOB_STORAGE.value, StorageType.GCS_STORAGE.value):
-            storage_format = StorageFormat.COMPRESSED_V1.value
-        elif storage_type == StorageType.DISK_STORAGE.value:
-            storage_format = StorageFormat.UNCOMPRESSED.value
-        else:
-            raise UsageError(
-                f"Could not determine default storage format for storage type {storage_type}."
-            )
-    uuid = local.model.create_bundle_store(
-        request.user.user_id,
-        new_bundle_store.get('name'),
-        storage_type,
-        storage_format,
-        new_bundle_store.get('url'),
-        new_bundle_store.get('authentication'),
-    )
-    bundle_store = local.model.get_bundle_store(request.user.user_id, uuid)
-    return BundleStoreSchema(many=True).dump([bundle_store]).data
+    with tracer.start_as_current_span(
+        "/bundle_stores",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        new_bundle_store = BundleStoreSchema(strict=True, many=True).load(request.json).data[0]
+        storage_type = new_bundle_store.get('storage_type')
+        storage_format = new_bundle_store.get('storage_format')
+        if storage_format is None:
+            if storage_type in (
+                StorageType.AZURE_BLOB_STORAGE.value,
+                StorageType.GCS_STORAGE.value,
+            ):
+                storage_format = StorageFormat.COMPRESSED_V1.value
+            elif storage_type == StorageType.DISK_STORAGE.value:
+                storage_format = StorageFormat.UNCOMPRESSED.value
+            else:
+                raise UsageError(
+                    f"Could not determine default storage format for storage type {storage_type}."
+                )
+        uuid = local.model.create_bundle_store(
+            request.user.user_id,
+            new_bundle_store.get('name'),
+            storage_type,
+            storage_format,
+            new_bundle_store.get('url'),
+            new_bundle_store.get('authentication'),
+        )
+        bundle_store = local.model.get_bundle_store(request.user.user_id, uuid)
+        return BundleStoreSchema(many=True).dump([bundle_store]).data
 
 
 # TODO: Endpoint not tested / used, reenable when we use it.
@@ -564,14 +658,22 @@ def _fetch_bundle_store(uuid):
     - `storage_format`: the format in which storage is being stored (UNCOMPRESSED, COMPRESSED_V1, etc)
     - `url`: a self-referential URL that points to the bundle store.
     """
-    bundle_store = local.model.get_bundle_store(request.user.user_id, uuid)
-    data = BundleStoreSchema().dump(bundle_store).data
+    with tracer.start_as_current_span(
+        "/bundle_stores/<uuid>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        bundle_store = local.model.get_bundle_store(request.user.user_id, uuid)
+        data = BundleStoreSchema().dump(bundle_store).data
 
-    # Fetch username instead of user_id for display on the front end.
-    data['data']['attributes']['owner'] = local.model.get_user(
-        user_id=data['data']['attributes']['owner']
-    ).user_name
-    return data
+        # Fetch username instead of user_id for display on the front end.
+        data['data']['attributes']['owner'] = local.model.get_user(
+            user_id=data['data']['attributes']['owner']
+        ).user_name
+        return data
 
 
 @delete('/bundle_stores', apply=AuthenticatedProtectedPlugin())
@@ -579,9 +681,15 @@ def _delete_bundle_stores():
     """
     Delete the specified bundle stores.
     """
-    uuids = get_resource_ids(request.json, 'bundle_stores')
-    for uuid in uuids:
-        local.model.delete_bundle_store(request.user.user_id, uuid)
+    with tracer.start_as_current_span(
+        "/bundle_stores",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        uuids = get_resource_ids(request.json, 'bundle_stores')
+        for uuid in uuids:
+            local.model.delete_bundle_store(request.user.user_id, uuid)
 
 
 @get('/bundles/<uuid:re:%s>/contents/info/' % spec_util.UUID_STR, name='fetch_bundle_contents_info')
@@ -617,23 +725,32 @@ def _fetch_bundle_contents_info(uuid, path=''):
     }
     ```
     """
-    depth = query_get_type(int, 'depth', default=0)
-    target = BundleTarget(uuid, path)
-    if depth < 0:
-        abort(http.client.BAD_REQUEST, "Depth must be at least 0")
-
-    check_bundles_have_read_permission(local.model, request.user, [uuid])
-    try:
-        info = local.download_manager.get_target_info(target, depth)
-        # Object is not JSON serializable so submit its dict in API response
-        # The client is responsible for deserializing it
-        info['resolved_target'] = info['resolved_target'].__dict__
-    except NotFoundError as e:
-        abort(http.client.NOT_FOUND, str(e))
-    except Exception as e:
-        abort(http.client.BAD_REQUEST, str(e))
-
-    return {'data': info}
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>/contents/info/<path>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        current_span.set_attribute("operation.path", path)
+        depth = query_get_type(int, 'depth', default=0)
+        target = BundleTarget(uuid, path)
+        if depth < 0:
+            abort(http.client.BAD_REQUEST, "Depth must be at least 0")
+
+        check_bundles_have_read_permission(local.model, request.user, [uuid])
+        try:
+            info = local.download_manager.get_target_info(target, depth)
+            # Object is not JSON serializable so submit its dict in API response
+            # The client is responsible for deserializing it
+            info['resolved_target'] = info['resolved_target'].__dict__
+        except NotFoundError as e:
+            abort(http.client.NOT_FOUND, str(e))
+        except Exception as e:
+            abort(http.client.BAD_REQUEST, str(e))
+
+        return {'data': info}
 
 
 @put(
@@ -651,11 +768,20 @@ def _netcat_bundle(uuid, port):
     # general, this is not safe, since hitting a port can mutate what's
     # happening in the bundle.  In the future, we might want to make people
     # explicitly expose ports to the world.
-    check_bundles_have_read_permission(local.model, request.user, [uuid])
-    bundle = local.model.get_bundle(uuid)
-    if bundle.state != State.RUNNING:
-        abort(http.client.FORBIDDEN, 'Cannot netcat bundle, bundle not running.')
-    return local.download_manager.netcat(uuid, port, request.json['message'])
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>/netcat/<port>/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        current_span.set_attribute("operation.port", port)
+        check_bundles_have_read_permission(local.model, request.user, [uuid])
+        bundle = local.model.get_bundle(uuid)
+        if bundle.state != State.RUNNING:
+            abort(http.client.FORBIDDEN, 'Cannot netcat bundle, bundle not running.')
+        return local.download_manager.netcat(uuid, port, request.json['message'])
 
 
 @post(
@@ -688,49 +814,59 @@ def _netcurl_bundle(uuid, port, path=''):
     Forward an HTTP request into the specified port of the running bundle with uuid.
     Return the HTTP response from this bundle.
     """
-    check_bundles_have_read_permission(local.model, request.user, [uuid])
-    bundle = local.model.get_bundle(uuid)
-    if bundle.state in State.FINAL_STATES:
-        abort(http.client.FORBIDDEN, 'Cannot netcurl bundle, bundle already finalized.')
-
-    try:
-        request.path_shift(4)  # shift away the routing parts of the URL
-
-        # Put the request headers into the message
-        headers_string = [
-            '{}: {}'.format(h, request.headers.get(h)) for h in request.headers.keys()
-        ]
-        message = "{} {} HTTP/1.1\r\n".format(request.method, request.path)
-        message += "\r\n".join(headers_string) + "\r\n"
-        message += "\r\n"
-        message += request.body.read().decode()  # Assume bytes can be decoded to string
-
-        bytestring = local.download_manager.netcat(uuid, port, message)
-
-        # Parse the response
-        class FakeSocket:
-            def __init__(self, bytestring):
-                self._file = BytesIO(bytestring)
-
-            def makefile(self, *args, **kwargs):
-                return self._file
-
-        new_response = HTTPResponse(FakeSocket(bytestring))
-        new_response.begin()
-        # Copy the headers over
-        for k in new_response.headers:
-            response.headers[k] = new_response.headers[k]
-        # Return the response (which sends back the body)
-        return new_response
-    except Exception:
-        logger.exception(
-            "Failed to forward HTTP request for the bundle with uuid: {} for environment: {}".format(
-                uuid, request.environ
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>/netcurl/<port>/<path>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        current_span.set_attribute("operation.port", port)
+        current_span.set_attribute("operation.path", path)
+        check_bundles_have_read_permission(local.model, request.user, [uuid])
+        bundle = local.model.get_bundle(uuid)
+        if bundle.state in State.FINAL_STATES:
+            abort(http.client.FORBIDDEN, 'Cannot netcurl bundle, bundle already finalized.')
+
+        try:
+            request.path_shift(4)  # shift away the routing parts of the URL
+
+            # Put the request headers into the message
+            headers_string = [
+                '{}: {}'.format(h, request.headers.get(h)) for h in request.headers.keys()
+            ]
+            message = "{} {} HTTP/1.1\r\n".format(request.method, request.path)
+            message += "\r\n".join(headers_string) + "\r\n"
+            message += "\r\n"
+            message += request.body.read().decode()  # Assume bytes can be decoded to string
+
+            bytestring = local.download_manager.netcat(uuid, port, message)
+
+            # Parse the response
+            class FakeSocket:
+                def __init__(self, bytestring):
+                    self._file = BytesIO(bytestring)
+
+                def makefile(self, *args, **kwargs):
+                    return self._file
+
+            new_response = HTTPResponse(FakeSocket(bytestring))
+            new_response.begin()
+            # Copy the headers over
+            for k in new_response.headers:
+                response.headers[k] = new_response.headers[k]
+            # Return the response (which sends back the body)
+            return new_response
+        except Exception:
+            logger.exception(
+                "Failed to forward HTTP request for the bundle with uuid: {} for environment: {}".format(
+                    uuid, request.environ
+                )
             )
-        )
-        raise
-    finally:
-        request.path_shift(-4)  # restore the URL
+            raise
+        finally:
+            request.path_shift(-4)  # restore the URL
 
 
 @get(
@@ -794,149 +930,167 @@ def _fetch_bundle_contents_blob(uuid, path=''):
     be equivalent to the downloaded file if from a single-file target, but will be the size of the uncompressed
     archive, not the compressed archive, if from a directory target.
     """
-    byte_range = get_request_range()
-    head_lines = query_get_type(int, 'head', default=0)
-    tail_lines = query_get_type(int, 'tail', default=0)
-    truncation_text = query_get_type(str, 'truncation_text', default='')
-    max_line_length = query_get_type(int, 'max_line_length', default=128)
-    support_redirect = query_get_type(
-        int,
-        'support_redirect',
-        default=1 if get_request_source() == RequestSource.WEB_BROWSER else 0,
-    )
-    check_bundles_have_read_permission(local.model, request.user, [uuid])
-    target = BundleTarget(uuid, path)
-    fileobj = None
-
-    try:
-        target_info = local.download_manager.get_target_info(target, 0)
-        if target_info['resolved_target'] != target:
-            check_bundles_have_read_permission(
-                local.model, request.user, [target_info['resolved_target'].bundle_uuid]
-            )
-        target = target_info['resolved_target']
-    except NotFoundError as e:
-        abort(http.client.NOT_FOUND, str(e))
-    except Exception as e:
-        abort(http.client.BAD_REQUEST, str(e))
-
-    # Figure out the file name.
-    bundle = local.model.get_bundle(target.bundle_uuid)
-    bundle_name = bundle.metadata.name
-    if not path and bundle_name:
-        filename = bundle_name
-    else:
-        filename = target_info['name']
-
-    location_info, _ = local.bundle_store.get_bundle_location_full_info(bundle.uuid)
-
-    # We should redirect to the Blob Storage URL if the following conditions are met:
-    should_redirect_url = (
-        support_redirect == 1
-        and location_info["storage_type"]
-        in (StorageType.AZURE_BLOB_STORAGE.value, StorageType.GCS_STORAGE.value)
-        and path == ''  # No subpath
-        and request_accepts_gzip_encoding()  # Client accepts gzip encoding
-        and not (byte_range or head_lines or tail_lines)  # We're requesting the entire file
-    )
-
-    # We don't support bypassing server for single-file bundles located on GCS requested
-    if (
-        target_info['type'] == 'file'
-        and location_info["storage_type"] == StorageType.GCS_STORAGE.value
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>/contents/blob/<path>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
     ):
-        should_redirect_url = False
-
-    if target_info['type'] == 'directory':
-        if byte_range:
-            abort(http.client.BAD_REQUEST, 'Range not supported for directory blobs.')
-        if head_lines or tail_lines:
-            abort(http.client.BAD_REQUEST, 'Head and tail not supported for directory blobs.')
-        # Always tar and gzip directories
-        gzipped_stream = False  # but don't set the encoding to 'gzip'
-        mimetype = "application/gzip"
-        filename += ".tar.gz"
-        if not should_redirect_url:
-            fileobj = local.download_manager.stream_tarred_gzipped_directory(target)
-    elif target_info['type'] == 'file':
-        # Let's gzip to save bandwidth.
-        # For simplicity, we do this even if the file is already a packed
-        # archive (which should be relatively rare).
-        # The browser will transparently decode the file.
-        gzipped_stream = request_accepts_gzip_encoding()
-
-        # Since guess_type() will interpret '.tar.gz' as an 'application/x-tar' file
-        # with 'gzip' encoding, which would usually go into the Content-Encoding
-        # header. But if the bundle contents is actually a packed archive, we don't
-        # want the client to automatically decompress the file, so we don't want to
-        # set the Content-Encoding header. Instead, if guess_type() detects an
-        # archive, we just set mimetype to indicate an arbitrary binary file.
-        mimetype, encoding = mimetypes.guess_type(filename, strict=False)
-        if encoding is not None:
-            mimetype = 'application/octet-stream'
-
-        if not should_redirect_url:
-            if byte_range and (head_lines or tail_lines):
-                abort(http.client.BAD_REQUEST, 'Head and range not supported on the same request.')
-            elif byte_range:
-                start, end = byte_range
-                fileobj = local.download_manager.read_file_section(
-                    target, start, end - start + 1, gzipped_stream
-                )
-            elif head_lines or tail_lines:
-                fileobj = local.download_manager.summarize_file(
-                    target, head_lines, tail_lines, max_line_length, truncation_text, gzipped_stream
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+        current_span.set_attribute("operation.path", path)
+
+        byte_range = get_request_range()
+        head_lines = query_get_type(int, 'head', default=0)
+        tail_lines = query_get_type(int, 'tail', default=0)
+        truncation_text = query_get_type(str, 'truncation_text', default='')
+        max_line_length = query_get_type(int, 'max_line_length', default=128)
+        support_redirect = query_get_type(
+            int,
+            'support_redirect',
+            default=1 if get_request_source() == RequestSource.WEB_BROWSER else 0,
+        )
+        check_bundles_have_read_permission(local.model, request.user, [uuid])
+        target = BundleTarget(uuid, path)
+        fileobj = None
+
+        try:
+            target_info = local.download_manager.get_target_info(target, 0)
+            if target_info['resolved_target'] != target:
+                check_bundles_have_read_permission(
+                    local.model, request.user, [target_info['resolved_target'].bundle_uuid]
                 )
-            else:
-                fileobj = local.download_manager.stream_file(target, gzipped_stream)
-    else:
-        # Symlinks.
-        abort(
-            http.client.FORBIDDEN, 'Cannot download files of this type (%s).' % target_info['type']
+            target = target_info['resolved_target']
+        except NotFoundError as e:
+            abort(http.client.NOT_FOUND, str(e))
+        except Exception as e:
+            abort(http.client.BAD_REQUEST, str(e))
+
+        # Figure out the file name.
+        bundle = local.model.get_bundle(target.bundle_uuid)
+        bundle_name = bundle.metadata.name
+        if not path and bundle_name:
+            filename = bundle_name
+        else:
+            filename = target_info['name']
+
+        location_info, _ = local.bundle_store.get_bundle_location_full_info(bundle.uuid)
+
+        # We should redirect to the Blob Storage URL if the following conditions are met:
+        should_redirect_url = (
+            support_redirect == 1
+            and location_info["storage_type"]
+            in (StorageType.AZURE_BLOB_STORAGE.value, StorageType.GCS_STORAGE.value)
+            and path == ''  # No subpath
+            and request_accepts_gzip_encoding()  # Client accepts gzip encoding
+            and not (byte_range or head_lines or tail_lines)  # We're requesting the entire file
         )
 
-    # Set headers.
-    response.set_header('Content-Type', mimetype or 'text/plain')
-    response.set_header('Content-Encoding', 'gzip' if gzipped_stream else 'identity')
-    if target_info['type'] == 'file':
-        response.set_header('Content-Disposition', 'inline; filename="%s"' % filename)
-    else:
-        response.set_header('Content-Disposition', 'attachment; filename="%s"' % filename)
-    response.set_header('Target-Type', target_info['type'])
-    if target_info['type'] == 'file':
-        size = target_info['size']
-    elif not path and bundle_name:
-        # return data_size if the user requests the actual bundle
-        size = local.model.get_bundle_metadata([target.bundle_uuid], 'data_size').get(
-            target.bundle_uuid, 0
-        )
-    else:
-        # if request is for a subdir in a bundle then return 0
-        size = 0
-    response.set_header('X-Codalab-Target-Size', size)
-
-    if should_redirect_url:
-        # Redirect to SAS URL on Blob Storage.
-        assert fileobj is None  # We should not be returning any other contents.
-        download_url = local.download_manager.get_target_download_url(
-            target,
-            # We pass these parameters to set the Content-Type, Content-Encoding, and
-            # Content-Disposition headers that are set on the Blob Storage response.
-            content_type=response.get_header('Content-Type'),
-            content_encoding=response.get_header('Content-Encoding'),
-            content_disposition=response.get_header('Content-Disposition'),
-        )
-        # Quirk when running CodaLab locally -- if this endpoint was called from within a Docker container
-        # such as the REST server or the worker, we need to redirect to http://azurite. This is because
-        # of the way Docker networking is set up, as local Docker containers doesn't have access to
-        # Azurite through http://localhost, but rather only through http://azurite.
-        if LOCAL_USING_AZURITE:
-            if get_request_source() == RequestSource.LOCAL_DOCKER:
-                download_url = download_url.replace("localhost", "azurite", 1)
-        return redirect(
-            download_url
-        )  # the client receive http 303, and send the request to new url
-    return fileobj
+        # We don't support bypassing server for single-file bundles located on GCS requested
+        if (
+            target_info['type'] == 'file'
+            and location_info["storage_type"] == StorageType.GCS_STORAGE.value
+        ):
+            should_redirect_url = False
+
+        if target_info['type'] == 'directory':
+            if byte_range:
+                abort(http.client.BAD_REQUEST, 'Range not supported for directory blobs.')
+            if head_lines or tail_lines:
+                abort(http.client.BAD_REQUEST, 'Head and tail not supported for directory blobs.')
+            # Always tar and gzip directories
+            gzipped_stream = False  # but don't set the encoding to 'gzip'
+            mimetype = "application/gzip"
+            filename += ".tar.gz"
+            if not should_redirect_url:
+                fileobj = local.download_manager.stream_tarred_gzipped_directory(target)
+        elif target_info['type'] == 'file':
+            # Let's gzip to save bandwidth.
+            # For simplicity, we do this even if the file is already a packed
+            # archive (which should be relatively rare).
+            # The browser will transparently decode the file.
+            gzipped_stream = request_accepts_gzip_encoding()
+
+            # Since guess_type() will interpret '.tar.gz' as an 'application/x-tar' file
+            # with 'gzip' encoding, which would usually go into the Content-Encoding
+            # header. But if the bundle contents is actually a packed archive, we don't
+            # want the client to automatically decompress the file, so we don't want to
+            # set the Content-Encoding header. Instead, if guess_type() detects an
+            # archive, we just set mimetype to indicate an arbitrary binary file.
+            mimetype, encoding = mimetypes.guess_type(filename, strict=False)
+            if encoding is not None:
+                mimetype = 'application/octet-stream'
+
+            if not should_redirect_url:
+                if byte_range and (head_lines or tail_lines):
+                    abort(
+                        http.client.BAD_REQUEST, 'Head and range not supported on the same request.'
+                    )
+                elif byte_range:
+                    start, end = byte_range
+                    fileobj = local.download_manager.read_file_section(
+                        target, start, end - start + 1, gzipped_stream
+                    )
+                elif head_lines or tail_lines:
+                    fileobj = local.download_manager.summarize_file(
+                        target,
+                        head_lines,
+                        tail_lines,
+                        max_line_length,
+                        truncation_text,
+                        gzipped_stream,
+                    )
+                else:
+                    fileobj = local.download_manager.stream_file(target, gzipped_stream)
+        else:
+            # Symlinks.
+            abort(
+                http.client.FORBIDDEN,
+                'Cannot download files of this type (%s).' % target_info['type'],
+            )
+
+        # Set headers.
+        response.set_header('Content-Type', mimetype or 'text/plain')
+        response.set_header('Content-Encoding', 'gzip' if gzipped_stream else 'identity')
+        if target_info['type'] == 'file':
+            response.set_header('Content-Disposition', 'inline; filename="%s"' % filename)
+        else:
+            response.set_header('Content-Disposition', 'attachment; filename="%s"' % filename)
+        response.set_header('Target-Type', target_info['type'])
+        if target_info['type'] == 'file':
+            size = target_info['size']
+        elif not path and bundle_name:
+            # return data_size if the user requests the actual bundle
+            size = local.model.get_bundle_metadata([target.bundle_uuid], 'data_size').get(
+                target.bundle_uuid, 0
+            )
+        else:
+            # if request is for a subdir in a bundle then return 0
+            size = 0
+        response.set_header('X-Codalab-Target-Size', size)
+
+        if should_redirect_url:
+            # Redirect to SAS URL on Blob Storage.
+            assert fileobj is None  # We should not be returning any other contents.
+            download_url = local.download_manager.get_target_download_url(
+                target,
+                # We pass these parameters to set the Content-Type, Content-Encoding, and
+                # Content-Disposition headers that are set on the Blob Storage response.
+                content_type=response.get_header('Content-Type'),
+                content_encoding=response.get_header('Content-Encoding'),
+                content_disposition=response.get_header('Content-Disposition'),
+            )
+            # Quirk when running CodaLab locally -- if this endpoint was called from within a Docker container
+            # such as the REST server or the worker, we need to redirect to http://azurite. This is because
+            # of the way Docker networking is set up, as local Docker containers doesn't have access to
+            # Azurite through http://localhost, but rather only through http://azurite.
+            if LOCAL_USING_AZURITE:
+                if get_request_source() == RequestSource.LOCAL_DOCKER:
+                    download_url = download_url.replace("localhost", "azurite", 1)
+            return redirect(
+                download_url
+            )  # the client receive http 303, and send the request to new url
+        return fileobj
 
 
 @put(
@@ -972,90 +1126,80 @@ def _update_bundle_contents_blob(uuid):
     - `store`: (optional) The name of the bundle store where the bundle should be uploaded to.
       If unspecified, the CLI will pick the optimal available bundle store.
     """
-    check_bundles_have_all_permission(local.model, request.user, [uuid])
-    bundle = local.model.get_bundle(uuid)
-    if bundle.state in State.FINAL_STATES:
-        abort(http.client.FORBIDDEN, 'Contents cannot be modified, bundle already finalized.')
-
-    # Get and validate query parameters
-    finalize_on_failure = query_get_bool('finalize_on_failure', default=False)
-    finalize_on_success = query_get_bool('finalize_on_success', default=True)
-    use_azure_blob_beta = query_get_bool('use_azure_blob_beta', default=False)
-    if os.getenv("CODALAB_ALWAYS_USE_AZURE_BLOB_BETA") == "1":
-        use_azure_blob_beta = True
-    store_name = request.query.get('store') or os.getenv('CODALAB_DEFAULT_BUNDLE_STORE_NAME')
-    store = (
-        local.model.get_bundle_store(request.user.user_id, name=store_name) if store_name else None
-    )
-    final_state = request.query.get('state_on_success', default=State.READY)
-    if finalize_on_success and final_state not in State.FINAL_STATES:
-        abort(
-            http.client.BAD_REQUEST,
-            'state_on_success must be one of %s' % '|'.join(State.FINAL_STATES),
+    with tracer.start_as_current_span(
+        "/bundles/<uuid>/contents/blob/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+
+        check_bundles_have_all_permission(local.model, request.user, [uuid])
+        bundle = local.model.get_bundle(uuid)
+        if bundle.state in State.FINAL_STATES:
+            abort(http.client.FORBIDDEN, 'Contents cannot be modified, bundle already finalized.')
+
+        # Get and validate query parameters
+        finalize_on_failure = query_get_bool('finalize_on_failure', default=False)
+        finalize_on_success = query_get_bool('finalize_on_success', default=True)
+        use_azure_blob_beta = query_get_bool('use_azure_blob_beta', default=False)
+        if os.getenv("CODALAB_ALWAYS_USE_AZURE_BLOB_BETA") == "1":
+            use_azure_blob_beta = True
+        store_name = request.query.get('store') or os.getenv('CODALAB_DEFAULT_BUNDLE_STORE_NAME')
+        store = (
+            local.model.get_bundle_store(request.user.user_id, name=store_name)
+            if store_name
+            else None
         )
-
-    # If this bundle already has data, remove it.
-    if local.upload_manager.has_contents(bundle):
-        local.upload_manager.cleanup_existing_contents(bundle)
-
-    # Store the data.
-    try:
-        source = None
-        if request.query.urls:
-            sources = query_get_list('urls')
-            if len(sources) != 1:
-                abort(http.client.BAD_REQUEST, "Exactly one url must be provided.")
-            source = sources[0]
-        # request without "filename" doesn't need to upload to bundle store
-        if request.query.filename:
-            filename = request.query.get('filename', default='contents')
-            source = (filename, request['wsgi.input'])
-        bundle_link_url = getattr(bundle.metadata, "link_url", None)
-        if bundle_link_url:
-            # Don't upload to bundle store if using --link, as the path
-            # already exists.
-            pass
-        elif source:
-            local.upload_manager.upload_to_bundle_store(
-                bundle,
-                source=source,
-                git=query_get_bool('git', default=False),
-                unpack=query_get_bool('unpack', default=True),
-                use_azure_blob_beta=use_azure_blob_beta,
-                destination_bundle_store=store,
+        final_state = request.query.get('state_on_success', default=State.READY)
+        if finalize_on_success and final_state not in State.FINAL_STATES:
+            abort(
+                http.client.BAD_REQUEST,
+                'state_on_success must be one of %s' % '|'.join(State.FINAL_STATES),
             )
-            bundle_link_url = getattr(bundle.metadata, "link_url", None)
-            bundle_location = bundle_link_url or local.bundle_store.get_bundle_location(bundle.uuid)
-            local.model.update_disk_metadata(bundle, bundle_location, enforce_disk_quota=True)
-
-    except UsageError as err:
-        # This is a user error (most likely disk quota overuser) so raise a client HTTP error
-        if local.upload_manager.has_contents(bundle):
-            local.upload_manager.cleanup_existing_contents(bundle)
-        msg = "Upload failed: %s" % err
-        local.model.update_bundle(
-            bundle,
-            {
-                'state': State.FAILED,
-                'metadata': {'failure_message': msg, 'error_traceback': traceback.format_exc()},
-            },
-        )
-        abort(http.client.BAD_REQUEST, msg)
 
-    except Exception as e:
-        # Upload failed: cleanup, update state if desired, and return HTTP error
+        # If this bundle already has data, remove it.
         if local.upload_manager.has_contents(bundle):
             local.upload_manager.cleanup_existing_contents(bundle)
 
-        msg = "Upload failed: %s" % e
+        # Store the data.
+        try:
+            source = None
+            if request.query.urls:
+                sources = query_get_list('urls')
+                if len(sources) != 1:
+                    abort(http.client.BAD_REQUEST, "Exactly one url must be provided.")
+                source = sources[0]
+            # request without "filename" doesn't need to upload to bundle store
+            if request.query.filename:
+                filename = request.query.get('filename', default='contents')
+                source = (filename, request['wsgi.input'])
+            bundle_link_url = getattr(bundle.metadata, "link_url", None)
+            if bundle_link_url:
+                # Don't upload to bundle store if using --link, as the path
+                # already exists.
+                pass
+            elif source:
+                local.upload_manager.upload_to_bundle_store(
+                    bundle,
+                    source=source,
+                    git=query_get_bool('git', default=False),
+                    unpack=query_get_bool('unpack', default=True),
+                    use_azure_blob_beta=use_azure_blob_beta,
+                    destination_bundle_store=store,
+                )
+                bundle_link_url = getattr(bundle.metadata, "link_url", None)
+                bundle_location = bundle_link_url or local.bundle_store.get_bundle_location(
+                    bundle.uuid
+                )
+                local.model.update_disk_metadata(bundle, bundle_location, enforce_disk_quota=True)
 
-        # The client may not want to finalize the bundle on failure, to keep
-        # open the possibility of retrying the upload in the case of transient
-        # failure.
-        # Workers also use this API endpoint to upload partial contents of
-        # running bundles, and they should use finalize_on_failure=0 to avoid
-        # letting transient errors during upload fail the bundles prematurely.
-        if finalize_on_failure:
+        except UsageError as err:
+            # This is a user error (most likely disk quota overuser) so raise a client HTTP error
+            if local.upload_manager.has_contents(bundle):
+                local.upload_manager.cleanup_existing_contents(bundle)
+            msg = "Upload failed: %s" % err
             local.model.update_bundle(
                 bundle,
                 {
@@ -1063,18 +1207,49 @@ def _update_bundle_contents_blob(uuid):
                     'metadata': {'failure_message': msg, 'error_traceback': traceback.format_exc()},
                 },
             )
-        else:
-            local.model.update_bundle(
-                bundle,
-                {'metadata': {'failure_message': msg, 'error_traceback': traceback.format_exc()},},
-            )
+            abort(http.client.BAD_REQUEST, msg)
+
+        except Exception as e:
+            # Upload failed: cleanup, update state if desired, and return HTTP error
+            if local.upload_manager.has_contents(bundle):
+                local.upload_manager.cleanup_existing_contents(bundle)
+
+            msg = "Upload failed: %s" % e
+
+            # The client may not want to finalize the bundle on failure, to keep
+            # open the possibility of retrying the upload in the case of transient
+            # failure.
+            # Workers also use this API endpoint to upload partial contents of
+            # running bundles, and they should use finalize_on_failure=0 to avoid
+            # letting transient errors during upload fail the bundles prematurely.
+            if finalize_on_failure:
+                local.model.update_bundle(
+                    bundle,
+                    {
+                        'state': State.FAILED,
+                        'metadata': {
+                            'failure_message': msg,
+                            'error_traceback': traceback.format_exc(),
+                        },
+                    },
+                )
+            else:
+                local.model.update_bundle(
+                    bundle,
+                    {
+                        'metadata': {
+                            'failure_message': msg,
+                            'error_traceback': traceback.format_exc(),
+                        },
+                    },
+                )
 
-        abort(http.client.INTERNAL_SERVER_ERROR, msg)
+            abort(http.client.INTERNAL_SERVER_ERROR, msg)
 
-    else:
-        if finalize_on_success:
-            # Upload succeeded: update state
-            local.model.update_bundle(bundle, {'state': final_state})
+        else:
+            if finalize_on_success:
+                # Upload succeeded: update state
+                local.model.update_bundle(bundle, {'state': final_state})
 
 
 #############################################################
diff --git a/codalab/rest/cli.py b/codalab/rest/cli.py
index e53d7046..2f699efa 100644
--- a/codalab/rest/cli.py
+++ b/codalab/rest/cli.py
@@ -14,6 +14,11 @@ from codalab.lib import bundle_cli
 from codalab.lib.codalab_manager import CodaLabManager
 from codalab.objects.oauth2 import OAuth2Token
 from codalab.server.authenticated_plugin import ProtectedPlugin
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @post('/cli/command', apply=ProtectedPlugin())
@@ -36,17 +41,23 @@ def post_worksheets_command():
     }
     ```
     """
-    query = request.json
-    if 'worksheet_uuid' not in query:
-        abort(httplib.BAD_REQUEST, 'Missing `workhseet_uuid`')
-    if 'command' not in query:
-        abort(httplib.BAD_REQUEST, 'Missing `command`')
-
-    # If 'autocomplete' field is set, return a list of completions instead
-    if query.get('autocomplete', False):
-        return {'completions': complete_command(query['worksheet_uuid'], query['command'])}
-
-    return general_command(query['worksheet_uuid'], query['command'])
+    with tracer.start_as_current_span(
+        "/cli/command",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        query = request.json
+        if 'worksheet_uuid' not in query:
+            abort(httplib.BAD_REQUEST, 'Missing `workhseet_uuid`')
+        if 'command' not in query:
+            abort(httplib.BAD_REQUEST, 'Missing `command`')
+
+        # If 'autocomplete' field is set, return a list of completions instead
+        if query.get('autocomplete', False):
+            return {'completions': complete_command(query['worksheet_uuid'], query['command'])}
+
+        return general_command(query['worksheet_uuid'], query['command'])
 
 
 def rest_url():
diff --git a/codalab/rest/groups.py b/codalab/rest/groups.py
index cc3b3d1e..7a843daa 100644
--- a/codalab/rest/groups.py
+++ b/codalab/rest/groups.py
@@ -10,36 +10,56 @@ from codalab.lib.server_util import json_api_include
 from codalab.rest.schemas import GroupSchema, UserSchema
 from codalab.rest.util import ensure_unused_group_name, get_group_info, get_resource_ids
 from codalab.server.authenticated_plugin import AuthenticatedProtectedPlugin
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @get('/groups/<group_spec>', apply=AuthenticatedProtectedPlugin())
 def fetch_group(group_spec):
     """Fetch a single group."""
-    group = get_group_info(group_spec, need_admin=False, access_all_groups=True)
-    load_group_members(group)
-    document = GroupSchema().dump(group).data
-    include_group_relationships(document, [group])
-    return document
+    with tracer.start_as_current_span(
+        "/groups/<group_spec>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.group_spec", group_spec)
+
+        group = get_group_info(group_spec, need_admin=False, access_all_groups=True)
+        load_group_members(group)
+        document = GroupSchema().dump(group).data
+        include_group_relationships(document, [group])
+        return document
 
 
 @get('/groups', apply=AuthenticatedProtectedPlugin())
 def fetch_groups():
     """Fetch list of groups readable by the authenticated user."""
-    if request.user.user_id == local.model.root_user_id:
-        groups = local.model.batch_get_all_groups(None, {'user_defined': True}, None)
-    else:
-        groups = local.model.batch_get_all_groups(
-            None,
-            {'owner_id': request.user.user_id, 'user_defined': True},
-            {'user_id': request.user.user_id},
-        )
+    with tracer.start_as_current_span(
+        "/groups",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        if request.user.user_id == local.model.root_user_id:
+            groups = local.model.batch_get_all_groups(None, {'user_defined': True}, None)
+        else:
+            groups = local.model.batch_get_all_groups(
+                None,
+                {'owner_id': request.user.user_id, 'user_defined': True},
+                {'user_id': request.user.user_id},
+            )
 
-    for group in groups:
-        load_group_members(group)
+        for group in groups:
+            load_group_members(group)
 
-    document = GroupSchema(many=True).dump(groups).data
-    include_group_relationships(document, groups)
-    return document
+        document = GroupSchema(many=True).dump(groups).data
+        include_group_relationships(document, groups)
+        return document
 
 
 def load_group_members(group):
@@ -83,26 +103,48 @@ def delete_groups():
 @post('/groups', apply=AuthenticatedProtectedPlugin())
 def create_group():
     """Create a group."""
-    groups = GroupSchema(strict=True, many=True).load(request.json, partial=True).data
-    created_groups = []
-    for group in groups:
-        ensure_unused_group_name(group['name'])
-        group['owner_id'] = request.user.user_id
-        group['user_defined'] = True
-        group = local.model.create_group(group)
-        local.model.add_user_in_group(request.user.user_id, group['uuid'], is_admin=True)
-        created_groups.append(group)
-    return GroupSchema(many=True).dump(created_groups).data
+    with tracer.start_as_current_span(
+        "/groups",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        groups = GroupSchema(strict=True, many=True).load(request.json, partial=True).data
+        created_groups = []
+        for group in groups:
+            ensure_unused_group_name(group['name'])
+            group['owner_id'] = request.user.user_id
+            group['user_defined'] = True
+            group = local.model.create_group(group)
+            local.model.add_user_in_group(request.user.user_id, group['uuid'], is_admin=True)
+            created_groups.append(group)
+        return GroupSchema(many=True).dump(created_groups).data
 
 
 @post('/groups/<group_spec>/relationships/admins', apply=AuthenticatedProtectedPlugin())
 def add_group_admins(group_spec):
-    return add_group_members_helper(group_spec, True)
+    with tracer.start_as_current_span(
+        "/groups/<group_spec>/relationships/admins",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.group_spec", group_spec)
+        return add_group_members_helper(group_spec, True)
 
 
 @post('/groups/<group_spec>/relationships/members', apply=AuthenticatedProtectedPlugin())
 def add_group_members(group_spec):
-    return add_group_members_helper(group_spec, False)
+    with tracer.start_as_current_span(
+        "/groups/<group_spec>/relationships/members",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.group_spec", group_spec)
+        return add_group_members_helper(group_spec, False)
 
 
 def add_group_members_helper(group_spec, is_admin):
@@ -127,9 +169,17 @@ def add_group_members_helper(group_spec, is_admin):
 @delete('/groups/<group_spec>/relationships/admins', apply=AuthenticatedProtectedPlugin())
 @delete('/groups/<group_spec>/relationships/members', apply=AuthenticatedProtectedPlugin())
 def delete_group_members(group_spec):
-    # For now, both routes will delete a member entirely from the group.
-    user_ids = get_resource_ids(request.json, 'users')
-    group = get_group_info(group_spec, need_admin=True)
-    for user_id in user_ids:
-        local.model.delete_user_in_group(user_id, group['uuid'])
-    abort(http.client.NO_CONTENT)
+    with tracer.start_as_current_span(
+        "/groups/<group_spec>/relationships/members",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.group_spec", group_spec)
+        # For now, both routes will delete a member entirely from the group.
+        user_ids = get_resource_ids(request.json, 'users')
+        group = get_group_info(group_spec, need_admin=True)
+        for user_id in user_ids:
+            local.model.delete_user_in_group(user_id, group['uuid'])
+        abort(http.client.NO_CONTENT)
diff --git a/codalab/rest/help.py b/codalab/rest/help.py
index 34539813..ec952155 100644
--- a/codalab/rest/help.py
+++ b/codalab/rest/help.py
@@ -3,38 +3,49 @@ import sys
 from bottle import request, local, post, template
 
 from codalab.server.authenticated_plugin import AuthenticatedPlugin, UserVerifiedPlugin
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @post('/help/', apply=AuthenticatedPlugin(), skip=UserVerifiedPlugin)
 def send_help_message():
-    message = request.json['message']
-
-    if 'server' in local.config and 'support_email' not in local.config['server']:
-        print('Warning: No support_email configured, so no email sent.', file=sys.stderr)
-        print('User\'s message: %s' % message, file=sys.stderr)
-        return
-
-    support_email = local.config['server']['support_email']
-    username = request.user.user_name
-    user_email = request.user.email
-    originUrl = request.get_header('Referer')
-
-    first_name = request.user.first_name if request.user.first_name else ''
-    last_name = request.user.last_name if request.user.last_name else ''
-    real_name = "%s %s" % (first_name, last_name)
-    message = message.encode('utf-8')
-
-    local.emailer.send_email(
-        subject="Message from %s" % user_email,
-        body=template(
-            'help_message_to_codalab_body',
-            real_name=real_name,
-            username=username,
-            email=user_email,
-            message=message,
-            originUrl=originUrl,
-        ),
-        recipient=support_email,
-        sender=user_email,
-        charset='utf-8',
-    )
+    with tracer.start_as_current_span(
+        "/help/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        message = request.json['message']
+
+        if 'server' in local.config and 'support_email' not in local.config['server']:
+            print('Warning: No support_email configured, so no email sent.', file=sys.stderr)
+            print('User\'s message: %s' % message, file=sys.stderr)
+            return
+
+        support_email = local.config['server']['support_email']
+        username = request.user.user_name
+        user_email = request.user.email
+        originUrl = request.get_header('Referer')
+
+        first_name = request.user.first_name if request.user.first_name else ''
+        last_name = request.user.last_name if request.user.last_name else ''
+        real_name = "%s %s" % (first_name, last_name)
+        message = message.encode('utf-8')
+
+        local.emailer.send_email(
+            subject="Message from %s" % user_email,
+            body=template(
+                'help_message_to_codalab_body',
+                real_name=real_name,
+                username=username,
+                email=user_email,
+                message=message,
+                originUrl=originUrl,
+            ),
+            recipient=support_email,
+            sender=user_email,
+            charset='utf-8',
+        )
diff --git a/codalab/rest/interpret.py b/codalab/rest/interpret.py
index cf4bdb21..8abe0003 100644
--- a/codalab/rest/interpret.py
+++ b/codalab/rest/interpret.py
@@ -63,10 +63,16 @@ def _interpret_search():
     }
     ```
     """
-    query = request.json
-    if 'keywords' not in query:
-        abort(httplib.BAD_REQUEST, 'Missing `keywords`')
-    return {'response': interpret_search(query['keywords'])}
+    with tracer.start_as_current_span(
+        "/interpret/search",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        query = request.json
+        if 'keywords' not in query:
+            abort(httplib.BAD_REQUEST, 'Missing `keywords`')
+        return {'response': interpret_search(query['keywords'])}
 
 
 @post('/interpret/wsearch', apply=ProtectedPlugin())
@@ -103,11 +109,17 @@ def _interpret_wsearch():
     }
     ```
     """
-    query = request.json
-    if 'keywords' not in query:
-        abort(httplib.BAD_REQUEST, 'Missing `keywords`')
+    with tracer.start_as_current_span(
+        "/interpret/wsearch",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        query = request.json
+        if 'keywords' not in query:
+            abort(httplib.BAD_REQUEST, 'Missing `keywords`')
 
-    return {'response': interpret_wsearch(query['keywords'])}
+        return {'response': interpret_wsearch(query['keywords'])}
 
 
 @post('/interpret/file-genpaths', apply=ProtectedPlugin())
@@ -139,9 +151,15 @@ def _interpret_file_genpaths():
     }
     ```
     """
-    queries = [(q['bundle_uuid'], q['genpath'], q['post']) for q in request.json['queries']]
-    results = interpret_file_genpaths(queries)
-    return {'data': results}
+    with tracer.start_as_current_span(
+        "/interpret/file-genpaths",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        queries = [(q['bundle_uuid'], q['genpath'], q['post']) for q in request.json['queries']]
+        results = interpret_file_genpaths(queries)
+        return {'data': results}
 
 
 @post('/interpret/genpath-table-contents', apply=ProtectedPlugin())
@@ -177,9 +195,15 @@ def _interpret_genpath_table_contents():
     }
     ```
     """
-    contents = request.json['contents']
-    new_contents = interpret_genpath_table_contents(contents)
-    return {'contents': new_contents}
+    with tracer.start_as_current_span(
+        "/interpret/genpath-table-contents",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        contents = request.json['contents']
+        new_contents = interpret_genpath_table_contents(contents)
+        return {'contents': new_contents}
 
 
 @get('/interpret/worksheet/<uuid:re:%s>' % spec_util.UUID_STR, apply=ProtectedPlugin())
@@ -225,130 +249,142 @@ def fetch_interpreted_worksheet(uuid):
     pass in the search query to the "directive" argument. The value for this argument
     must be a search/wsearch query -- for example, &directive=search 0x .limit=100
     """
-    bundle_uuids = request.query.getall('bundle_uuid')
-    brief = request.query.get("brief", "0") == "1"
+    with tracer.start_as_current_span(
+        "/interpret/worksheet/{uuid}",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        bundle_uuids = request.query.getall('bundle_uuid')
+        brief = request.query.get("brief", "0") == "1"
 
-    directive = request.query.get("directive", None)
-    search_results = []
+        directive = request.query.get("directive", None)
+        search_results = []
 
-    worksheet_info = get_worksheet_info(uuid, fetch_items=True, fetch_permissions=True)
+        worksheet_info = get_worksheet_info(uuid, fetch_items=True, fetch_permissions=True)
 
-    # Shim in additional data for the frontend
-    worksheet_info['items'] = resolve_items_into_infos(worksheet_info['items'])
+        # Shim in additional data for the frontend
+        worksheet_info['items'] = resolve_items_into_infos(worksheet_info['items'])
 
-    if worksheet_info['owner_id'] is None:
-        worksheet_info['owner_name'] = None
-    else:
-        owner = local.model.get_user(user_id=worksheet_info['owner_id'])
-        worksheet_info['owner_name'] = owner.user_name
-
-    # Fetch items.
-    worksheet_info['source'] = get_worksheet_lines(worksheet_info)
-
-    if not directive and not brief:
-        expanded_items = []
-        for index, raw_item in enumerate(worksheet_info['items']):
-            expanded = expand_search_item(raw_item)
-            expanded_items.append(expanded)
-            # Multiple items can correspond to the same source line (i.e: search directives)
-            # raw_items_to_source_index.extend([index] * len(expanded))
-        worksheet_info['items'] = list(chain.from_iterable(expanded_items))
-    elif directive:
-        # Only expand the search item corresponding to the given directive.
-        # Used in async loading to only load a single table.
-        items_to_show = []
-        for i, item in enumerate(worksheet_info['items']):
-            (bundle_info, subworksheet_info, value_obj, item_type, id, sort_key) = item
-            if directive == formatting.tokens_to_string(value_obj):
-                search_results = perform_search_query(value_obj)
-                items_to_show.append(item)
-                break
-            elif item_type == TYPE_DIRECTIVE:
-                # We need to include previous directives
-                # so that the final search result can be properly
-                # rendered (it may depend on a schema defined earlier
-                # in the worksheet).
-                items_to_show.append(item)
-        # Make sure the search item is at the end of worksheet_info['items'],
-        # so we can isolate it later after interpret_items is called.
-        worksheet_info['items'] = items_to_show
-        worksheet_info['items'].extend(search_results)
-
-    # Set permissions
-    worksheet_info['edit_permission'] = worksheet_info['permission'] == GROUP_OBJECT_PERMISSION_ALL
-    # Check enable chat box
-    worksheet_info['enable_chat'] = local.config.get('enable_chat', False)
-    # Format permissions into strings
-    worksheet_info['permission_spec'] = permission_str(worksheet_info['permission'])
-    for group_permission in worksheet_info['group_permissions']:
-        group_permission['permission_spec'] = permission_str(group_permission['permission'])
-
-    # Go and fetch more information about the worksheet contents by
-    # resolving the interpreted items.
-    try:
-        interpreted_blocks = interpret_items(
-            get_default_schemas(), worksheet_info['items'], db_model=local.model
+        if worksheet_info['owner_id'] is None:
+            worksheet_info['owner_name'] = None
+        else:
+            owner = local.model.get_user(user_id=worksheet_info['owner_id'])
+            worksheet_info['owner_name'] = owner.user_name
+
+        # Fetch items.
+        worksheet_info['source'] = get_worksheet_lines(worksheet_info)
+
+        if not directive and not brief:
+            expanded_items = []
+            for index, raw_item in enumerate(worksheet_info['items']):
+                expanded = expand_search_item(raw_item)
+                expanded_items.append(expanded)
+                # Multiple items can correspond to the same source line (i.e: search directives)
+                # raw_items_to_source_index.extend([index] * len(expanded))
+            worksheet_info['items'] = list(chain.from_iterable(expanded_items))
+        elif directive:
+            # Only expand the search item corresponding to the given directive.
+            # Used in async loading to only load a single table.
+            items_to_show = []
+            for i, item in enumerate(worksheet_info['items']):
+                (bundle_info, subworksheet_info, value_obj, item_type, id, sort_key) = item
+                if directive == formatting.tokens_to_string(value_obj):
+                    search_results = perform_search_query(value_obj)
+                    items_to_show.append(item)
+                    break
+                elif item_type == TYPE_DIRECTIVE:
+                    # We need to include previous directives
+                    # so that the final search result can be properly
+                    # rendered (it may depend on a schema defined earlier
+                    # in the worksheet).
+                    items_to_show.append(item)
+            # Make sure the search item is at the end of worksheet_info['items'],
+            # so we can isolate it later after interpret_items is called.
+            worksheet_info['items'] = items_to_show
+            worksheet_info['items'].extend(search_results)
+
+        # Set permissions
+        worksheet_info['edit_permission'] = (
+            worksheet_info['permission'] == GROUP_OBJECT_PERMISSION_ALL
         )
-    except UsageError as e:
-        interpreted_blocks = {'blocks': []}
-        worksheet_info['error'] = str(e)
-
-    # bundle_uuids is an optional argument that, if exists, contain the uuids of all the unfinished run bundles that need updating
-    # In this case, full_worksheet will return a list of item parallel to ws.info.items that contain only items that need updating.
-    # More specifically, all blocks that don't contain run bundles that need updating are None.
-    # Also, a non-None block could contain a list of bundle_infos, which represent a list of bundles. Usually not all of them need updating.
-    # The bundle_infos for bundles that don't need updating are also None.
-    if bundle_uuids:
-        for i, block in enumerate(interpreted_blocks['blocks']):
-            if not ('bundles_spec' in block and 'bundle_infos' in block['bundles_spec']):
-                interpreted_blocks['blocks'][i] = None
-            else:
-                if isinstance(block['bundles_spec']['bundle_infos'], dict):
-                    block['bundles_spec']['bundle_infos'] = [block['bundles_spec']['bundle_infos']]
-                is_relevant_block = False
-                for j, bundle in enumerate(block['bundles_spec']['bundle_infos']):
-                    if bundle['uuid'] in bundle_uuids:
-                        is_relevant_block = True
-                    else:
-                        block['bundles_spec']['bundle_infos'][j] = None
-                if not is_relevant_block:
+        # Check enable chat box
+        worksheet_info['enable_chat'] = local.config.get('enable_chat', False)
+        # Format permissions into strings
+        worksheet_info['permission_spec'] = permission_str(worksheet_info['permission'])
+        for group_permission in worksheet_info['group_permissions']:
+            group_permission['permission_spec'] = permission_str(group_permission['permission'])
+
+        # Go and fetch more information about the worksheet contents by
+        # resolving the interpreted items.
+        try:
+            interpreted_blocks = interpret_items(
+                get_default_schemas(), worksheet_info['items'], db_model=local.model
+            )
+        except UsageError as e:
+            interpreted_blocks = {'blocks': []}
+            worksheet_info['error'] = str(e)
+
+        # bundle_uuids is an optional argument that, if exists, contain the uuids of all the unfinished run bundles that need updating
+        # In this case, full_worksheet will return a list of item parallel to ws.info.items that contain only items that need updating.
+        # More specifically, all blocks that don't contain run bundles that need updating are None.
+        # Also, a non-None block could contain a list of bundle_infos, which represent a list of bundles. Usually not all of them need updating.
+        # The bundle_infos for bundles that don't need updating are also None.
+        if bundle_uuids:
+            for i, block in enumerate(interpreted_blocks['blocks']):
+                if not ('bundles_spec' in block and 'bundle_infos' in block['bundles_spec']):
                     interpreted_blocks['blocks'][i] = None
-    # Grouped individual items into blocks
-    worksheet_info['blocks'] = resolve_interpreted_blocks(interpreted_blocks['blocks'], brief=brief)
-    worksheet_info['raw_to_block'] = interpreted_blocks['raw_to_block']
-    worksheet_info['block_to_raw'] = interpreted_blocks['block_to_raw']
-
-    if directive:
-        # If we're only async loading a single table_block / subworksheets_block,
-        # return only that block (which is at the end of worksheet_info['items'])
-        worksheet_info['blocks'] = [worksheet_info['blocks'][-1]] if len(search_results) else []
-
-    for block in worksheet_info['blocks']:
-        if block is None:
-            continue
-        if block['mode'] == 'table':
-            for row_map in block['rows']:
-                for k, v in row_map.items():
-                    if v is None:
-                        row_map[k] = formatting.contents_str(v)
-        if 'bundle_info' in block:
-            infos = []
-            if isinstance(block['bundle_info'], list):
-                infos = block['bundle_info']
-            elif isinstance(block['bundle_info'], dict):
-                infos = [block['bundle_info']]
-            for bundle_info in infos:
-                if bundle_info is None:
-                    continue
-                if 'bundle_type' not in bundle_info:
-                    continue  # empty info: invalid bundle reference
-                if isinstance(bundle_info, dict):
-                    format_metadata(bundle_info.get('metadata'))
-    # Frontend doesn't use individual 'items' for now
-    del worksheet_info['items']
-    if bundle_uuids:
-        return {'blocks': worksheet_info['blocks'], 'uuid': uuid}
-    return worksheet_info
+                else:
+                    if isinstance(block['bundles_spec']['bundle_infos'], dict):
+                        block['bundles_spec']['bundle_infos'] = [
+                            block['bundles_spec']['bundle_infos']
+                        ]
+                    is_relevant_block = False
+                    for j, bundle in enumerate(block['bundles_spec']['bundle_infos']):
+                        if bundle['uuid'] in bundle_uuids:
+                            is_relevant_block = True
+                        else:
+                            block['bundles_spec']['bundle_infos'][j] = None
+                    if not is_relevant_block:
+                        interpreted_blocks['blocks'][i] = None
+        # Grouped individual items into blocks
+        worksheet_info['blocks'] = resolve_interpreted_blocks(
+            interpreted_blocks['blocks'], brief=brief
+        )
+        worksheet_info['raw_to_block'] = interpreted_blocks['raw_to_block']
+        worksheet_info['block_to_raw'] = interpreted_blocks['block_to_raw']
+
+        if directive:
+            # If we're only async loading a single table_block / subworksheets_block,
+            # return only that block (which is at the end of worksheet_info['items'])
+            worksheet_info['blocks'] = [worksheet_info['blocks'][-1]] if len(search_results) else []
+
+        for block in worksheet_info['blocks']:
+            if block is None:
+                continue
+            if block['mode'] == 'table':
+                for row_map in block['rows']:
+                    for k, v in row_map.items():
+                        if v is None:
+                            row_map[k] = formatting.contents_str(v)
+            if 'bundle_info' in block:
+                infos = []
+                if isinstance(block['bundle_info'], list):
+                    infos = block['bundle_info']
+                elif isinstance(block['bundle_info'], dict):
+                    infos = [block['bundle_info']]
+                for bundle_info in infos:
+                    if bundle_info is None:
+                        continue
+                    if 'bundle_type' not in bundle_info:
+                        continue  # empty info: invalid bundle reference
+                    if isinstance(bundle_info, dict):
+                        format_metadata(bundle_info.get('metadata'))
+        # Frontend doesn't use individual 'items' for now
+        del worksheet_info['items']
+        if bundle_uuids:
+            return {'blocks': worksheet_info['blocks'], 'uuid': uuid}
+        return worksheet_info
 
 
 #############################################################
diff --git a/codalab/rest/oauth2.py b/codalab/rest/oauth2.py
index 37cc5b65..15476b0b 100644
--- a/codalab/rest/oauth2.py
+++ b/codalab/rest/oauth2.py
@@ -29,6 +29,11 @@ from bottle import request, template, local, route, post, get, default_app
 from codalab.objects.oauth2 import OAuth2AuthCode, OAuth2Token
 from codalab.server.authenticated_plugin import AuthenticatedPlugin
 from codalab.server.oauth2_provider import oauth2_provider
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @oauth2_provider.clientgetter
@@ -103,15 +108,21 @@ def authorize(*args, **kwargs):
     """
     'authorize' endpoint for OAuth2 authorization code flow.
     """
-    if request.method == 'GET':
-        client_id = kwargs.get('client_id')
-        redirect_uri = kwargs.get('redirect_uri')
-        client = local.model.get_oauth2_client(client_id)
-        return template("oauth2_authorize", client=client, redirect_uri=redirect_uri)
-    elif request.method == 'POST':
-        # Return True back to the authorize_handler wrapper iff confirmed.
-        confirm = request.forms.get('confirm', 'no')
-        return confirm == 'yes'
+    with tracer.start_as_current_span(
+        "/oauth2/authorize",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        if request.method == 'GET':
+            client_id = kwargs.get('client_id')
+            redirect_uri = kwargs.get('redirect_uri')
+            client = local.model.get_oauth2_client(client_id)
+            return template("oauth2_authorize", client=client, redirect_uri=redirect_uri)
+        elif request.method == 'POST':
+            # Return True back to the authorize_handler wrapper iff confirmed.
+            confirm = request.forms.get('confirm', 'no')
+            return confirm == 'yes'
 
 
 @post('/oauth2/token')
@@ -149,19 +160,37 @@ def handle_token():
           "example_parameter":"example_value"
         }
     """
-    pass
+    with tracer.start_as_current_span(
+        "/oauth2/token",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        pass
 
 
 @post('/oauth2/revoke')
 @oauth2_provider.revoke_handler
 def revoke_token():
     """Revoke OAuth2 token."""
-    pass
+    with tracer.start_as_current_span(
+        "/oauth2/revoke",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        pass
 
 
 @get('/oauth2/errors', name='oauth2_errors')
 def show_errors():
-    return template('oauth2_errors', **request.query)
+    with tracer.start_as_current_span(
+        "/oauth2/errors",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        return template('oauth2_errors', **request.query)
 
 
 default_app().config['OAUTH2_PROVIDER_ERROR_ENDPOINT'] = 'oauth2_errors'
diff --git a/codalab/rest/users.py b/codalab/rest/users.py
index ce679a13..fa3fa180 100644
--- a/codalab/rest/users.py
+++ b/codalab/rest/users.py
@@ -3,6 +3,7 @@ Worksheets REST API Users Views.
 """
 import http.client
 import os
+import logging
 
 from bottle import abort, get, request, local, delete
 
@@ -16,6 +17,11 @@ from codalab.rest.schemas import (
 )
 from codalab.server.authenticated_plugin import AuthenticatedPlugin, UserVerifiedPlugin
 from codalab.rest.util import get_resource_ids
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 USER_ACCESSIBLE_KEYWORDS = (
@@ -35,52 +41,70 @@ USER_ACCESSIBLE_KEYWORDS = (
     'size',
 )
 
+logger = logging.getLogger(__name__)
+
 
 @get('/user', apply=AuthenticatedPlugin(), skip=UserVerifiedPlugin)
 def fetch_authenticated_user():
     """Fetch authenticated user."""
-    user_info = AuthenticatedUserSchema().dump(request.user).data
-    user_info['data']['attributes']['is_root_user'] = (
-        request.user.user_id == local.model.root_user_id
-    )
-    user_info['data']['attributes']['protected_mode'] = (
-        os.environ.get('CODALAB_PROTECTED_MODE') == 'True'
-    )
-    return user_info
+    with tracer.start_as_current_span(
+        "/user",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        user_info = AuthenticatedUserSchema().dump(request.user).data
+        user_info['data']['attributes']['is_root_user'] = (
+            request.user.user_id == local.model.root_user_id
+        )
+        user_info['data']['attributes']['protected_mode'] = (
+            os.environ.get('CODALAB_PROTECTED_MODE') == 'True'
+        )
+        return user_info
 
 
 @patch('/user', apply=AuthenticatedPlugin(), skip=UserVerifiedPlugin)
 def update_authenticated_user():
+    """Fetch authenticated user."""
     """Update one or multiple fields of the authenticated user."""
-    # Load update request data
-    user_info = AuthenticatedUserSchema(strict=True).load(request.json, partial=False).data
-
-    if any(k in user_info for k in USER_READ_ONLY_FIELDS):
-        abort(
-            http.client.FORBIDDEN, "These fields are read-only: " + ', '.join(USER_READ_ONLY_FIELDS)
-        )
+    with tracer.start_as_current_span(
+        "/user",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        # Load update request data
+        user_info = AuthenticatedUserSchema(strict=True).load(request.json, partial=False).data
+
+        if any(k in user_info for k in USER_READ_ONLY_FIELDS):
+            abort(
+                http.client.FORBIDDEN,
+                "These fields are read-only: " + ', '.join(USER_READ_ONLY_FIELDS),
+            )
 
-    # Patch in user_id manually (do not allow requests to change id)
-    user_info['user_id'] = request.user.user_id
+        # Patch in user_id manually (do not allow requests to change id)
+        user_info['user_id'] = request.user.user_id
 
-    # Ensure that user name is not taken
-    if user_info.get(
-        'user_name', request.user.user_name
-    ) != request.user.user_name and local.model.user_exists(user_info['user_name'], None):
-        abort(http.client.BAD_REQUEST, "User name %s is already taken." % user_info['user_name'])
+        # Ensure that user name is not taken
+        if user_info.get(
+            'user_name', request.user.user_name
+        ) != request.user.user_name and local.model.user_exists(user_info['user_name'], None):
+            abort(
+                http.client.BAD_REQUEST, "User name %s is already taken." % user_info['user_name']
+            )
 
-    # Validate user name
-    if not NAME_REGEX.match(user_info.get('user_name', request.user.user_name)):
-        abort(
-            http.client.BAD_REQUEST,
-            "User name characters must be alphanumeric, underscores, periods, or dashes.",
-        )
+        # Validate user name
+        if not NAME_REGEX.match(user_info.get('user_name', request.user.user_name)):
+            abort(
+                http.client.BAD_REQUEST,
+                "User name characters must be alphanumeric, underscores, periods, or dashes.",
+            )
 
-    # Update user
-    local.model.update_user_info(user_info)
+        # Update user
+        local.model.update_user_info(user_info)
 
-    # Return updated user
-    return AuthenticatedUserSchema().dump(local.model.get_user(request.user.user_id)).data
+        # Return updated user
+        return AuthenticatedUserSchema().dump(local.model.get_user(request.user.user_id)).data
 
 
 def allowed_user_schema():
@@ -94,66 +118,85 @@ def allowed_user_schema():
 @get('/users/<user_spec>')
 def fetch_user(user_spec):
     """Fetch a single user."""
-    user = local.model.get_user(user_id=user_spec)
-    user = user or local.model.get_user(username=user_spec)
-    if user is None:
-        abort(http.client.NOT_FOUND, "User %s not found" % user_spec)
-    return allowed_user_schema()().dump(user).data
+    with tracer.start_as_current_span(
+        "/user/user_spec",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.user_spec", user_spec)
+
+        user = local.model.get_user(user_id=user_spec)
+        user = user or local.model.get_user(username=user_spec)
+        if user is None:
+            abort(http.client.NOT_FOUND, "User %s not found" % user_spec)
+        return allowed_user_schema()().dump(user).data
 
 
 @delete('/users', apply=AuthenticatedPlugin())
 def delete_user():
     """Fetch user ids"""
-    user_ids = get_resource_ids(request.json, 'users')
-
-    request_user_id = request.user.user_id
-
-    if not (request_user_id == local.model.root_user_id or (user_ids == [request_user_id])):
-        abort(http.client.UNAUTHORIZED, 'As a non-root user, you can only delete your own account.')
+    with tracer.start_as_current_span(
+        "/user",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        user_ids = get_resource_ids(request.json, 'users')
 
-    for user_id in user_ids:
-        if user_id == local.model.root_user_id:
-            abort(http.client.UNAUTHORIZED, 'Cannot delete root user.')
-        user = local.model.get_user(user_id=user_id)
-        if user is None:
-            abort(http.client.NOT_FOUND, 'User %s not found' % user_id)
-
-        '''
-        Check for owned bundles, worksheets, and groups.
-        If any are found, then do not allow user to be deleted.
-        '''
-        error_messages = []
-
-        bundles = local.model.batch_get_bundles(owner_id=user_id)
-        if bundles is not None and len(bundles) > 0:
-            bundle_uuids = [bundle.uuid for bundle in bundles]
-            error_messages.append(
-                'User %s owns bundles, can\'t delete user. UUIDs: %s\n'
-                % (user_id, ','.join(bundle_uuids))
-            )
+        request_user_id = request.user.user_id
 
-        worksheets = local.model.batch_get_worksheets(fetch_items=False, owner_id=user_id)
-        if worksheets is not None and len(worksheets) > 0:
-            worksheet_uuids = [worksheet.uuid for worksheet in worksheets]
-            error_messages.append(
-                'User %s owns worksheets, can\'t delete. UUIDs: %s\n'
-                % (user_id, ','.join(worksheet_uuids))
-            )
-
-        groups = local.model.batch_get_groups(owner_id=user_id)
-        if groups is not None and len(groups) > 0:
-            group_uuids = [group['uuid'] for group in groups]
-            error_messages.append(
-                'User %s owns groups, can\'t delete. UUIDs: %s\n' % (user_id, ','.join(group_uuids))
+        if not (request_user_id == local.model.root_user_id or (user_ids == [request_user_id])):
+            abort(
+                http.client.UNAUTHORIZED,
+                'As a non-root user, you can only delete your own account.',
             )
 
-        if error_messages:
-            abort(http.client.NOT_FOUND, '\n'.join(error_messages))
-
-        local.model.delete_user(user_id=user.user_id)
-
-    # Return list of deleted id as meta
-    return json_api_meta({}, {'ids': user_ids})
+        for user_id in user_ids:
+            if user_id == local.model.root_user_id:
+                abort(http.client.UNAUTHORIZED, 'Cannot delete root user.')
+            user = local.model.get_user(user_id=user_id)
+            if user is None:
+                abort(http.client.NOT_FOUND, 'User %s not found' % user_id)
+
+            '''
+            Check for owned bundles, worksheets, and groups.
+            If any are found, then do not allow user to be deleted.
+            '''
+            error_messages = []
+
+            bundles = local.model.batch_get_bundles(owner_id=user_id)
+            if bundles is not None and len(bundles) > 0:
+                bundle_uuids = [bundle.uuid for bundle in bundles]
+                error_messages.append(
+                    'User %s owns bundles, can\'t delete user. UUIDs: %s\n'
+                    % (user_id, ','.join(bundle_uuids))
+                )
+
+            worksheets = local.model.batch_get_worksheets(fetch_items=False, owner_id=user_id)
+            if worksheets is not None and len(worksheets) > 0:
+                worksheet_uuids = [worksheet.uuid for worksheet in worksheets]
+                error_messages.append(
+                    'User %s owns worksheets, can\'t delete. UUIDs: %s\n'
+                    % (user_id, ','.join(worksheet_uuids))
+                )
+
+            groups = local.model.batch_get_groups(owner_id=user_id)
+            if groups is not None and len(groups) > 0:
+                group_uuids = [group['uuid'] for group in groups]
+                error_messages.append(
+                    'User %s owns groups, can\'t delete. UUIDs: %s\n'
+                    % (user_id, ','.join(group_uuids))
+                )
+
+            if error_messages:
+                abort(http.client.NOT_FOUND, '\n'.join(error_messages))
+
+            local.model.delete_user(user_id=user.user_id)
+
+        # Return list of deleted id as meta
+        return json_api_meta({}, {'ids': user_ids})
 
 
 @get('/users')
@@ -176,32 +219,39 @@ def fetch_users():
     - `.count                 ` : Count the number of users.
     - `.limit=10              ` : Limit the number of results to the top 10.
     """
-    # Combine username and email filters
-    usernames = set(request.query.get('filter[user_name]', '').split(','))
-    usernames |= set(request.query.get('filter[email]', '').split(','))
-    usernames.discard('')  # str.split(',') will return '' on empty strings
-
-    keywords = query_get_list('keywords')
-    if usernames is None and keywords is None:
-        abort(
-            http.client.BAD_REQUEST, "Request must include 'keywords' query parameter or usernames"
-        )
+    with tracer.start_as_current_span(
+        "/users",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        # Combine username and email filters
+        usernames = set(request.query.get('filter[user_name]', '').split(','))
+        usernames |= set(request.query.get('filter[email]', '').split(','))
+        usernames.discard('')  # str.split(',') will return '' on empty strings
+
+        keywords = query_get_list('keywords')
+        if usernames is None and keywords is None:
+            abort(
+                http.client.BAD_REQUEST,
+                "Request must include 'keywords' query parameter or usernames",
+            )
 
-    if request.user.user_id != local.model.root_user_id:
-        for key in keywords:
-            if not all(accessed_field in key for accessed_field in USER_ACCESSIBLE_KEYWORDS):
-                abort(http.client.FORBIDDEN, "You don't have access to search for these fields")
+        if request.user.user_id != local.model.root_user_id:
+            for key in keywords:
+                if not all(accessed_field in key for accessed_field in USER_ACCESSIBLE_KEYWORDS):
+                    abort(http.client.FORBIDDEN, "You don't have access to search for these fields")
 
-    # Handle search keywords
-    users = local.model.get_users(keywords=(keywords or None), usernames=(usernames or None))
-    # Return simple dict if scalar result (e.g. .sum or .count queries)
-    if users.get('is_aggregate'):
+        # Handle search keywords
+        users = local.model.get_users(keywords=(keywords or None), usernames=(usernames or None))
+        # Return simple dict if scalar result (e.g. .sum or .count queries)
+        if users.get('is_aggregate'):
 
-        return json_api_meta({}, {'results': users['results']})
-    else:
-        users = users['results']
+            return json_api_meta({}, {'results': users['results']})
+        else:
+            users = users['results']
 
-    return allowed_user_schema()(many=True).dump(users).data
+        return allowed_user_schema()(many=True).dump(users).data
 
 
 @patch('/users')
@@ -214,28 +264,34 @@ def update_users():
     Follows the bulk-update convention in the CodaLab API, but currently only
     allows one update at a time.
     """
-    if request.user.user_id != local.model.root_user_id:
-        abort(http.client.FORBIDDEN, "Only root user can update other users.")
-
-    users = AdminUserSchema(strict=True, many=True).load(request.json, partial=True).data
-
-    if len(users) != 1:
-        abort(http.client.BAD_REQUEST, "Users can only be updated one at a time.")
-
-    if 'has_access' in users[0]:
-        # has_access can only be updated in protected mode
-        if os.environ.get('CODALAB_PROTECTED_MODE') != 'True':
-            abort(http.client.BAD_REQUEST, "This CodaLab instance is not in protected mode.")
-
-        # Only verified users can be given access to a protected instance
-        if not local.model.is_verified(users[0]['user_id']):
-            abort(
-                http.client.BAD_REQUEST,
-                "User has to be verified first in order to be granted access.",
-            )
-
-    local.model.update_user_info(users[0])
-
-    # Return updated users
-    users = local.model.get_users(user_ids=[users[0]['user_id']])['results']
-    return AdminUserSchema(many=True).dump(users).data
+    with tracer.start_as_current_span(
+        "/users",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        if request.user.user_id != local.model.root_user_id:
+            abort(http.client.FORBIDDEN, "Only root user can update other users.")
+
+        users = AdminUserSchema(strict=True, many=True).load(request.json, partial=True).data
+
+        if len(users) != 1:
+            abort(http.client.BAD_REQUEST, "Users can only be updated one at a time.")
+
+        if 'has_access' in users[0]:
+            # has_access can only be updated in protected mode
+            if os.environ.get('CODALAB_PROTECTED_MODE') != 'True':
+                abort(http.client.BAD_REQUEST, "This CodaLab instance is not in protected mode.")
+
+            # Only verified users can be given access to a protected instance
+            if not local.model.is_verified(users[0]['user_id']):
+                abort(
+                    http.client.BAD_REQUEST,
+                    "User has to be verified first in order to be granted access.",
+                )
+
+        local.model.update_user_info(users[0])
+
+        # Return updated users
+        users = local.model.get_users(user_ids=[users[0]['user_id']])['results']
+        return AdminUserSchema(many=True).dump(users).data
diff --git a/codalab/rest/workers.py b/codalab/rest/workers.py
index 57917d6d..a8b92e2d 100644
--- a/codalab/rest/workers.py
+++ b/codalab/rest/workers.py
@@ -13,6 +13,11 @@ from codalab.objects.permission import check_bundle_have_run_permission
 from codalab.server.authenticated_plugin import AuthenticatedProtectedPlugin
 from codalab.worker.bundle_state import BundleCheckinState
 from codalab.worker.main import DEFAULT_EXIT_AFTER_NUM_RUNS
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @post("/workers/<worker_id>/checkin", name="worker_checkin", apply=AuthenticatedProtectedPlugin())
@@ -22,36 +27,45 @@ def checkin(worker_id):
     Waits for a message for the worker for WAIT_TIME_SECS seconds. Returns the
     message or None if there isn't one.
     """
-    WAIT_TIME_SECS = 3.0
-
-    # Old workers might not have all the fields, so allow subsets to be missing.
-    socket_id = local.worker_model.worker_checkin(
-        request.user.user_id,
-        worker_id,
-        request.json.get("tag"),
-        request.json.get("group_name"),
-        request.json.get("cpus"),
-        request.json.get("gpus"),
-        request.json.get("memory_bytes"),
-        request.json.get("free_disk_bytes"),
-        request.json["dependencies"],
-        request.json.get("shared_file_system", False),
-        request.json.get("tag_exclusive", False),
-        request.json.get("exit_after_num_runs", DEFAULT_EXIT_AFTER_NUM_RUNS),
-        request.json.get("is_terminating", False),
-        request.json.get("preemptible", False),
-    )
-
-    for run in request.json["runs"]:
-        try:
-            worker_run = BundleCheckinState.from_dict(run)
-            bundle = local.model.get_bundle(worker_run.uuid)
-            local.model.bundle_checkin(bundle, worker_run, request.user.user_id, worker_id)
-        except Exception:
-            pass
+    with tracer.start_as_current_span(
+        "/workers/<worker_id>/checkin",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.worker_id", worker_id)
+
+        WAIT_TIME_SECS = 3.0
+
+        # Old workers might not have all the fields, so allow subsets to be missing.
+        socket_id = local.worker_model.worker_checkin(
+            request.user.user_id,
+            worker_id,
+            request.json.get("tag"),
+            request.json.get("group_name"),
+            request.json.get("cpus"),
+            request.json.get("gpus"),
+            request.json.get("memory_bytes"),
+            request.json.get("free_disk_bytes"),
+            request.json["dependencies"],
+            request.json.get("shared_file_system", False),
+            request.json.get("tag_exclusive", False),
+            request.json.get("exit_after_num_runs", DEFAULT_EXIT_AFTER_NUM_RUNS),
+            request.json.get("is_terminating", False),
+            request.json.get("preemptible", False),
+        )
+
+        for run in request.json["runs"]:
+            try:
+                worker_run = BundleCheckinState.from_dict(run)
+                bundle = local.model.get_bundle(worker_run.uuid)
+                local.model.bundle_checkin(bundle, worker_run, request.user.user_id, worker_id)
+            except Exception:
+                pass
 
-    with closing(local.worker_model.start_listening(socket_id)) as sock:
-        return local.worker_model.get_json_message(sock, WAIT_TIME_SECS)
+        with closing(local.worker_model.start_listening(socket_id)) as sock:
+            return local.worker_model.get_json_message(sock, WAIT_TIME_SECS)
 
 
 def check_reply_permission(worker_id, socket_id):
@@ -72,8 +86,16 @@ def reply(worker_id, socket_id):
     """
     Replies with a single JSON message to the given socket ID.
     """
-    check_reply_permission(worker_id, socket_id)
-    local.worker_model.send_json_message(socket_id, request.json, 60, autoretry=False)
+    with tracer.start_as_current_span(
+        "/workers/<worker_id>/reply/<socket_id>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.worker_id", worker_id)
+        check_reply_permission(worker_id, socket_id)
+        local.worker_model.send_json_message(socket_id, request.json, 60, autoretry=False)
 
 
 @post(
@@ -92,17 +114,26 @@ def reply_data(worker_id, socket_id):
 
     The contents of the second message go in the body of the HTTP request.
     """
-    if "header_message" not in request.query:
-        abort(http.client.BAD_REQUEST, "Missing header message.")
+    with tracer.start_as_current_span(
+        "/workers/<worker_id>/reply_data/<socket_id>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.worker_id", worker_id)
+        current_span.set_attribute("operation.socket_id", socket_id)
+        if "header_message" not in request.query:
+            abort(http.client.BAD_REQUEST, "Missing header message.")
 
-    try:
-        header_message = json.loads(request.query.header_message)
-    except ValueError:
-        abort(http.client.BAD_REQUEST, "Header message should be in JSON format.")
+        try:
+            header_message = json.loads(request.query.header_message)
+        except ValueError:
+            abort(http.client.BAD_REQUEST, "Header message should be in JSON format.")
 
-    check_reply_permission(worker_id, socket_id)
-    local.worker_model.send_json_message(socket_id, header_message, 60, autoretry=False)
-    local.worker_model.send_stream(socket_id, request["wsgi.input"], 60)
+        check_reply_permission(worker_id, socket_id)
+        local.worker_model.send_json_message(socket_id, header_message, 60, autoretry=False)
+        local.worker_model.send_stream(socket_id, request["wsgi.input"], 60)
 
 
 def check_run_permission(bundle):
@@ -124,43 +155,58 @@ def start_bundle(worker_id, uuid):
     given worker_id. If so, reports that it's starting to run and returns True.
     Otherwise, returns False, meaning the worker shouldn't run the bundle.
     """
-    bundle = local.model.get_bundle(uuid)
-    check_run_permission(bundle)
-    response.content_type = "application/json"
-    if local.model.transition_bundle_preparing(
-        bundle,
-        request.user.user_id,
-        worker_id,
-        start_time=request.json["start_time"],
-        remote=request.json["hostname"],
+    with tracer.start_as_current_span(
+        "/workers/<worker_id>/start_bundle/<uuid>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
     ):
-        print("Started bundle %s" % uuid)
-        return json.dumps(True)
-    return json.dumps(False)
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.worker_id", worker_id)
+        current_span.set_attribute("operation.uuid", uuid)
+        bundle = local.model.get_bundle(uuid)
+        check_run_permission(bundle)
+        response.content_type = "application/json"
+        if local.model.transition_bundle_preparing(
+            bundle,
+            request.user.user_id,
+            worker_id,
+            start_time=request.json["start_time"],
+            remote=request.json["hostname"],
+        ):
+            print("Started bundle %s" % uuid)
+            return json.dumps(True)
+        return json.dumps(False)
 
 
 @get("/workers/info", name="workers_info", apply=AuthenticatedProtectedPlugin())
 def workers_info():
-    workers = local.worker_model.get_workers()
-    if request.user.user_id != local.model.root_user_id:
-        # Filter to only include the workers that the user owns or has access to
-        user_groups = local.model.get_user_groups(request.user.user_id)
-        workers = [
-            worker
-            for worker in workers
-            if worker['user_id'] == request.user.user_id or worker['group_uuid'] in user_groups
-        ]
-
-    # Edit entries in the data to make them suitable for human reading
-    for worker in workers:
-        # checkin_time: seconds since epoch
-        worker["checkin_time"] = int(
-            (worker["checkin_time"] - datetime.utcfromtimestamp(0)).total_seconds()
-        )
-        del worker["dependencies"]
-
-        running_bundles = local.model.batch_get_bundles(uuid=worker["run_uuids"])
-        worker["cpus_in_use"] = sum(bundle.metadata.request_cpus for bundle in running_bundles)
-        worker["gpus_in_use"] = sum(bundle.metadata.request_gpus for bundle in running_bundles)
-
-    return {"data": workers}
+    with tracer.start_as_current_span(
+        "/workers/info",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        workers = local.worker_model.get_workers()
+        if request.user.user_id != local.model.root_user_id:
+            # Filter to only include the workers that the user owns or has access to
+            user_groups = local.model.get_user_groups(request.user.user_id)
+            workers = [
+                worker
+                for worker in workers
+                if worker['user_id'] == request.user.user_id or worker['group_uuid'] in user_groups
+            ]
+
+        # Edit entries in the data to make them suitable for human reading
+        for worker in workers:
+            # checkin_time: seconds since epoch
+            worker["checkin_time"] = int(
+                (worker["checkin_time"] - datetime.utcfromtimestamp(0)).total_seconds()
+            )
+            del worker["dependencies"]
+
+            running_bundles = local.model.batch_get_bundles(uuid=worker["run_uuids"])
+            worker["cpus_in_use"] = sum(bundle.metadata.request_cpus for bundle in running_bundles)
+            worker["gpus_in_use"] = sum(bundle.metadata.request_gpus for bundle in running_bundles)
+
+        return {"data": workers}
diff --git a/codalab/rest/worksheets.py b/codalab/rest/worksheets.py
index 778eaa85..baf948cd 100644
--- a/codalab/rest/worksheets.py
+++ b/codalab/rest/worksheets.py
@@ -32,6 +32,11 @@ from codalab.rest.schemas import (
 from codalab.rest.users import UserSchema
 from codalab.rest.util import get_bundle_infos, resolve_owner_in_keywords, get_resource_ids
 from codalab.server.authenticated_plugin import AuthenticatedProtectedPlugin, ProtectedPlugin
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
+
+tracer = trace.get_tracer(__name__)
 
 
 @get('/worksheets/<uuid:re:%s>' % spec_util.UUID_STR, apply=ProtectedPlugin())
@@ -43,70 +48,79 @@ def fetch_worksheet(uuid):
 
      - `include`: comma-separated list of related resources to include, such as "owner"
     """
-    include_set = query_get_json_api_include_set(
-        supported={
-            'owner',
-            'group_permissions',
-            'items',
-            'items.bundle',
-            'items.bundle.owner',
-            'items.subworksheet',
-        }
-    )
-    worksheet = get_worksheet_info(
-        uuid,
-        fetch_items='items' in include_set,
-        fetch_permissions='group_permissions' in include_set,
-    )
-
-    # Build response document
-    document = WorksheetSchema().dump(worksheet).data
-
-    # Include items
-    if 'items' in include_set:
-        json_api_include(document, WorksheetItemSchema(), worksheet['items'])
-
-    user_ids = set()
-
-    # Include bundles
-    if 'items.bundle' in include_set:
-        bundle_uuids = {
-            item['bundle_uuid']
-            for item in worksheet['items']
-            if item['type'] == worksheet_util.TYPE_BUNDLE and item['bundle_uuid'] is not None
-        }
-        bundle_infos = list(get_bundle_infos(bundle_uuids).values())
-        json_api_include(document, BundleSchema(), bundle_infos)
-        if 'items.bundle.owner' in include_set:
-            user_ids.update({b['owner_id'] for b in bundle_infos})
-
-    # Include users
-    if 'owner' in include_set:
-        user_ids.add(worksheet['owner_id'])
-    if user_ids:
-        json_api_include(
-            document, UserSchema(), local.model.get_users(user_ids=user_ids)['results']
+    with tracer.start_as_current_span(
+        "/worksheets/<uuid>",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+
+        include_set = query_get_json_api_include_set(
+            supported={
+                'owner',
+                'group_permissions',
+                'items',
+                'items.bundle',
+                'items.bundle.owner',
+                'items.subworksheet',
+            }
         )
-
-    # Include subworksheets
-    if 'items.subworksheets' in include_set:
-        subworksheet_uuids = {
-            item['subworksheet_uuid']
-            for item in worksheet['items']
-            if item['type'] == worksheet_util.TYPE_WORKSHEET
-            and item['subworksheet_uuid'] is not None
-        }
-        json_api_include(
-            document,
-            WorksheetSchema(),
-            local.model.batch_get_worksheets(fetch_items=False, uuid=subworksheet_uuids),
+        worksheet = get_worksheet_info(
+            uuid,
+            fetch_items='items' in include_set,
+            fetch_permissions='group_permissions' in include_set,
         )
 
-    # Include permissions
-    if 'group_permissions' in include_set:
-        json_api_include(document, WorksheetPermissionSchema(), worksheet['group_permissions'])
+        # Build response document
+        document = WorksheetSchema().dump(worksheet).data
+
+        # Include items
+        if 'items' in include_set:
+            json_api_include(document, WorksheetItemSchema(), worksheet['items'])
+
+        user_ids = set()
+
+        # Include bundles
+        if 'items.bundle' in include_set:
+            bundle_uuids = {
+                item['bundle_uuid']
+                for item in worksheet['items']
+                if item['type'] == worksheet_util.TYPE_BUNDLE and item['bundle_uuid'] is not None
+            }
+            bundle_infos = list(get_bundle_infos(bundle_uuids).values())
+            json_api_include(document, BundleSchema(), bundle_infos)
+            if 'items.bundle.owner' in include_set:
+                user_ids.update({b['owner_id'] for b in bundle_infos})
+
+        # Include users
+        if 'owner' in include_set:
+            user_ids.add(worksheet['owner_id'])
+        if user_ids:
+            json_api_include(
+                document, UserSchema(), local.model.get_users(user_ids=user_ids)['results']
+            )
+
+        # Include subworksheets
+        if 'items.subworksheets' in include_set:
+            subworksheet_uuids = {
+                item['subworksheet_uuid']
+                for item in worksheet['items']
+                if item['type'] == worksheet_util.TYPE_WORKSHEET
+                and item['subworksheet_uuid'] is not None
+            }
+            json_api_include(
+                document,
+                WorksheetSchema(),
+                local.model.batch_get_worksheets(fetch_items=False, uuid=subworksheet_uuids),
+            )
+
+        # Include permissions
+        if 'group_permissions' in include_set:
+            json_api_include(document, WorksheetPermissionSchema(), worksheet['group_permissions'])
 
-    return document
+        return document
 
 
 @get('/worksheets', apply=ProtectedPlugin())
@@ -118,51 +132,65 @@ def fetch_worksheets():
 
      - `include`: comma-separated list of related resources to include, such as "owner"
     """
-    keywords = query_get_list('keywords')
-    specs = query_get_list('specs')
-    base_worksheet_uuid = request.query.get('base')
-    include_set = query_get_json_api_include_set(supported={'owner', 'group_permissions'})
+    with tracer.start_as_current_span(
+        "/worksheets",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        keywords = query_get_list('keywords')
+        specs = query_get_list('specs')
+        base_worksheet_uuid = request.query.get('base')
+        include_set = query_get_json_api_include_set(supported={'owner', 'group_permissions'})
+
+        if specs:
+            uuids = [get_worksheet_uuid_or_create(base_worksheet_uuid, spec) for spec in specs]
+            worksheets = [
+                w.to_dict() for w in local.model.batch_get_worksheets(fetch_items=False, uuid=uuids)
+            ]
+        else:
+            keywords = resolve_owner_in_keywords(keywords)
+            worksheets = local.model.search_worksheets(request.user.user_id, keywords)
 
-    if specs:
-        uuids = [get_worksheet_uuid_or_create(base_worksheet_uuid, spec) for spec in specs]
-        worksheets = [
-            w.to_dict() for w in local.model.batch_get_worksheets(fetch_items=False, uuid=uuids)
-        ]
-    else:
-        keywords = resolve_owner_in_keywords(keywords)
-        worksheets = local.model.search_worksheets(request.user.user_id, keywords)
+        # Build response document
+        document = WorksheetSchema(many=True).dump(worksheets).data
 
-    # Build response document
-    document = WorksheetSchema(many=True).dump(worksheets).data
+        # Include users
+        if 'owner' in include_set:
+            owner_ids = {w['owner_id'] for w in worksheets}
+            if owner_ids:
+                json_api_include(
+                    document, UserSchema(), local.model.get_users(user_ids=owner_ids)['results']
+                )
 
-    # Include users
-    if 'owner' in include_set:
-        owner_ids = {w['owner_id'] for w in worksheets}
-        if owner_ids:
-            json_api_include(
-                document, UserSchema(), local.model.get_users(user_ids=owner_ids)['results']
-            )
+        # Include permissions
+        if 'group_permissions' in include_set:
+            for w in worksheets:
+                if 'group_permissions' in w:
+                    json_api_include(document, WorksheetPermissionSchema(), w['group_permissions'])
 
-    # Include permissions
-    if 'group_permissions' in include_set:
-        for w in worksheets:
-            if 'group_permissions' in w:
-                json_api_include(document, WorksheetPermissionSchema(), w['group_permissions'])
-
-    return document
+        return document
 
 
 @post('/worksheets', apply=AuthenticatedProtectedPlugin())
 def create_worksheets():
-    # TODO: support more attributes
-    worksheets = (
-        WorksheetSchema(strict=True, many=True).load(request.json).data  # only allow name for now
-    )
+    with tracer.start_as_current_span(
+        "/worksheets",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        # TODO: support more attributes
+        worksheets = (
+            WorksheetSchema(strict=True, many=True)
+            .load(request.json)
+            .data  # only allow name for now
+        )
 
-    for w in worksheets:
-        w['uuid'] = new_worksheet(w['name'])
+        for w in worksheets:
+            w['uuid'] = new_worksheet(w['name'])
 
-    return WorksheetSchema(many=True).dump(worksheets).data
+        return WorksheetSchema(many=True).dump(worksheets).data
 
 
 @put('/worksheets/<uuid:re:%s>/raw' % spec_util.UUID_STR, apply=ProtectedPlugin())
@@ -171,11 +199,20 @@ def update_worksheet_raw(uuid):
     """
     Request body contains the raw lines of the worksheet.
     """
-    lines = decoded_body().split(os.linesep)
-    new_items = worksheet_util.parse_worksheet_form(lines, local.model, request.user, uuid)
-    worksheet_info = get_worksheet_info(uuid, fetch_items=True)
-    update_worksheet_items(worksheet_info, new_items)
-    response.status = 204  # Success, No Content
+    with tracer.start_as_current_span(
+        "/worksheets/<uuid>/raw",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.uuid", uuid)
+
+        lines = decoded_body().split(os.linesep)
+        new_items = worksheet_util.parse_worksheet_form(lines, local.model, request.user, uuid)
+        worksheet_info = get_worksheet_info(uuid, fetch_items=True)
+        update_worksheet_items(worksheet_info, new_items)
+        response.status = 204  # Success, No Content
 
 
 @patch('/worksheets', apply=AuthenticatedProtectedPlugin())
@@ -183,14 +220,20 @@ def update_worksheets():
     """
     Bulk update worksheets metadata.
     """
-    worksheet_updates = (
-        WorksheetSchema(strict=True, many=True).load(request.json, partial=True).data
-    )
+    with tracer.start_as_current_span(
+        "/worksheets",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        worksheet_updates = (
+            WorksheetSchema(strict=True, many=True).load(request.json, partial=True).data
+        )
 
-    for w in worksheet_updates:
-        update_worksheet_metadata(w['uuid'], w)
+        for w in worksheet_updates:
+            update_worksheet_metadata(w['uuid'], w)
 
-    return WorksheetSchema(many=True).dump(worksheet_updates).data
+        return WorksheetSchema(many=True).dump(worksheet_updates).data
 
 
 @delete('/worksheets', apply=AuthenticatedProtectedPlugin())
@@ -202,10 +245,16 @@ def delete_worksheets():
     If |data-only|, only remove from the bundle store, not the bundle metadata.
     If |dry-run|, just return list of bundles that would be deleted, but do not actually delete.
     """
-    uuids = get_resource_ids(request.json, 'worksheets')
-    force = query_get_bool('force', default=False)
-    for uuid in uuids:
-        delete_worksheet(uuid, force)
+    with tracer.start_as_current_span(
+        "/worksheets",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        uuids = get_resource_ids(request.json, 'worksheets')
+        force = query_get_bool('force', default=False)
+        for uuid in uuids:
+            delete_worksheet(uuid, force)
 
 
 @post(
@@ -217,22 +266,31 @@ def replace_items(worksheet_uuid):
     Replace worksheet items with 'ids' with new 'items'.
     The new items will be inserted after the after_sort_key
     """
-    worksheet = local.model.get_worksheet(worksheet_uuid, fetch_items=False)
-    check_worksheet_has_all_permission(local.model, request.user, worksheet)
-    worksheet_util.check_worksheet_not_frozen(worksheet)
+    with tracer.start_as_current_span(
+        "/worksheets/<worksheet_uuid>/add-items",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        current_span = trace.get_current_span()
+        current_span.set_attribute("operation.worksheet_uuid", worksheet_uuid)
+
+        worksheet = local.model.get_worksheet(worksheet_uuid, fetch_items=False)
+        check_worksheet_has_all_permission(local.model, request.user, worksheet)
+        worksheet_util.check_worksheet_not_frozen(worksheet)
 
-    ids = request.json.get('ids', [])
-    item_type = request.json.get('item_type', 'markup')
-    after_sort_key = request.json.get('after_sort_key')
-    # Default to process only markup items.
-    if item_type == "markup":
-        items = [worksheet_util.markup_item(item) for item in request.json.get('items', [])]
-    elif item_type == "bundle":
-        items = [worksheet_util.bundle_item(item) for item in request.json.get('items', [])]
-    elif item_type == "directive":
-        # Note: for directives, the item should not include the preceding "%" symbol
-        items = [worksheet_util.directive_item(item) for item in request.json.get('items', [])]
-    local.model.add_worksheet_items(worksheet_uuid, items, after_sort_key, ids)
+        ids = request.json.get('ids', [])
+        item_type = request.json.get('item_type', 'markup')
+        after_sort_key = request.json.get('after_sort_key')
+        # Default to process only markup items.
+        if item_type == "markup":
+            items = [worksheet_util.markup_item(item) for item in request.json.get('items', [])]
+        elif item_type == "bundle":
+            items = [worksheet_util.bundle_item(item) for item in request.json.get('items', [])]
+        elif item_type == "directive":
+            # Note: for directives, the item should not include the preceding "%" symbol
+            items = [worksheet_util.directive_item(item) for item in request.json.get('items', [])]
+        local.model.add_worksheet_items(worksheet_uuid, items, after_sort_key, ids)
 
 
 @post('/worksheet-items', apply=AuthenticatedProtectedPlugin())
@@ -242,31 +300,37 @@ def create_worksheet_items():
 
     |replace| - Replace existing items in host worksheets. Default is False.
     """
-    replace = query_get_bool('replace', False)
-    # Get the uuid of the current worksheet
-    worksheet_uuid = query_get_type(str, 'uuid')
-    new_items = WorksheetItemSchema(strict=True, many=True).load(request.json).data
+    with tracer.start_as_current_span(
+        "/worksheets-items",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        replace = query_get_bool('replace', False)
+        # Get the uuid of the current worksheet
+        worksheet_uuid = query_get_type(str, 'uuid')
+        new_items = WorksheetItemSchema(strict=True, many=True).load(request.json).data
 
-    # Map of worksheet_uuid to list of items that exist in this worksheet
-    worksheet_to_items = {}
-    worksheet_to_items.setdefault(worksheet_uuid, [])
+        # Map of worksheet_uuid to list of items that exist in this worksheet
+        worksheet_to_items = {}
+        worksheet_to_items.setdefault(worksheet_uuid, [])
 
-    for item in new_items:
-        worksheet_to_items[worksheet_uuid].append(item)
+        for item in new_items:
+            worksheet_to_items[worksheet_uuid].append(item)
 
-    for worksheet_uuid, items in worksheet_to_items.items():
-        worksheet_info = get_worksheet_info(worksheet_uuid, fetch_items=True)
-        if replace:
-            # Replace items in the worksheet
-            update_worksheet_items(
-                worksheet_info, [Worksheet.Item.as_tuple(i) for i in items], convert_items=False
-            )
-        else:
-            # Append items to the worksheet
-            for item in items:
-                add_worksheet_item(worksheet_uuid, Worksheet.Item.as_tuple(item))
+        for worksheet_uuid, items in worksheet_to_items.items():
+            worksheet_info = get_worksheet_info(worksheet_uuid, fetch_items=True)
+            if replace:
+                # Replace items in the worksheet
+                update_worksheet_items(
+                    worksheet_info, [Worksheet.Item.as_tuple(i) for i in items], convert_items=False
+                )
+            else:
+                # Append items to the worksheet
+                for item in items:
+                    add_worksheet_item(worksheet_uuid, Worksheet.Item.as_tuple(item))
 
-    return WorksheetItemSchema(many=True).dump(new_items).data
+        return WorksheetItemSchema(many=True).dump(new_items).data
 
 
 @post('/worksheet-permissions', apply=AuthenticatedProtectedPlugin())
@@ -274,13 +338,19 @@ def set_worksheet_permissions():
     """
     Bulk set worksheet permissions.
     """
-    new_permissions = WorksheetPermissionSchema(strict=True, many=True).load(request.json).data
+    with tracer.start_as_current_span(
+        "/worksheet-permissions",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        new_permissions = WorksheetPermissionSchema(strict=True, many=True).load(request.json).data
 
-    for p in new_permissions:
-        worksheet = local.model.get_worksheet(p['object_uuid'], fetch_items=False)
-        worksheet_util.check_worksheet_not_frozen(worksheet)
-        set_worksheet_permission(worksheet, p['group_uuid'], p['permission'])
-    return WorksheetPermissionSchema(many=True).dump(new_permissions).data
+        for p in new_permissions:
+            worksheet = local.model.get_worksheet(p['object_uuid'], fetch_items=False)
+            worksheet_util.check_worksheet_not_frozen(worksheet)
+            set_worksheet_permission(worksheet, p['group_uuid'], p['permission'])
+        return WorksheetPermissionSchema(many=True).dump(new_permissions).data
 
 
 @get('/worksheets/sample/', apply=ProtectedPlugin())
@@ -289,32 +359,44 @@ def get_sample_worksheets():
     Get worksheets to display on the front page.
     Keep only |worksheet_uuids|.
     """
-    # Select good high-quality worksheets and randomly choose some
-    list_worksheets = search_worksheets(['tag=paper,software,data'])
-    list_worksheets = random.sample(list_worksheets, min(3, len(list_worksheets)))
-
-    # Always put home worksheet in
-    list_worksheets = search_worksheets(['name=home']) + list_worksheets
-
-    # Reformat
-    list_worksheets = [
-        {
-            'uuid': val['uuid'],
-            'display_name': val.get('title') or val['name'],
-            'owner_name': val['owner_name'],
-        }
-        for val in list_worksheets
-    ]
+    with tracer.start_as_current_span(
+        "/worksheets/sample",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        # Select good high-quality worksheets and randomly choose some
+        list_worksheets = search_worksheets(['tag=paper,software,data'])
+        list_worksheets = random.sample(list_worksheets, min(3, len(list_worksheets)))
+
+        # Always put home worksheet in
+        list_worksheets = search_worksheets(['name=home']) + list_worksheets
+
+        # Reformat
+        list_worksheets = [
+            {
+                'uuid': val['uuid'],
+                'display_name': val.get('title') or val['name'],
+                'owner_name': val['owner_name'],
+            }
+            for val in list_worksheets
+        ]
 
-    response.content_type = 'application/json'
-    return json.dumps(list_worksheets)
+        response.content_type = 'application/json'
+        return json.dumps(list_worksheets)
 
 
 @get('/worksheets/', apply=ProtectedPlugin())
 def get_worksheets_landing():
-    requested_ws = request.query.get('uuid', request.query.get('name', 'home'))
-    uuid = get_worksheet_uuid_or_create(None, requested_ws)
-    redirect('/worksheets/%s/' % uuid)
+    with tracer.start_as_current_span(
+        "/worksheets/",
+        context=extract(request.headers),
+        kind=trace.SpanKind.SERVER,
+        attributes=collect_request_attributes(request.environ),
+    ):
+        requested_ws = request.query.get('uuid', request.query.get('name', 'home'))
+        uuid = get_worksheet_uuid_or_create(None, requested_ws)
+        redirect('/worksheets/%s/' % uuid)
 
 
 #############################################################
diff --git a/codalab/server/auth.py b/codalab/server/auth.py
index 6cabb788..04624e5f 100644
--- a/codalab/server/auth.py
+++ b/codalab/server/auth.py
@@ -56,10 +56,12 @@ class RestOAuthHandler(object):
         }
         headers.update(self._extra_headers)
         request = urllib.request.Request(
-            self._address + '/rest/oauth2/token', data=urllib.parse.urlencode(data).encode('utf-8'),
+            self._address + '/rest/oauth2/token',
+            data=urllib.parse.urlencode(data).encode('utf-8'),
+            headers=headers,
         )
-        for k, v in headers.items():
-            request.add_unredirected_header(k, v)
+        # for k, v in headers.items():
+        #     request.add_unredirected_header(k, v)
         try:
             response = urlopen_with_retry(request)
             result = json.loads(response.read().decode())
diff --git a/codalab/server/bundle_manager.py b/codalab/server/bundle_manager.py
index d8a61060..81cc7cfb 100644
--- a/codalab/server/bundle_manager.py
+++ b/codalab/server/bundle_manager.py
@@ -26,7 +26,11 @@ from codalab.worker.file_util import remove_path
 from codalab.worker.un_tar_directory import un_tar_directory
 from codalab.worker.bundle_state import State, RunResources
 from codalab.worker.download_util import BundleTarget
+from opentelemetry import trace
+from opentelemetry.propagate import extract
+from opentelemetry.instrumentation.wsgi import collect_request_attributes
 
+tracer = trace.get_tracer(__name__)
 logger = logging.getLogger(__name__)
 
 SECONDS_PER_DAY = 60 * 60 * 24
@@ -125,88 +129,97 @@ class BundleManager(object):
             1) Failing any bundles that have any missing or failed dependencies.
             2) Staging any bundles that have all ready dependencies.
         """
-        bundles = self._model.batch_get_bundles(state=State.CREATED)
-        parent_uuids = set(dep.parent_uuid for bundle in bundles for dep in bundle.dependencies)
-        parents = self._model.batch_get_bundles(uuid=parent_uuids)
-
-        all_parent_states = {parent.uuid: parent.state for parent in parents}
-        all_parent_uuids = set(all_parent_states)
-
-        bundles_to_fail = []
-        bundles_to_stage = []
-        for bundle in bundles:
-            parent_uuids = set(dep.parent_uuid for dep in bundle.dependencies)
-
-            missing_uuids = parent_uuids - all_parent_uuids
-            if missing_uuids:
-                bundles_to_fail.append(
-                    (bundle, 'Missing parent bundles: %s' % ', '.join(missing_uuids))
-                )
-                continue
-
-            try:
-                check_bundles_have_read_permission(
-                    self._model, self._model.get_user(bundle.owner_id), parent_uuids
-                )
-            except PermissionError as e:
-                bundles_to_fail.append((bundle, str(e)))
-                continue
-
-            parent_states = {uuid: all_parent_states[uuid] for uuid in parent_uuids}
+        with tracer.start_as_current_span(
+            "/bundle_manager._stage_bundles", kind=trace.SpanKind.SERVER,
+        ):
+            bundles = self._model.batch_get_bundles(state=State.CREATED)
+            parent_uuids = set(dep.parent_uuid for bundle in bundles for dep in bundle.dependencies)
+            parents = self._model.batch_get_bundles(uuid=parent_uuids)
+
+            all_parent_states = {parent.uuid: parent.state for parent in parents}
+            all_parent_uuids = set(all_parent_states)
+
+            bundles_to_fail = []
+            bundles_to_stage = []
+            for bundle in bundles:
+                parent_uuids = set(dep.parent_uuid for dep in bundle.dependencies)
+
+                missing_uuids = parent_uuids - all_parent_uuids
+                if missing_uuids:
+                    bundles_to_fail.append(
+                        (bundle, 'Missing parent bundles: %s' % ', '.join(missing_uuids))
+                    )
+                    continue
 
-            acceptable_states = [State.READY]
-            if bundle.metadata.allow_failed_dependencies:
-                acceptable_states.append(State.FAILED)
-                acceptable_states.append(State.KILLED)
-            else:
-                failed_uuids = [
-                    uuid for uuid, state in parent_states.items() if state == State.FAILED
-                ]
-                killed_uuids = [
-                    uuid for uuid, state in parent_states.items() if state == State.KILLED
-                ]
-                failure_message = ''
-                if failed_uuids:
-                    failure_message += ' Parent bundles failed: %s' % ', '.join(failed_uuids)
-                if killed_uuids:
-                    failure_message += ' Parent bundles were killed: %s' % ', '.join(killed_uuids)
-                if failure_message:
-                    failure_message += ' (Please use the --allow-failed-dependencies flag to depend on results of failed or killed bundles)'
-                    bundles_to_fail.append((bundle, failure_message))
+                try:
+                    check_bundles_have_read_permission(
+                        self._model, self._model.get_user(bundle.owner_id), parent_uuids
+                    )
+                except PermissionError as e:
+                    bundles_to_fail.append((bundle, str(e)))
                     continue
 
-            if all(state in acceptable_states for state in parent_states.values()):
-                bundles_to_stage.append(bundle)
+                parent_states = {uuid: all_parent_states[uuid] for uuid in parent_uuids}
 
-        for bundle, failure_message in bundles_to_fail:
-            logger.info('Failing bundle %s: %s', bundle.uuid, failure_message)
-            self._model.update_bundle(
-                bundle, {'state': State.FAILED, 'metadata': {'failure_message': failure_message}}
-            )
-        for bundle in bundles_to_stage:
-            logger.info('Staging %s', bundle.uuid)
-            self._model.update_bundle(bundle, {'state': State.STAGED})
+                acceptable_states = [State.READY]
+                if bundle.metadata.allow_failed_dependencies:
+                    acceptable_states.append(State.FAILED)
+                    acceptable_states.append(State.KILLED)
+                else:
+                    failed_uuids = [
+                        uuid for uuid, state in parent_states.items() if state == State.FAILED
+                    ]
+                    killed_uuids = [
+                        uuid for uuid, state in parent_states.items() if state == State.KILLED
+                    ]
+                    failure_message = ''
+                    if failed_uuids:
+                        failure_message += ' Parent bundles failed: %s' % ', '.join(failed_uuids)
+                    if killed_uuids:
+                        failure_message += ' Parent bundles were killed: %s' % ', '.join(
+                            killed_uuids
+                        )
+                    if failure_message:
+                        failure_message += ' (Please use the --allow-failed-dependencies flag to depend on results of failed or killed bundles)'
+                        bundles_to_fail.append((bundle, failure_message))
+                        continue
 
-    def _make_bundles(self) -> List[threading.Thread]:
-        # Re-stage any stuck bundles. This would happen if the bundle manager
-        # died.
-        for bundle in self._model.batch_get_bundles(state=State.MAKING, bundle_type='make'):
-            if not self._is_making_bundle(bundle.uuid):
-                logger.info('Re-staging make bundle %s', bundle.uuid)
+                if all(state in acceptable_states for state in parent_states.values()):
+                    bundles_to_stage.append(bundle)
+
+            for bundle, failure_message in bundles_to_fail:
+                logger.info('Failing bundle %s: %s', bundle.uuid, failure_message)
+                self._model.update_bundle(
+                    bundle,
+                    {'state': State.FAILED, 'metadata': {'failure_message': failure_message}},
+                )
+            for bundle in bundles_to_stage:
+                logger.info('Staging %s', bundle.uuid)
                 self._model.update_bundle(bundle, {'state': State.STAGED})
 
-        threads = []
-        for bundle in self._model.batch_get_bundles(state=State.STAGED, bundle_type='make'):
-            logger.info('Making bundle %s', bundle.uuid)
-            self._model.update_bundle(bundle, {'state': State.MAKING})
-            with self._make_uuids_lock:
-                self._make_uuids.add(bundle.uuid)
-            # Making a bundle could take time, so do the work in a separate
-            # thread to ensure quick scheduling.
-            t = threading.Thread(target=self._make_bundle, args=[bundle])
-            threads.append(t)
-            t.start()
-        return threads
+    def _make_bundles(self) -> List[threading.Thread]:
+        with tracer.start_as_current_span(
+            "/bundle_manager._make_bundles", kind=trace.SpanKind.SERVER,
+        ):
+            # Re-stage any stuck bundles. This would happen if the bundle manager
+            # died.
+            for bundle in self._model.batch_get_bundles(state=State.MAKING, bundle_type='make'):
+                if not self._is_making_bundle(bundle.uuid):
+                    logger.info('Re-staging make bundle %s', bundle.uuid)
+                    self._model.update_bundle(bundle, {'state': State.STAGED})
+
+            threads = []
+            for bundle in self._model.batch_get_bundles(state=State.STAGED, bundle_type='make'):
+                logger.info('Making bundle %s', bundle.uuid)
+                self._model.update_bundle(bundle, {'state': State.MAKING})
+                with self._make_uuids_lock:
+                    self._make_uuids.add(bundle.uuid)
+                # Making a bundle could take time, so do the work in a separate
+                # thread to ensure quick scheduling.
+                t = threading.Thread(target=self._make_bundle, args=[bundle])
+                threads.append(t)
+                t.start()
+            return threads
 
     def _is_making_bundles(self):
         with self._make_uuids_lock:
@@ -793,24 +806,27 @@ class BundleManager(object):
         Fail bundles in uploading, staged and running state if we haven't heard from them for more than
         BUNDLE_TIMEOUT_DAYS days.
         """
-        bundles_to_fail = self._model.batch_get_bundles(
-            state=[State.UPLOADING, State.STAGED, State.RUNNING]
-        )
+        with tracer.start_as_current_span(
+            "/bundle_manager._fail_unresponsive_bundles", kind=trace.SpanKind.SERVER,
+        ):
+            bundles_to_fail = self._model.batch_get_bundles(
+                state=[State.UPLOADING, State.STAGED, State.RUNNING]
+            )
 
-        now = time.time()
+            now = time.time()
 
-        for bundle in bundles_to_fail:
-            # For simplicity, we use field metadata.created to calculate timeout for now.
-            # Ideally, we should use field metadata.last_updated.
-            if now - bundle.metadata.created > BUNDLE_TIMEOUT_DAYS * SECONDS_PER_DAY:
-                failure_message = 'Bundle has been stuck in {} state for more than {} days.'.format(
-                    bundle.state, BUNDLE_TIMEOUT_DAYS
-                )
-                logger.info('Failing bundle %s: %s', bundle.uuid, failure_message)
-                self._model.update_bundle(
-                    bundle,
-                    {'state': State.FAILED, 'metadata': {'failure_message': failure_message}},
-                )
+            for bundle in bundles_to_fail:
+                # For simplicity, we use field metadata.created to calculate timeout for now.
+                # Ideally, we should use field metadata.last_updated.
+                if now - bundle.metadata.created > BUNDLE_TIMEOUT_DAYS * SECONDS_PER_DAY:
+                    failure_message = 'Bundle has been stuck in {} state for more than {} days.'.format(
+                        bundle.state, BUNDLE_TIMEOUT_DAYS
+                    )
+                    logger.info('Failing bundle %s: %s', bundle.uuid, failure_message)
+                    self._model.update_bundle(
+                        bundle,
+                        {'state': State.FAILED, 'metadata': {'failure_message': failure_message}},
+                    )
 
     def _schedule_run_bundles(self):
         """
@@ -825,21 +841,24 @@ class BundleManager(object):
         READY / FAILED, no worker_run DB entry:
             Finished.
         """
-        workers = WorkerInfoAccessor(
-            self._model, self._worker_model, self._worker_timeout_seconds - 5
-        )
+        with tracer.start_as_current_span(
+            "/bundle_manager._schedule_run_bundles", kind=trace.SpanKind.SERVER,
+        ):
+            workers = WorkerInfoAccessor(
+                self._model, self._worker_model, self._worker_timeout_seconds - 5
+            )
 
-        # Handle some exceptional cases.
-        self._cleanup_dead_workers(workers)
-        self._restage_stuck_starting_bundles(workers)
-        self._bring_offline_stuck_running_bundles(workers)
-        self._acknowledge_recently_finished_bundles(workers)
-        # A dictionary structured as {user id : user information} to track those visited user information
-        user_info_cache = {}
-        staged_bundles_to_run = self._get_staged_bundles_to_run(workers, user_info_cache)
-
-        # Schedule, preferring user-owned workers.
-        self._schedule_run_bundles_on_workers(workers, staged_bundles_to_run, user_info_cache)
+            # Handle some exceptional cases.
+            self._cleanup_dead_workers(workers)
+            self._restage_stuck_starting_bundles(workers)
+            self._bring_offline_stuck_running_bundles(workers)
+            self._acknowledge_recently_finished_bundles(workers)
+            # A dictionary structured as {user id : user information} to track those visited user information
+            user_info_cache = {}
+            staged_bundles_to_run = self._get_staged_bundles_to_run(workers, user_info_cache)
+
+            # Schedule, preferring user-owned workers.
+            self._schedule_run_bundles_on_workers(workers, staged_bundles_to_run, user_info_cache)
 
     @staticmethod
     def _check_resource_failure(
diff --git a/codalab/server/rest_server.py b/codalab/server/rest_server.py
index 59e05f67..a2503461 100644
--- a/codalab/server/rest_server.py
+++ b/codalab/server/rest_server.py
@@ -55,6 +55,16 @@ sentry_sdk.init(
     environment=os.getenv('CODALAB_SENTRY_ENVIRONMENT'),
     integrations=[BottleIntegration()],
 )
+from opentelemetry import trace
+from opentelemetry.exporter.jaeger.thrift import JaegerExporter
+from opentelemetry.sdk.trace import TracerProvider
+from opentelemetry.sdk.trace.export import (
+    BatchSpanProcessor,
+    ConsoleSpanExporter,
+)
+from opentelemetry.propagate import set_global_textmap
+from opentelemetry.propagators.jaeger import JaegerPropagator
+from opentelemetry.sdk.resources import Resource
 
 
 class SaveEnvironmentPlugin(object):
diff --git a/codalab/worker/rest_client.py b/codalab/worker/rest_client.py
index 11fc5b06..6a653aaa 100644
--- a/codalab/worker/rest_client.py
+++ b/codalab/worker/rest_client.py
@@ -3,6 +3,7 @@ from io import StringIO
 import http.client
 import json
 import urllib.request
+from opentelemetry.instrumentation.urllib import URLLibInstrumentor
 import urllib.parse
 import urllib.error
 from typing import Dict
@@ -11,6 +12,12 @@ import socket
 
 from .un_gzip_stream import un_gzip_stream
 from codalab.common import URLOPEN_TIMEOUT_SECONDS, urlopen_with_retry
+from opentelemetry import trace
+from opentelemetry.propagate import inject
+
+
+# URLLibInstrumentor().instrument()
+tracer = trace.get_tracer(__name__)
 
 
 class RestClientException(Exception):
@@ -62,59 +69,62 @@ class RestClient(object):
         - string (text/plain)
         - dict (application/json)
         """
-        # Set headers
-        if headers is None:
-            headers = {}
-        headers['X-Requested-With'] = 'XMLHttpRequest'
-        access_token = self._get_access_token()
-        if authorized and access_token:
-            headers['Authorization'] = 'Bearer ' + self._get_access_token()
-
-        if isinstance(data, dict):
-            headers['Content-Type'] = 'application/json'
-            data = json.dumps(data)  # Turn dict into string
-        if isinstance(data, str):
-            data = data.encode()  # Turn string into bytes
-
-        # Emphasize utf-8 for non-bytes data.
-        if headers.get('Content-Type') in ('text/plain', 'application/json'):
-            headers['Content-Type'] += '; charset=utf-8'
-
-        headers.update(self._extra_headers)
-
-        # Set path
-        if query_params is not None:
-            path = path + '?' + urllib.parse.urlencode(query_params)
-        request_url = self._base_url + path
-
-        # Make the actual request
-        request = urllib.request.Request(request_url, data=data)
-        for k, v in headers.items():
-            request.add_unredirected_header(k, v)
-        request.get_method = lambda: method
-        if return_response:
-            # Return a file-like object containing the contents of the response
-            # body, transparently decoding gzip streams if indicated by the
-            # Content-Encoding header.
-            response = urlopen_with_retry(request, timeout=timeout_seconds)
-            encoding = response.headers.get('Content-Encoding')
-            if not encoding or encoding == 'identity':
-                return response
-            elif encoding == 'gzip':
-                return un_gzip_stream(response)
-            else:
-                raise RestClientException('Unsupported Content-Encoding: ' + encoding, False)
-
-        with closing(urlopen_with_retry(request, timeout=timeout_seconds)) as response:
-            # If the response is a JSON document, as indicated by the
-            # Content-Type header, try to deserialize it and return the result.
-            # Otherwise, just ignore the response body and return None.
-            if response.headers.get('Content-Type') == 'application/json':
-                response_data = response.read().decode()
-                try:
-                    return json.loads(response_data)
-                except ValueError:
-                    raise RestClientException('Invalid JSON: ' + response_data, False)
+        with tracer.start_as_current_span("rest_client", kind=trace.SpanKind.CLIENT):
+            # Set headers
+            if headers is None:
+                headers = {}
+            # Inject opentelemetry headers
+            inject(headers)
+            headers['X-Requested-With'] = 'XMLHttpRequest'
+            access_token = self._get_access_token()
+            if authorized and access_token:
+                headers['Authorization'] = 'Bearer ' + self._get_access_token()
+
+            if isinstance(data, dict):
+                headers['Content-Type'] = 'application/json'
+                data = json.dumps(data)  # Turn dict into string
+            if isinstance(data, str):
+                data = data.encode()  # Turn string into bytes
+
+            # Emphasize utf-8 for non-bytes data.
+            if headers.get('Content-Type') in ('text/plain', 'application/json'):
+                headers['Content-Type'] += '; charset=utf-8'
+
+            headers.update(self._extra_headers)
+
+            # Set path
+            if query_params is not None:
+                path = path + '?' + urllib.parse.urlencode(query_params)
+            request_url = self._base_url + path
+
+            # Make the actual request
+            request = urllib.request.Request(request_url, data=data, headers=headers)
+            # for k, v in headers.items():
+            #     request.add_unredirected_header(k, v)
+            request.get_method = lambda: method
+            if return_response:
+                # Return a file-like object containing the contents of the response
+                # body, transparently decoding gzip streams if indicated by the
+                # Content-Encoding header.
+                response = urlopen_with_retry(request, timeout=timeout_seconds)
+                encoding = response.headers.get('Content-Encoding')
+                if not encoding or encoding == 'identity':
+                    return response
+                elif encoding == 'gzip':
+                    return un_gzip_stream(response)
+                else:
+                    raise RestClientException('Unsupported Content-Encoding: ' + encoding, False)
+
+            with closing(urlopen_with_retry(request, timeout=timeout_seconds)) as response:
+                # If the response is a JSON document, as indicated by the
+                # Content-Type header, try to deserialize it and return the result.
+                # Otherwise, just ignore the response body and return None.
+                if response.headers.get('Content-Type') == 'application/json':
+                    response_data = response.read().decode()
+                    try:
+                        return json.loads(response_data)
+                    except ValueError:
+                        raise RestClientException('Invalid JSON: ' + response_data, False)
 
     def _upload_with_chunked_encoding(
         self, method, url, query_params, fileobj, progress_callback=None
diff --git a/requirements.txt b/requirements.txt
index 7b78c27f..5a0cf2f7 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -32,3 +32,10 @@ retry==0.9.2
 spython==0.1.14
 flufl.lock==6.0
 google-cloud-storage==2.0.0
+opentelemetry-api
+opentelemetry-sdk
+opentelemetry-instrumentation-urllib
+opentelemetry-exporter-jaeger
+opentelemetry-propagator-jaeger
+opentelemetry-instrumentation-wsgi
+opentelemetry-instrumentation-sqlalchemy
